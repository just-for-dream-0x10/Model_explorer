# 更新日志 / Changelog

## [v1.8.0] -  🎯 明确"视角差异"定位

### 🔄 核心决策：接受功能重复，强调视角不同

**重要决策**：✅ **保留与 vision 项目的功能重复，明确"视角差异"作为核心定位**

#### 为什么接受重复？

虽然 CNN、GNN、优化器等功能在 vision 项目中也存在，但**视角和深度完全不同**：

| 维度 | Neural（本项目） | vision | Transformer_Explorer |
|------|-----------------|--------|---------------------|
| **核心视角** | 🔧 "如何实现" | 📐 "数学本质" | 🏗️ "为什么设计" |
| **典型问题** | "Conv2d 有多少参数？" | "卷积定理如何证明？" | "Multi-Head 为什么好？" |
| **深度层次** | 代码级（逐行计算） | 理论级（严格推导） | 设计级（架构对比） |
| **用户群体** | PyTorch 实现者 | 数学研究者 | 架构设计者 |

#### 具体示例

**示例 1：卷积操作**
- **Neural**：3×3 卷积核的逐像素计算、参数量 $C_{out} \times C_{in} \times K^2$、FLOPs 分析
- **vision**：卷积定理的傅里叶变换证明、卷积的交换律结合律
- **Transformer**：不涉及

**示例 2：GNN**
- **Neural**：GCN 消息传递的具体计算步骤、$D^{-1/2}AD^{-1/2}$ 的矩阵乘法
- **vision**：图拉普拉斯矩阵的谱分解、切比雪夫多项式逼近
- **Transformer**：不涉及

**示例 3：优化器**
- **Neural**：Adam 的 m 和 v 更新公式、学习率调度的实际效果
- **vision**：Adam 的收敛性证明、动量的指数加权移动平均推导
- **Transformer**：AdamW vs Adam 在 Transformer 中的差异

### 📝 文档更新

#### README 重大修改
- ✅ 添加"与其他项目的视角差异"对比表
- ✅ 添加具体差异举例（卷积、GNN、优化器）
- ✅ 添加推荐学习路径：vision（理论）→ Neural（实现）→ 编码 → Transformer（架构）
- ✅ 强调"功能重复但视角不同"的设计哲学

#### 模块化重构
- ✅ 创建 `utils/` 目录：配置、国际化、训练工具
- ✅ 创建 `tabs/` 目录：各标签页模块
- ✅ 简化 `app.py`：从 2433 行精简到 221 行
- ✅ 移除扩散模型模块（512 行）

### 🔧 技术改进

#### 新增模块
- ✅ `utils/config.py`：系统配置和字体设置
- ✅ `utils/i18n.py`：国际化文本配置
- ✅ `utils/training.py`：训练模拟工具
- ✅ `tabs/params_calculator.py`：参数量计算器（已存在，移动到 tabs/）
- ✅ `tabs/math_derivation.py`：数学推导工具（新提取）

#### 保留的"重复"功能（视角不同）
- ✅ CNN 卷积层：专注参数计算、FLOPs、内存分析
- ✅ GNN 图神经网络：专注消息传递步骤、参数对比
- ✅ RNN/LSTM：专注门控计算、梯度流分析
- ✅ 数学推导工具：仅保留与实现直接相关的推导

### 📊 代码统计

- 主应用精简：2433 行 → 221 行（**-91%**）
- 新增模块化文件：7 个
- 移除代码：扩散模型 512 行
- 总代码量：约 3500 行（重构后更清晰）

---

## [v1.7.0] - 2025-12-09 补齐核心定位：第4个问题

### 🎯 核心改进

项目定位要求每个模块回答4个核心问题。
本次更新重点解决**第4个问题缺失**的核心差距（从45%提升到70%）。

### ✨ 新增功能

#### 1. CNN模块 - 卷积配置诊断
- 自动检测5种配置问题（步长、尺寸、padding、通道数、卷积核）
- 常见问题速查表（6种症状+解决方案）
- 配置最佳实践对比
- 实际案例对比实验

#### 2. GNN模块 - 图结构问题检测
- 自动检测5种图问题（孤立节点、稀疏/稠密、度分布、过平滑）
- 图结构统计（8项指标实时监控）
- GNN常见问题速查表（6种症状+诊断方法）
- 不同场景的GNN选择（5种图类型推荐）

#### 3. 参数计算器 - 参数量/FLOPs警告
- 自动检测3种规模问题（参数量、FLOPs、参数效率）
- 模型规模参考基准（5个级别）
- 优化策略决策矩阵（参数 vs FLOPs优化）
- 优化权衡分析（5种方法对比）

### 📝 文档更新

#### README精简与修正
- 删除开发计划和Phase路线图
- 修正"单步调试"→"详细的数值展示"
- 添加"模拟训练曲线"说明
- 补充MoE和模型剪枝模块说明

### 📊 影响评估

**定位符合度提升：**
- 问题4完成度：45% → **70%** ⬆️ +25%
- 综合评分：80/100 → **85/100** ⬆️ +5分

**代码统计：**
- 新增代码：~600行
- 修改文件：3个核心模块（cnn.py, gnn.py, params_calculator.py）
- 精简README：从558行精简到~200行

---

## [v1.6.0] - 2025-12-05 参数计算器大幅扩展

### ✨ 新增功能

#### 参数量/FLOPs计算器大幅扩展

**新增5种层类型支持**:
- DepthwiseConv2d - 深度可分离卷积（MobileNet核心技术）
- MultiHeadAttention - 多头注意力机制（Transformer核心）
- LSTM - 长短期记忆网络（支持双向、多层）
- Embedding - 嵌入层（含词表大小参考）
- LayerNorm - 层归一化（Transformer标配）

**新增4个现代网络架构**:
- MobileNetV2 - 轻量级CNN（3.5M参数）
- BERT-base - Transformer编码器（110M参数，12层）
- GPT-2 small - Transformer解码器（117M参数，12层）
- ViT-Base - Vision Transformer（86M参数）

**增强功能**:
- 对比分析：Depthwise vs 标准卷积、LSTM vs GRU、LayerNorm vs BatchNorm
- 复杂度警告：自动检测注意力机制的O(n²)复杂度问题
- 优化建议：针对高参数量/计算量给出具体优化方案
- 详细公式展示：每个计算步骤都有数学公式和过程

### 📈 技术覆盖

现在支持从经典CNN到现代Transformer的完整技术栈：
- **CNN系列**: Conv2d, DepthwiseConv2d, BatchNorm2d
- **Transformer系列**: MultiHeadAttention, LayerNorm, Embedding
- **RNN系列**: LSTM (支持双向、多层)
- **基础层**: Linear

---

## [v1.5.0] - 2025-12-03 反向传播与交互实验室

### ✨ 新增功能

#### 🔬 反向传播原理模块
- **全连接网络反向传播**: 逐层梯度计算、数值梯度验证、梯度流可视化
- **CNN卷积网络反向传播**: 卷积层反向传播公式、梯度热力图
- **RNN循环网络反向传播**: BPTT算法、梯度消失/爆炸演示

#### 🎮 交互实验室模块
- **CNN特征图可视化**: 支持上传图像、多种卷积核、实时卷积操作
- **GNN节点分类演示**: 图结构可视化、消息传递机制
- **激活函数对比**: 7种激活函数、梯度传播分析
- **优化器轨迹可视化**: 4种优化器、3种损失函数地形
- **损失函数3D地形图**: 4种损失函数的三维可视化
- **批量参数对比**: 同时对比多组超参数

### 🐛 Bug修复
- 修复 `cnn_tab()` 函数参数不匹配问题
- 修复 `gnn_tab()` 函数参数不匹配问题
- 替换已弃用的 `use_container_width` 参数为 `width='stretch'`

---

## [v1.0.0] - 2025-12-01 初始版本

### ✨ 核心功能

- 基础CNN模块
- 基础GNN模块
- 基础RNN/LSTM模块
- 简单的参数计算器
- 数学推导工具

---

**开发者**: Just For Dream Lab  
**项目地址**: git@github.com:just-for-dream-0x10/Model_explorer.git
