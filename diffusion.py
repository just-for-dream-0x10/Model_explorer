"""
æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰æ•°å­¦åŸç†æ¨¡å—

åŒ…å«ï¼š
- DDPM (Denoising Diffusion Probabilistic Models)
- å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸åå‘å»å™ªè¿‡ç¨‹
- æ•°å­¦æ¨å¯¼å’Œå¯è§†åŒ–
- å›¾åƒç”Ÿæˆæ¼”ç¤º
"""

import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from simple_latex import display_latex
from PIL import Image
import torchvision.transforms as transforms


class SimpleUNet(nn.Module):
    """ç®€åŒ–ç‰ˆU-Netç”¨äºæ‰©æ•£æ¨¡å‹å»å™ª"""
    def __init__(self, in_channels=1, out_channels=1, time_emb_dim=32):
        super().__init__()
        self.time_emb_dim = time_emb_dim
        
        # æ—¶é—´åµŒå…¥
        self.time_mlp = nn.Sequential(
            nn.Linear(time_emb_dim, time_emb_dim * 4),
            nn.SiLU(),
            nn.Linear(time_emb_dim * 4, time_emb_dim)
        )
        
        # ç¼–ç å™¨
        self.conv1 = nn.Conv2d(in_channels, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)
        
        # è§£ç å™¨
        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)
        self.conv5 = nn.Conv2d(64, 32, 3, padding=1)
        self.conv6 = nn.Conv2d(32, out_channels, 3, padding=1)
        
        self.pool = nn.MaxPool2d(2)
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        
    def pos_encoding(self, t, channels):
        """ä½ç½®ç¼–ç ç”¨äºæ—¶é—´æ­¥"""
        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2, device=t.device).float() / channels))
        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)
        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)
        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)
        return pos_enc
    
    def forward(self, x, t):
        # æ—¶é—´åµŒå…¥
        t = t.unsqueeze(-1).float()
        t_emb = self.pos_encoding(t, self.time_emb_dim)
        t_emb = self.time_mlp(t_emb)
        
        # ç¼–ç 
        x1 = F.relu(self.conv1(x))
        x2 = self.pool(x1)
        x2 = F.relu(self.conv2(x2))
        x3 = self.pool(x2)
        x3 = F.relu(self.conv3(x3))
        
        # è§£ç 
        x = self.upsample(x3)
        x = F.relu(self.conv4(x))
        x = self.upsample(x)
        x = F.relu(self.conv5(x))
        x = self.conv6(x)
        
        return x


def get_beta_schedule(schedule_name, timesteps, beta_start=0.0001, beta_end=0.02):
    """
    è·å–ä¸åŒçš„å™ªå£°è°ƒåº¦ç­–ç•¥
    
    å‚æ•°:
        schedule_name: 'linear', 'cosine', 'quadratic'
        timesteps: æ‰©æ•£æ­¥æ•°
        beta_start: èµ·å§‹Î²å€¼
        beta_end: ç»“æŸÎ²å€¼
    """
    if schedule_name == 'linear':
        return np.linspace(beta_start, beta_end, timesteps)
    elif schedule_name == 'cosine':
        steps = timesteps + 1
        x = np.linspace(0, timesteps, steps)
        alphas_cumprod = np.cos(((x / timesteps) + 0.008) / 1.008 * np.pi * 0.5) ** 2
        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])
        return np.clip(betas, 0.0001, 0.9999)
    elif schedule_name == 'quadratic':
        return np.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2
    else:
        raise ValueError(f"Unknown schedule: {schedule_name}")


class DiffusionModel:
    """DDPMæ‰©æ•£æ¨¡å‹å®ç°"""
    
    def __init__(self, timesteps=1000, beta_schedule='linear'):
        self.timesteps = timesteps
        
        # è®¡ç®—betaå’Œalpha
        self.betas = get_beta_schedule(beta_schedule, timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = np.cumprod(self.alphas)
        self.alphas_cumprod_prev = np.append(1.0, self.alphas_cumprod[:-1])
        
        # ç”¨äºq(x_t | x_0)çš„è®¡ç®—
        self.sqrt_alphas_cumprod = np.sqrt(self.alphas_cumprod)
        self.sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - self.alphas_cumprod)
        
        # ç”¨äºåéªŒq(x_{t-1} | x_t, x_0)
        self.posterior_variance = (
            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)
        )
        
    def q_sample(self, x_start, t, noise=None):
        """
        å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼šq(x_t | x_0)
        x_t = âˆš(á¾±_t) * x_0 + âˆš(1 - á¾±_t) * Îµ
        """
        if noise is None:
            noise = np.random.randn(*x_start.shape)
        
        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t]
        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t]
        
        # è°ƒæ•´ç»´åº¦ä»¥ä¾¿å¹¿æ’­
        while len(sqrt_alphas_cumprod_t.shape) < len(x_start.shape):
            sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_t[..., np.newaxis]
            sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod_t[..., np.newaxis]
        
        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise
    
    def p_sample(self, model, x_t, t, device='cpu'):
        """
        åå‘å»å™ªè¿‡ç¨‹ï¼šp(x_{t-1} | x_t)
        ä½¿ç”¨æ¨¡å‹é¢„æµ‹çš„å™ªå£°æ¥æ¢å¤x_{t-1}
        """
        # é¢„æµ‹å™ªå£°
        with torch.no_grad():
            x_t_tensor = torch.FloatTensor(x_t).to(device)
            t_tensor = torch.LongTensor([t]).to(device)
            predicted_noise = model(x_t_tensor.unsqueeze(0).unsqueeze(0), t_tensor)
            predicted_noise = predicted_noise.squeeze().cpu().numpy()
        
        # è®¡ç®—x_0çš„ä¼°è®¡
        alpha_t = self.alphas[t]
        alpha_cumprod_t = self.alphas_cumprod[t]
        beta_t = self.betas[t]
        
        x_0_pred = (x_t - np.sqrt(1 - alpha_cumprod_t) * predicted_noise) / np.sqrt(alpha_cumprod_t)
        
        # è®¡ç®—å‡å€¼
        if t > 0:
            posterior_variance_t = self.posterior_variance[t]
            noise = np.random.randn(*x_t.shape)
            x_prev = (
                np.sqrt(alpha_t) * (1 - self.alphas_cumprod_prev[t]) / (1 - alpha_cumprod_t) * x_t +
                np.sqrt(self.alphas_cumprod_prev[t]) * beta_t / (1 - alpha_cumprod_t) * x_0_pred +
                np.sqrt(posterior_variance_t) * noise
            )
        else:
            x_prev = x_0_pred
        
        return x_prev, x_0_pred


def create_2d_gaussian_data(n_samples=500, noise_level=0.1):
    """åˆ›å»º2Dé«˜æ–¯æ··åˆæ•°æ®ç”¨äºå¯è§†åŒ–"""
    # åˆ›å»ºSwiss Rollæˆ–å…¶ä»–2Dåˆ†å¸ƒ
    theta = np.sqrt(np.random.rand(n_samples)) * 3 * np.pi
    r = 2 * theta + np.random.randn(n_samples) * noise_level
    x = r * np.cos(theta)
    y = r * np.sin(theta)
    return np.stack([x, y], axis=1)


def diffusion_tab(CHINESE_SUPPORTED):
    """æ‰©æ•£æ¨¡å‹ä¸»æ ‡ç­¾é¡µ"""
    
    if CHINESE_SUPPORTED:
        st.title("ğŸŒŠ æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰æ•°å­¦åŸç†")
        st.markdown("""
        æ‰©æ•£æ¨¡å‹æ˜¯å½“å‰æœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹ä¹‹ä¸€ï¼Œå¹¿æ³›åº”ç”¨äºå›¾åƒç”Ÿæˆï¼ˆStable Diffusionã€DALL-Eï¼‰ã€
        éŸ³é¢‘åˆæˆã€è§†é¢‘ç”Ÿæˆç­‰é¢†åŸŸã€‚æœ¬æ¨¡å—æ·±å…¥æ¢è®¨å…¶æ•°å­¦åŸç†ã€‚
        """)
    else:
        st.title("ğŸŒŠ Diffusion Models: Mathematical Principles")
        st.markdown("""
        Diffusion models are state-of-the-art generative models widely used in image generation 
        (Stable Diffusion, DALL-E), audio synthesis, and video generation.
        """)
    
    # ä¾§è¾¹æ å‚æ•°
    st.sidebar.header("æ‰©æ•£æ¨¡å‹å‚æ•°" if CHINESE_SUPPORTED else "Diffusion Parameters")
    
    timesteps = st.sidebar.slider(
        "æ‰©æ•£æ­¥æ•° (T)" if CHINESE_SUPPORTED else "Timesteps (T)",
        min_value=50, max_value=1000, value=200, step=50
    )
    
    beta_schedule = st.sidebar.selectbox(
        "Î²è°ƒåº¦ç­–ç•¥" if CHINESE_SUPPORTED else "Beta Schedule",
        ['linear', 'cosine', 'quadratic']
    )
    
    # ç”Ÿæˆå¯è§†åŒ–æ—¶é—´æ­¥é€‰é¡¹
    timestep_options = list(range(0, timesteps, max(1, timesteps//10)))
    if timesteps - 1 not in timestep_options:
        timestep_options.append(timesteps - 1)
    
    # ç¡®ä¿é»˜è®¤å€¼åœ¨é€‰é¡¹ä¸­
    default_steps = []
    for t in [0, timesteps//4, timesteps//2, 3*timesteps//4, timesteps-1]:
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„é€‰é¡¹
        closest = min(timestep_options, key=lambda x: abs(x - t))
        if closest not in default_steps:
            default_steps.append(closest)
    
    visualization_timesteps = st.sidebar.multiselect(
        "å¯è§†åŒ–æ—¶é—´æ­¥" if CHINESE_SUPPORTED else "Visualization Timesteps",
        timestep_options,
        default=default_steps[:5]  # æœ€å¤š5ä¸ªé»˜è®¤å€¼
    )
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“š æ•°å­¦ç†è®º" if CHINESE_SUPPORTED else "ğŸ“š Theory",
        "â¡ï¸ å‰å‘æ‰©æ•£" if CHINESE_SUPPORTED else "â¡ï¸ Forward Process",
        "â¬…ï¸ åå‘å»å™ª" if CHINESE_SUPPORTED else "â¬…ï¸ Reverse Process",
        "ğŸ¨ å›¾åƒç”Ÿæˆ" if CHINESE_SUPPORTED else "ğŸ¨ Image Generation",
        "ğŸ“Š 2Då¯è§†åŒ–" if CHINESE_SUPPORTED else "ğŸ“Š 2D Visualization"
    ])
    
    # åˆ›å»ºæ‰©æ•£æ¨¡å‹å®ä¾‹
    diffusion = DiffusionModel(timesteps=timesteps, beta_schedule=beta_schedule)
    
    with tab1:
        show_theory(CHINESE_SUPPORTED, diffusion)
    
    with tab2:
        show_forward_process(CHINESE_SUPPORTED, diffusion, visualization_timesteps)
    
    with tab3:
        show_reverse_process(CHINESE_SUPPORTED, diffusion, visualization_timesteps)
    
    with tab4:
        show_image_generation(CHINESE_SUPPORTED, diffusion, timesteps)
    
    with tab5:
        show_2d_visualization(CHINESE_SUPPORTED, diffusion, visualization_timesteps)


def show_theory(CHINESE_SUPPORTED, diffusion):
    """æ˜¾ç¤ºæ•°å­¦ç†è®ºéƒ¨åˆ†"""
    
    if CHINESE_SUPPORTED:
        st.header("æ‰©æ•£æ¨¡å‹æ•°å­¦åŸºç¡€")
        
        st.subheader("1ï¸âƒ£ æ ¸å¿ƒæ€æƒ³")
        st.markdown("""
        æ‰©æ•£æ¨¡å‹é€šè¿‡ä¸¤ä¸ªè¿‡ç¨‹ç”Ÿæˆæ•°æ®ï¼š
        - **å‰å‘è¿‡ç¨‹**ï¼šé€æ­¥å‘æ•°æ®æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œç›´åˆ°å˜æˆçº¯å™ªå£°
        - **åå‘è¿‡ç¨‹**ï¼šè®­ç»ƒç¥ç»ç½‘ç»œå­¦ä¹ é€†å‘å»å™ªï¼Œä»å™ªå£°æ¢å¤æ•°æ®
        """)
        
        st.subheader("2ï¸âƒ£ å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼ˆForward Processï¼‰")
        st.markdown("**é©¬å°”å¯å¤«é“¾å®šä¹‰**ï¼šç»™å®šæ•°æ® $x_0 \\sim q(x_0)$ï¼Œé€šè¿‡ $T$ æ­¥é€æ¸æ·»åŠ å™ªå£°")
        
        display_latex(r"q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)")
        
        st.markdown("å…¶ä¸­ $\\beta_t \\in (0,1)$ æ˜¯å™ªå£°è°ƒåº¦è¡¨")
        
        st.markdown("**é‡è¦æ€§è´¨**ï¼šå¯ä»¥ç›´æ¥ä» $x_0$ é‡‡æ ·ä»»æ„æ—¶åˆ» $x_t$ï¼ˆé‡å‚æ•°åŒ–æŠ€å·§ï¼‰")
        
        display_latex(r"q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) I)")
        
        st.markdown("å…¶ä¸­ï¼š")
        display_latex(r"\alpha_t = 1 - \beta_t, \quad \bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s")
        
        st.markdown("**é‡‡æ ·å…¬å¼**ï¼ˆé‡å‚æ•°åŒ–ï¼‰ï¼š")
        display_latex(r"x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)")
        
        st.subheader("3ï¸âƒ£ åå‘å»å™ªè¿‡ç¨‹ï¼ˆReverse Processï¼‰")
        st.markdown("ç›®æ ‡ï¼šå­¦ä¹ åå‘è½¬ç§»æ¦‚ç‡ $p_\\theta(x_{t-1} | x_t)$")
        
        display_latex(r"p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))")
        
        st.markdown("**å…³é”®æ´å¯Ÿ**ï¼šå½“ $\\beta_t$ è¶³å¤Ÿå°æ—¶ï¼Œåå‘è¿‡ç¨‹ä¹Ÿæ˜¯é«˜æ–¯åˆ†å¸ƒï¼")
        
        st.subheader("4ï¸âƒ£ è®­ç»ƒç›®æ ‡ï¼šå˜åˆ†ä¸‹ç•Œï¼ˆELBOï¼‰")
        st.markdown("ä¼˜åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶çš„å˜åˆ†ä¸‹ç•Œï¼š")
        
        display_latex(r"\mathcal{L} = \mathbb{E}_q \left[ -\log p_\theta(x_0) \right] \leq \mathcal{L}_{\text{VLB}}")
        
        st.markdown("**ç®€åŒ–ç›®æ ‡**ï¼ˆHo et al. 2020 DDPMï¼‰ï¼š")
        display_latex(r"\mathcal{L}_{\text{simple}} = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]")
        
        st.markdown("å³ï¼šè®­ç»ƒç¥ç»ç½‘ç»œ $\\epsilon_\\theta$ é¢„æµ‹æ·»åŠ çš„å™ªå£°ï¼")
        
        st.subheader("5ï¸âƒ£ åéªŒåˆ†å¸ƒæ¨å¯¼")
        st.markdown("çœŸå®çš„åéªŒåˆ†å¸ƒï¼ˆä½¿ç”¨è´å¶æ–¯å®šç†ï¼‰ï¼š")
        
        display_latex(r"q(x_{t-1} | x_t, x_0) = \mathcal{N}(x_{t-1}; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I)")
        
        st.markdown("å…¶ä¸­å‡å€¼ä¸ºï¼š")
        display_latex(r"\tilde{\mu}_t(x_t, x_0) = \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1-\bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} x_t")
        
        st.markdown("æ–¹å·®ä¸ºï¼š")
        display_latex(r"\tilde{\beta}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t")
        
        st.subheader("6ï¸âƒ£ é‡‡æ ·ç®—æ³•ï¼ˆDDPMï¼‰")
        st.code("""
# ä»çº¯å™ªå£°å¼€å§‹
x_T ~ N(0, I)

# é€æ­¥å»å™ª
for t = T, T-1, ..., 1:
    # é¢„æµ‹å™ªå£°
    Îµ_Î¸ = model(x_t, t)
    
    # è®¡ç®—å‡å€¼
    Î¼_Î¸ = 1/âˆšÎ±_t * (x_t - Î²_t/âˆš(1-á¾±_t) * Îµ_Î¸)
    
    # æ·»åŠ å™ªå£°ï¼ˆt>1æ—¶ï¼‰
    z ~ N(0, I) if t > 1 else 0
    x_{t-1} = Î¼_Î¸ + âˆšÎ²_t * z

return x_0
        """, language="python")
        
    else:
        st.header("Diffusion Models: Mathematical Foundations")
        # è‹±æ–‡ç‰ˆæœ¬
        st.subheader("Core Idea")
        st.markdown("""
        Diffusion models generate data through two processes:
        - **Forward Process**: Gradually add Gaussian noise until data becomes pure noise
        - **Reverse Process**: Train neural network to denoise and recover data
        """)
    
    # æ˜¾ç¤ºÎ²è°ƒåº¦
    st.subheader("ğŸ“Š Betaè°ƒåº¦å¯è§†åŒ–" if CHINESE_SUPPORTED else "ğŸ“Š Beta Schedule Visualization")
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=(
            'Î²_t (Noise Schedule)', 
            'Î±_t = 1 - Î²_t',
            'á¾±_t = âˆÎ±_s (Cumulative Product)',
            'âˆšá¾±_t and âˆš(1-á¾±_t)'
        )
    )
    
    t_range = np.arange(len(diffusion.betas))
    
    # Î²_t
    fig.add_trace(go.Scatter(x=t_range, y=diffusion.betas, name='Î²_t', 
                             line=dict(color='red')), row=1, col=1)
    
    # Î±_t
    fig.add_trace(go.Scatter(x=t_range, y=diffusion.alphas, name='Î±_t',
                             line=dict(color='blue')), row=1, col=2)
    
    # á¾±_t
    fig.add_trace(go.Scatter(x=t_range, y=diffusion.alphas_cumprod, name='á¾±_t',
                             line=dict(color='green')), row=2, col=1)
    
    # ä¿¡å·å’Œå™ªå£°æ¯”ä¾‹
    fig.add_trace(go.Scatter(x=t_range, y=diffusion.sqrt_alphas_cumprod, 
                             name='âˆšá¾±_t (signal)', line=dict(color='purple')), row=2, col=2)
    fig.add_trace(go.Scatter(x=t_range, y=diffusion.sqrt_one_minus_alphas_cumprod,
                             name='âˆš(1-á¾±_t) (noise)', line=dict(color='orange')), row=2, col=2)
    
    fig.update_xaxes(title_text="Time step t")
    fig.update_yaxes(title_text="Value")
    fig.update_layout(height=600, showlegend=True)
    
    st.plotly_chart(fig, use_container_width=True)
    
    # å…³é”®æ´å¯Ÿ
    if CHINESE_SUPPORTED:
        st.info("""
        **å…³é”®æ´å¯Ÿ**ï¼š
        - å½“ tâ†’T æ—¶ï¼Œâˆšá¾±_t â†’ 0ï¼Œâˆš(1-á¾±_t) â†’ 1ï¼Œæ•°æ®å®Œå…¨å˜æˆå™ªå£°
        - ä¸åŒçš„Î²è°ƒåº¦ç­–ç•¥å½±å“æ‰©æ•£é€Ÿåº¦
        - cosineè°ƒåº¦åœ¨æ—©æœŸä¿ç•™æ›´å¤šä¿¡æ¯ï¼ŒåæœŸæ›´æ¿€è¿›
        """)
    
    # æ•°å­¦è¯æ˜å±•å¼€
    with st.expander("ğŸ“– é‡å‚æ•°åŒ–å…¬å¼è¯æ˜" if CHINESE_SUPPORTED else "ğŸ“– Reparameterization Proof"):
        if CHINESE_SUPPORTED:
            st.markdown("**è¯æ˜**ï¼šä» $q(x_t | x_0)$ å¯ä»¥ç›´æ¥é‡‡æ ·")
            st.markdown("ä»é€’æ¨å…³ç³»å‡ºå‘ï¼š")
            display_latex(r"x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}")
            st.markdown("é€’å½’å±•å¼€ï¼š")
            display_latex(r"x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{\alpha_t(1-\alpha_{t-1})} \epsilon_{t-2} + \sqrt{1-\alpha_t} \epsilon_{t-1}")
            st.markdown("åˆ©ç”¨é«˜æ–¯åˆ†å¸ƒçš„æ€§è´¨ï¼Œä¸¤ä¸ªç‹¬ç«‹é«˜æ–¯å™ªå£°çš„å’Œä»æ˜¯é«˜æ–¯ï¼š")
            display_latex(r"\mathcal{N}(0, \sigma_1^2) + \mathcal{N}(0, \sigma_2^2) = \mathcal{N}(0, \sigma_1^2 + \sigma_2^2)")
            st.markdown("ç»§ç»­é€’å½’åˆ° $x_0$ï¼Œæœ€ç»ˆå¾—åˆ°ï¼š")
            display_latex(r"x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon")
            st.markdown("å…¶ä¸­ $\\epsilon \\sim \\mathcal{N}(0, I)$")
        else:
            st.markdown("Proof of direct sampling from q(x_t | x_0)")
    
    with st.expander("ğŸ“– åéªŒåˆ†å¸ƒæ¨å¯¼" if CHINESE_SUPPORTED else "ğŸ“– Posterior Derivation"):
        if CHINESE_SUPPORTED:
            st.markdown("**ç›®æ ‡**ï¼šè®¡ç®— $q(x_{t-1} | x_t, x_0)$")
            st.markdown("ä½¿ç”¨è´å¶æ–¯å®šç†ï¼š")
            display_latex(r"q(x_{t-1} | x_t, x_0) = \frac{q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0)}{q(x_t | x_0)}")
            st.markdown("ç”±é©¬å°”å¯å¤«æ€§è´¨ï¼Œ$q(x_t | x_{t-1}, x_0) = q(x_t | x_{t-1})$")
            st.markdown("ä»£å…¥é«˜æ–¯åˆ†å¸ƒå½¢å¼ï¼Œå®Œæˆé…æ–¹åå¾—åˆ°åéªŒå‡å€¼å’Œæ–¹å·®")
        else:
            st.markdown("Posterior q(x_{t-1} | x_t, x_0) derivation using Bayes' theorem")


def show_forward_process(CHINESE_SUPPORTED, diffusion, visualization_timesteps):
    """æ˜¾ç¤ºå‰å‘æ‰©æ•£è¿‡ç¨‹"""
    
    if CHINESE_SUPPORTED:
        st.header("å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼šé€æ­¥æ·»åŠ å™ªå£°")
        st.markdown("""
        å‰å‘è¿‡ç¨‹é€šè¿‡å…¬å¼ $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1-\\bar{\\alpha}_t} \\epsilon$ 
        å°†åŸå§‹å›¾åƒé€æ­¥è½¬åŒ–ä¸ºçº¯å™ªå£°ã€‚
        """)
    else:
        st.header("Forward Diffusion: Gradually Adding Noise")
    
    # é€‰æ‹©å›¾åƒç±»å‹
    image_type = st.selectbox(
        "é€‰æ‹©è¾“å…¥å›¾åƒ" if CHINESE_SUPPORTED else "Select Input Image",
        ["ç®€å•å›¾æ¡ˆ", "æ•°å­—å›¾æ¡ˆ", "æ¸å˜å›¾æ¡ˆ"] if CHINESE_SUPPORTED else 
        ["Simple Pattern", "Digit Pattern", "Gradient Pattern"]
    )
    
    # åˆ›å»ºåŸå§‹å›¾åƒ
    size = 64
    if "ç®€å•" in image_type or "Simple" in image_type:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„åœ†å½¢å›¾æ¡ˆ
        y, x = np.ogrid[:size, :size]
        center = size // 2
        radius = size // 4
        mask = (x - center)**2 + (y - center)**2 <= radius**2
        x_0 = mask.astype(float)
    elif "æ•°å­—" in image_type or "Digit" in image_type:
        # åˆ›å»ºæ•°å­—"8"çš„å›¾æ¡ˆ
        x_0 = np.zeros((size, size))
        # ä¸Šåœ†
        y, x = np.ogrid[:size, :size]
        center_y1, center_x = size // 3, size // 2
        radius = size // 6
        mask1 = (x - center_x)**2 + (y - center_y1)**2 <= radius**2
        # ä¸‹åœ†
        center_y2 = 2 * size // 3
        mask2 = (x - center_x)**2 + (y - center_y2)**2 <= radius**2
        x_0[mask1 | mask2] = 1.0
    else:
        # æ¸å˜å›¾æ¡ˆ
        x_0 = np.linspace(0, 1, size)
        x_0 = np.outer(x_0, x_0)
    
    # æ ‡å‡†åŒ–åˆ°[-1, 1]
    x_0 = (x_0 - 0.5) * 2
    
    # ç”Ÿæˆä¸åŒæ—¶é—´æ­¥çš„å™ªå£°å›¾åƒ
    if not visualization_timesteps:
        visualization_timesteps = [0, len(diffusion.betas)//4, len(diffusion.betas)//2, 
                                   3*len(diffusion.betas)//4, len(diffusion.betas)-1]
    
    num_vis = len(visualization_timesteps)
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=(num_vis + 1) // 2,
        subplot_titles=[f"t = {t}" for t in visualization_timesteps],
        vertical_spacing=0.15,
        horizontal_spacing=0.1
    )
    
    noisy_images = []
    for idx, t in enumerate(visualization_timesteps):
        # ç”Ÿæˆå™ªå£°å›¾åƒ
        noise = np.random.randn(*x_0.shape)
        x_t = diffusion.q_sample(x_0, np.array([t]), noise)
        noisy_images.append(x_t)
        
        row = idx // ((num_vis + 1) // 2) + 1
        col = idx % ((num_vis + 1) // 2) + 1
        
        fig.add_trace(
            go.Heatmap(z=x_t, colorscale='RdBu_r', zmid=0, 
                      showscale=(idx == num_vis - 1),
                      zmin=-3, zmax=3),
            row=row, col=col
        )
    
    fig.update_xaxes(showticklabels=False)
    fig.update_yaxes(showticklabels=False)
    fig.update_layout(height=400, title_text="ä¸åŒæ—¶é—´æ­¥çš„æ‰©æ•£ç»“æœ" if CHINESE_SUPPORTED else "Diffusion at Different Timesteps")
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ˜¾ç¤ºæ•°å€¼ç»Ÿè®¡
    if CHINESE_SUPPORTED:
        st.subheader("ğŸ“Š æ•°å€¼ç»Ÿè®¡")
        
        stats_data = []
        for idx, t in enumerate(visualization_timesteps):
            x_t = noisy_images[idx]
            signal_coef = diffusion.sqrt_alphas_cumprod[t]
            noise_coef = diffusion.sqrt_one_minus_alphas_cumprod[t]
            
            stats_data.append({
                "æ—¶é—´æ­¥ t": t,
                "âˆšá¾±_t (ä¿¡å·ç³»æ•°)": f"{signal_coef:.4f}",
                "âˆš(1-á¾±_t) (å™ªå£°ç³»æ•°)": f"{noise_coef:.4f}",
                "å›¾åƒå‡å€¼": f"{x_t.mean():.4f}",
                "å›¾åƒæ ‡å‡†å·®": f"{x_t.std():.4f}",
                "ä¿¡å™ªæ¯”": f"{signal_coef/noise_coef:.4f}" if noise_coef > 0.01 else "âˆ"
            })
        
        df = pd.DataFrame(stats_data)
        st.dataframe(df, use_container_width=True)
        
        st.info("""
        **è§‚å¯Ÿ**ï¼š
        - éšç€ t å¢å¤§ï¼Œä¿¡å·ç³»æ•° âˆšá¾±_t é€’å‡ï¼Œå™ªå£°ç³»æ•° âˆš(1-á¾±_t) é€’å¢
        - æœ€ç»ˆå›¾åƒå˜æˆæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼â‰ˆ0ï¼Œæ ‡å‡†å·®â‰ˆ1ï¼‰
        - ä¿¡å™ªæ¯”æŒç»­ä¸‹é™ï¼Œç›´åˆ°ä¿¡å·å®Œå…¨è¢«å™ªå£°æ·¹æ²¡
        """)
    
    # äº¤äº’å¼å•æ­¥æ¼”ç¤º
    with st.expander("ğŸ” å•æ­¥æ‰©æ•£è¯¦ç»†è¿‡ç¨‹" if CHINESE_SUPPORTED else "ğŸ” Single Step Detailed Process"):
        single_t = st.slider(
            "é€‰æ‹©æ—¶é—´æ­¥" if CHINESE_SUPPORTED else "Select Timestep",
            min_value=0,
            max_value=len(diffusion.betas) - 1,
            value=len(diffusion.betas) // 2
        )
        
        noise = np.random.randn(*x_0.shape)
        x_t = diffusion.q_sample(x_0, np.array([single_t]), noise)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**åŸå§‹å›¾åƒ** $x_0$")
            fig1 = go.Figure(data=go.Heatmap(z=x_0, colorscale='RdBu_r', zmid=0))
            fig1.update_layout(height=250, margin=dict(l=0, r=0, t=0, b=0))
            fig1.update_xaxes(showticklabels=False)
            fig1.update_yaxes(showticklabels=False)
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            st.markdown("**çº¯å™ªå£°** $\\epsilon$")
            fig2 = go.Figure(data=go.Heatmap(z=noise, colorscale='RdBu_r', zmid=0))
            fig2.update_layout(height=250, margin=dict(l=0, r=0, t=0, b=0))
            fig2.update_xaxes(showticklabels=False)
            fig2.update_yaxes(showticklabels=False)
            st.plotly_chart(fig2, use_container_width=True)
        
        with col3:
            st.markdown(f"**åŠ å™ªç»“æœ** $x_{{{single_t}}}$")
            fig3 = go.Figure(data=go.Heatmap(z=x_t, colorscale='RdBu_r', zmid=0))
            fig3.update_layout(height=250, margin=dict(l=0, r=0, t=0, b=0))
            fig3.update_xaxes(showticklabels=False)
            fig3.update_yaxes(showticklabels=False)
            st.plotly_chart(fig3, use_container_width=True)
        
        if CHINESE_SUPPORTED:
            st.markdown("**è®¡ç®—å…¬å¼**ï¼š")
            signal_coef = diffusion.sqrt_alphas_cumprod[single_t]
            noise_coef = diffusion.sqrt_one_minus_alphas_cumprod[single_t]
            st.latex(f"x_{{{single_t}}} = {signal_coef:.4f} \\cdot x_0 + {noise_coef:.4f} \\cdot \\epsilon")
            
            st.markdown(f"""
            - ä¿¡å·ä¿ç•™æ¯”ä¾‹ï¼š{signal_coef:.2%}
            - å™ªå£°æ·»åŠ æ¯”ä¾‹ï¼š{noise_coef:.2%}
            - Î²_{single_t} = {diffusion.betas[single_t]:.6f}
            - Î±_{single_t} = {diffusion.alphas[single_t]:.6f}
            - á¾±_{single_t} = {diffusion.alphas_cumprod[single_t]:.6f}
            """)


def show_reverse_process(CHINESE_SUPPORTED, diffusion, visualization_timesteps):
    """æ˜¾ç¤ºåå‘å»å™ªè¿‡ç¨‹"""
    
    if CHINESE_SUPPORTED:
        st.header("åå‘å»å™ªè¿‡ç¨‹ï¼šä»å™ªå£°æ¢å¤æ•°æ®")
        st.markdown("""
        åå‘è¿‡ç¨‹ä½¿ç”¨è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œ $\\epsilon_\\theta(x_t, t)$ é¢„æµ‹å™ªå£°ï¼Œ
        ç„¶åé€šè¿‡å…¬å¼é€æ­¥å»å™ªæ¢å¤åŸå§‹å›¾åƒã€‚
        """)
    else:
        st.header("Reverse Denoising: Recovering Data from Noise")
    
    st.info("""
    **æ³¨æ„**ï¼šå®Œæ•´è®­ç»ƒæ‰©æ•£æ¨¡å‹éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºã€‚è¿™é‡Œæˆ‘ä»¬æ¼”ç¤ºåå‘è¿‡ç¨‹çš„æ•°å­¦åŸç†ï¼Œ
    ä½¿ç”¨ç†æƒ³æƒ…å†µï¼ˆå·²çŸ¥çœŸå®å™ªå£°ï¼‰æ¥å±•ç¤ºå»å™ªè¿‡ç¨‹ã€‚
    """ if CHINESE_SUPPORTED else """
    **Note**: Training a full diffusion model requires substantial data and computation.
    Here we demonstrate the mathematical principles using the ideal case (known noise).
    """)
    
    # åˆ›å»ºåŸå§‹å›¾åƒ
    size = 64
    image_type = st.selectbox(
        "é€‰æ‹©ç›®æ ‡å›¾åƒ" if CHINESE_SUPPORTED else "Select Target Image",
        ["åœ†å½¢", "æ–¹å½¢", "ä¸‰è§’å½¢", "æ˜Ÿå½¢"] if CHINESE_SUPPORTED else 
        ["Circle", "Square", "Triangle", "Star"],
        key="reverse_image_type"
    )
    
    x_0 = np.zeros((size, size))
    y, x = np.ogrid[:size, :size]
    center = size // 2
    
    if "åœ†å½¢" in image_type or "Circle" in image_type:
        radius = size // 4
        mask = (x - center)**2 + (y - center)**2 <= radius**2
        x_0[mask] = 1.0
    elif "æ–¹å½¢" in image_type or "Square" in image_type:
        x_0[size//4:3*size//4, size//4:3*size//4] = 1.0
    elif "ä¸‰è§’å½¢" in image_type or "Triangle" in image_type:
        for i in range(size):
            for j in range(size):
                if i >= size//4 and i <= 3*size//4:
                    width = (i - size//4) * size // (2*size)
                    if abs(j - center) <= width:
                        x_0[i, j] = 1.0
    else:  # æ˜Ÿå½¢
        angles = np.linspace(0, 2*np.pi, 6)[:-1]
        for angle in angles:
            for r in np.linspace(0, size//4, 20):
                px = int(center + r * np.cos(angle))
                py = int(center + r * np.sin(angle))
                if 0 <= px < size and 0 <= py < size:
                    x_0[py, px] = 1.0
    
    x_0 = (x_0 - 0.5) * 2  # æ ‡å‡†åŒ–åˆ°[-1, 1]
    
    # é€‰æ‹©æ¼”ç¤ºç±»å‹
    demo_type = st.radio(
        "æ¼”ç¤ºç±»å‹" if CHINESE_SUPPORTED else "Demo Type",
        ["ç†æƒ³å»å™ªï¼ˆå·²çŸ¥çœŸå®å™ªå£°ï¼‰", "é€æ­¥å»å™ªè¿‡ç¨‹"] if CHINESE_SUPPORTED else
        ["Ideal Denoising (Known Noise)", "Step-by-Step Denoising"]
    )
    
    if "ç†æƒ³" in demo_type or "Ideal" in demo_type:
        # ç†æƒ³æƒ…å†µï¼šæˆ‘ä»¬çŸ¥é“çœŸå®å™ªå£°
        st.subheader("ç†æƒ³å»å™ªæ¼”ç¤º" if CHINESE_SUPPORTED else "Ideal Denoising Demo")
        
        # ç”ŸæˆåŠ å™ªå›¾åƒ
        t = st.slider(
            "å™ªå£°æ°´å¹³ (t)" if CHINESE_SUPPORTED else "Noise Level (t)",
            min_value=1,
            max_value=len(diffusion.betas) - 1,
            value=len(diffusion.betas) // 2,
            key="ideal_t"
        )
        
        noise = np.random.randn(*x_0.shape)
        x_t = diffusion.q_sample(x_0, np.array([t]), noise)
        
        # ä½¿ç”¨å·²çŸ¥å™ªå£°"å»å™ª"ï¼ˆç†æƒ³æƒ…å†µï¼‰
        alpha_cumprod_t = diffusion.alphas_cumprod[t]
        x_0_pred = (x_t - np.sqrt(1 - alpha_cumprod_t) * noise) / np.sqrt(alpha_cumprod_t)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**åŸå§‹å›¾åƒ** $x_0$")
            fig1 = go.Figure(data=go.Heatmap(z=x_0, colorscale='RdBu_r', zmid=0, zmin=-2, zmax=2))
            fig1.update_layout(height=250, margin=dict(l=0, r=0, t=30, b=0))
            fig1.update_xaxes(showticklabels=False)
            fig1.update_yaxes(showticklabels=False)
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            st.markdown(f"**åŠ å™ªå›¾åƒ** $x_{{{t}}}$")
            fig2 = go.Figure(data=go.Heatmap(z=x_t, colorscale='RdBu_r', zmid=0, zmin=-2, zmax=2))
            fig2.update_layout(height=250, margin=dict(l=0, r=0, t=30, b=0))
            fig2.update_xaxes(showticklabels=False)
            fig2.update_yaxes(showticklabels=False)
            st.plotly_chart(fig2, use_container_width=True)
        
        with col3:
            st.markdown("**æ¢å¤å›¾åƒ** $\\hat{x}_0$")
            fig3 = go.Figure(data=go.Heatmap(z=x_0_pred, colorscale='RdBu_r', zmid=0, zmin=-2, zmax=2))
            fig3.update_layout(height=250, margin=dict(l=0, r=0, t=30, b=0))
            fig3.update_xaxes(showticklabels=False)
            fig3.update_yaxes(showticklabels=False)
            st.plotly_chart(fig3, use_container_width=True)
        
        # è®¡ç®—è¯¯å·®
        mse = np.mean((x_0_pred - x_0)**2)
        if CHINESE_SUPPORTED:
            st.markdown(f"""
            **å»å™ªå…¬å¼**ï¼š
            $$\\hat{{x}}_0 = \\frac{{x_t - \\sqrt{{1-\\bar{{\\alpha}}_t}} \\cdot \\epsilon}}{{\\sqrt{{\\bar{{\\alpha}}_t}}}}$$
            
            **é‡å»ºè¯¯å·® (MSE)**: {mse:.6f}
            
            åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼ˆå·²çŸ¥çœŸå®å™ªå£°ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å‡ ä¹å®Œç¾åœ°æ¢å¤åŸå§‹å›¾åƒã€‚
            å®é™…åº”ç”¨ä¸­ï¼Œç¥ç»ç½‘ç»œéœ€è¦å­¦ä¹ é¢„æµ‹è¿™ä¸ªå™ªå£°ã€‚
            """)
    
    else:
        # é€æ­¥å»å™ªè¿‡ç¨‹
        st.subheader("é€æ­¥å»å™ªå¯è§†åŒ–" if CHINESE_SUPPORTED else "Step-by-Step Denoising")
        
        # ä»å®Œå…¨å™ªå£°å¼€å§‹
        num_steps = st.slider(
            "å»å™ªæ­¥æ•°" if CHINESE_SUPPORTED else "Denoising Steps",
            min_value=5, max_value=50, value=10, step=5
        )
        
        # ç”Ÿæˆå®Œå…¨å™ªå£°
        x_t = np.random.randn(*x_0.shape)
        
        # é€‰æ‹©æ—¶é—´æ­¥
        timesteps_to_show = np.linspace(len(diffusion.betas)-1, 0, num_steps).astype(int)
        
        # æ¨¡æ‹Ÿå»å™ªè¿‡ç¨‹ï¼ˆä½¿ç”¨å·²çŸ¥çš„x_0ï¼‰
        denoising_steps = []
        current_x = x_t.copy()
        
        for t in timesteps_to_show:
            # è®¡ç®—x_0çš„ä¼°è®¡ï¼ˆåœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™æ¥è‡ªç¥ç»ç½‘ç»œé¢„æµ‹çš„å™ªå£°ï¼‰
            if t > 0:
                # æ¨¡æ‹Ÿï¼šå‡è®¾æˆ‘ä»¬èƒ½é¢„æµ‹å™ªå£°
                noise_pred = (current_x - np.sqrt(diffusion.alphas_cumprod[t]) * x_0) / np.sqrt(1 - diffusion.alphas_cumprod[t])
                
                # è®¡ç®—x_{t-1}
                alpha_t = diffusion.alphas[t]
                alpha_cumprod_t = diffusion.alphas_cumprod[t]
                beta_t = diffusion.betas[t]
                
                x_0_pred = (current_x - np.sqrt(1 - alpha_cumprod_t) * noise_pred) / np.sqrt(alpha_cumprod_t)
                
                # åéªŒå‡å€¼
                posterior_mean = (
                    np.sqrt(diffusion.alphas_cumprod[t-1]) * beta_t / (1 - alpha_cumprod_t) * x_0_pred +
                    np.sqrt(alpha_t) * (1 - diffusion.alphas_cumprod[t-1]) / (1 - alpha_cumprod_t) * current_x
                )
                
                # æ·»åŠ å™ªå£°
                posterior_variance = diffusion.posterior_variance[t]
                noise = np.random.randn(*x_0.shape)
                current_x = posterior_mean + np.sqrt(posterior_variance) * noise
            else:
                current_x = (current_x - np.sqrt(1 - diffusion.alphas_cumprod[t]) * 
                           (current_x - np.sqrt(diffusion.alphas_cumprod[t]) * x_0) / 
                           np.sqrt(1 - diffusion.alphas_cumprod[t])) / np.sqrt(diffusion.alphas_cumprod[t])
            
            denoising_steps.append((t, current_x.copy()))
        
        # æ˜¾ç¤ºå»å™ªè¿‡ç¨‹
        num_vis = min(6, len(denoising_steps))
        indices = np.linspace(0, len(denoising_steps)-1, num_vis).astype(int)
        
        fig = make_subplots(
            rows=2, cols=3,
            subplot_titles=[f"t = {denoising_steps[i][0]}" for i in indices],
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )
        
        for idx, i in enumerate(indices):
            t, img = denoising_steps[i]
            row = idx // 3 + 1
            col = idx % 3 + 1
            
            fig.add_trace(
                go.Heatmap(z=img, colorscale='RdBu_r', zmid=0, 
                          showscale=(idx == num_vis - 1),
                          zmin=-2, zmax=2),
                row=row, col=col
            )
        
        fig.update_xaxes(showticklabels=False)
        fig.update_yaxes(showticklabels=False)
        fig.update_layout(height=500, title_text="å»å™ªè¿‡ç¨‹" if CHINESE_SUPPORTED else "Denoising Process")
        
        st.plotly_chart(fig, use_container_width=True)
        
        if CHINESE_SUPPORTED:
            st.info("""
            **è§‚å¯Ÿ**ï¼š
            - ä»çº¯å™ªå£°å¼€å§‹ï¼Œé€æ­¥å‡ºç°å›¾åƒç»“æ„
            - æ—©æœŸæ­¥éª¤ç¡®å®šå¤§è‡´è½®å»“ï¼ŒåæœŸæ­¥éª¤ç»†åŒ–ç»†èŠ‚
            - è¿™ä¸ªè¿‡ç¨‹æ¨¡æ‹Ÿäº†è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹
            """)


def show_image_generation(CHINESE_SUPPORTED, diffusion, timesteps):
    """æ˜¾ç¤ºå›¾åƒç”Ÿæˆæ¼”ç¤º"""
    
    if CHINESE_SUPPORTED:
        st.header("å›¾åƒç”Ÿæˆæ¼”ç¤º")
        st.markdown("""
        è¿™é‡Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒã€‚ç”±äºå®Œæ•´è®­ç»ƒéœ€è¦å¤§é‡èµ„æºï¼Œ
        æˆ‘ä»¬å±•ç¤ºé‡‡æ ·ç®—æ³•çš„å·¥ä½œåŸç†ï¼Œä»¥åŠä¸åŒé‡‡æ ·æ–¹æ³•çš„å¯¹æ¯”ã€‚
        """)
    else:
        st.header("Image Generation Demo")
    
    # é€‰æ‹©é‡‡æ ·æ–¹æ³•
    sampling_method = st.selectbox(
        "é‡‡æ ·æ–¹æ³•" if CHINESE_SUPPORTED else "Sampling Method",
        ["DDPM (æ ‡å‡†é‡‡æ ·)", "DDIM (åŠ é€Ÿé‡‡æ ·)", "å¯¹æ¯”å±•ç¤º"] if CHINESE_SUPPORTED else
        ["DDPM (Standard)", "DDIM (Accelerated)", "Comparison"]
    )
    
    if "å¯¹æ¯”" in sampling_method or "Comparison" in sampling_method:
        show_sampling_comparison(CHINESE_SUPPORTED, diffusion)
    else:
        show_single_sampling(CHINESE_SUPPORTED, diffusion, sampling_method)
    
    # ç®—æ³•è¯¦è§£
    with st.expander("ğŸ“– DDPM vs DDIM ç®—æ³•å¯¹æ¯”" if CHINESE_SUPPORTED else "ğŸ“– DDPM vs DDIM Algorithm Comparison"):
        if CHINESE_SUPPORTED:
            st.markdown("### DDPM (Denoising Diffusion Probabilistic Models)")
            st.markdown("""
            **ç‰¹ç‚¹**ï¼š
            - é©¬å°”å¯å¤«é‡‡æ ·è¿‡ç¨‹ï¼Œéœ€è¦éå†æ‰€æœ‰æ—¶é—´æ­¥
            - æ¯æ­¥æ·»åŠ éšæœºå™ªå£°ï¼Œç”Ÿæˆç»“æœå…·æœ‰éšæœºæ€§
            - é«˜è´¨é‡ä½†é€Ÿåº¦è¾ƒæ…¢ï¼ˆTæ­¥é‡‡æ ·ï¼‰
            """)
            
            st.markdown("**é‡‡æ ·å…¬å¼**ï¼š")
            display_latex(r"x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z")
            
            st.markdown("å…¶ä¸­ $z \\sim \\mathcal{N}(0, I)$ï¼Œ$\\sigma_t = \\sqrt{\\beta_t}$")
            
            st.markdown("---")
            
            st.markdown("### DDIM (Denoising Diffusion Implicit Models)")
            st.markdown("""
            **ç‰¹ç‚¹**ï¼š
            - éé©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œå¯ä»¥è·³è¿‡æ—¶é—´æ­¥
            - ç¡®å®šæ€§é‡‡æ ·ï¼ˆÎ·=0æ—¶ï¼‰ï¼Œç›¸åŒåˆå§‹å™ªå£°ç”Ÿæˆç›¸åŒç»“æœ
            - é€Ÿåº¦å¿«ï¼ˆå¯ç”¨10-50æ­¥ä»£æ›¿1000æ­¥ï¼‰
            """)
            
            st.markdown("**é‡‡æ ·å…¬å¼**ï¼š")
            display_latex(r"x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \left( \frac{x_t - \sqrt{1-\bar{\alpha}_t} \epsilon_\theta(x_t, t)}{\sqrt{\bar{\alpha}_t}} \right) + \sqrt{1-\bar{\alpha}_{t-1} - \sigma_t^2} \epsilon_\theta(x_t, t) + \sigma_t z")
            
            st.markdown("å…¶ä¸­ $\\sigma_t = \\eta \\sqrt{(1-\\bar{\\alpha}_{t-1})/(1-\\bar{\\alpha}_t)} \\sqrt{1-\\bar{\\alpha}_t/\\bar{\\alpha}_{t-1}}$")
            st.markdown("- $\\eta = 0$: å®Œå…¨ç¡®å®šæ€§")
            st.markdown("- $\\eta = 1$: ç­‰ä»·äºDDPM")
            
            st.markdown("---")
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**DDPMä¼˜åŠ¿**")
                st.markdown("- ç†è®ºä¿è¯å¼º")
                st.markdown("- æ ·æœ¬è´¨é‡é«˜")
                st.markdown("- å¤šæ ·æ€§å¥½")
            
            with col2:
                st.markdown("**DDIMä¼˜åŠ¿**")
                st.markdown("- é‡‡æ ·é€Ÿåº¦å¿«10-100å€")
                st.markdown("- å¯ç¡®å®šæ€§ç”Ÿæˆ")
                st.markdown("- æ”¯æŒæ’å€¼å’Œç¼–è¾‘")
        else:
            st.markdown("### DDPM (Denoising Diffusion Probabilistic Models)")
            st.markdown("- Markov sampling, slower but high quality")
            st.markdown("### DDIM (Denoising Diffusion Implicit Models)")
            st.markdown("- Non-Markov, 10-100x faster, deterministic option")
    
    # å®é™…åº”ç”¨
    with st.expander("ğŸŒŸ æ‰©æ•£æ¨¡å‹çš„å®é™…åº”ç”¨" if CHINESE_SUPPORTED else "ğŸŒŸ Real-world Applications"):
        if CHINESE_SUPPORTED:
            st.markdown("""
            ### å›¾åƒç”Ÿæˆ
            - **Stable Diffusion**: å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹
            - **DALL-E 2/3**: OpenAIçš„å›¾åƒç”Ÿæˆç³»ç»Ÿ
            - **Midjourney**: è‰ºæœ¯å›¾åƒç”Ÿæˆ
            - **Imagen**: Googleçš„é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆ
            
            ### å…¶ä»–åº”ç”¨
            - **è§†é¢‘ç”Ÿæˆ**: Runway Gen-2, Pika
            - **éŸ³é¢‘åˆæˆ**: DiffWave, WaveGrad
            - **3Dç”Ÿæˆ**: DreamFusion, Point-E
            - **å›¾åƒç¼–è¾‘**: InstructPix2Pix
            - **è¶…åˆ†è¾¨ç‡**: SR3, Imagen Video
            - **åŒ»å­¦å½±åƒ**: å»å™ªã€é‡å»ºã€åˆ†å‰²
            
            ### å…³é”®æŠ€æœ¯
            - **Classifier-Free Guidance**: æé«˜ç”Ÿæˆè´¨é‡å’Œå¯æ§æ€§
            - **Latent Diffusion**: åœ¨æ½œç©ºé—´æ“ä½œï¼Œé™ä½è®¡ç®—æˆæœ¬
            - **ControlNet**: ç²¾ç¡®æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹
            - **LoRA**: é«˜æ•ˆå¾®è°ƒ
            """)
        else:
            st.markdown("Applications: Stable Diffusion, DALL-E, Midjourney, video/audio generation, etc.")


def show_single_sampling(CHINESE_SUPPORTED, diffusion, method):
    """å•ä¸ªé‡‡æ ·æ–¹æ³•æ¼”ç¤º"""
    
    is_ddim = "DDIM" in method
    
    if CHINESE_SUPPORTED:
        st.subheader(f"{'DDIM' if is_ddim else 'DDPM'} é‡‡æ ·æ¼”ç¤º")
    else:
        st.subheader(f"{'DDIM' if is_ddim else 'DDPM'} Sampling Demo")
    
    # å‚æ•°è®¾ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        if is_ddim:
            num_inference_steps = st.slider(
                "æ¨ç†æ­¥æ•°" if CHINESE_SUPPORTED else "Inference Steps",
                min_value=10, max_value=100, value=50, step=10
            )
            eta = st.slider(
                "éšæœºæ€§å‚æ•° Î·" if CHINESE_SUPPORTED else "Stochasticity Î·",
                min_value=0.0, max_value=1.0, value=0.0, step=0.1
            )
        else:
            num_inference_steps = min(len(diffusion.betas), 200)
            eta = 1.0
    
    with col2:
        image_size = st.selectbox(
            "å›¾åƒå°ºå¯¸" if CHINESE_SUPPORTED else "Image Size",
            [32, 64],
            index=0
        )
    
    # ç”ŸæˆæŒ‰é’®
    if st.button("å¼€å§‹ç”Ÿæˆ" if CHINESE_SUPPORTED else "Generate", key=f"gen_{method}"):
        with st.spinner("ç”Ÿæˆä¸­..." if CHINESE_SUPPORTED else "Generating..."):
            # åˆ›å»ºç®€å•ç›®æ ‡å›¾åƒï¼ˆç”¨äºæ¼”ç¤ºï¼‰
            target_images = create_target_images(image_size)
            
            # é€‰æ‹©ä¸€ä¸ªç›®æ ‡
            target_idx = np.random.randint(0, len(target_images))
            x_0_target = target_images[target_idx]
            
            # ä»å™ªå£°å¼€å§‹
            x_t = np.random.randn(image_size, image_size)
            
            # é€‰æ‹©æ—¶é—´æ­¥
            if is_ddim:
                timesteps_to_use = np.linspace(len(diffusion.betas)-1, 0, num_inference_steps).astype(int)
            else:
                timesteps_to_use = np.arange(len(diffusion.betas)-1, -1, -1)[:num_inference_steps]
            
            # ç”Ÿæˆè¿‡ç¨‹
            generated_steps = []
            for i, t in enumerate(timesteps_to_use):
                if i % max(1, len(timesteps_to_use) // 10) == 0:
                    generated_steps.append((t, x_t.copy()))
                
                # æ¨¡æ‹Ÿå»å™ªï¼ˆä½¿ç”¨ç›®æ ‡å›¾åƒä½œä¸ºå‚è€ƒï¼‰
                if t > 0:
                    # é¢„æµ‹çš„å™ªå£°ï¼ˆç®€åŒ–ï¼šä½¿ç”¨å·²çŸ¥ä¿¡æ¯ï¼‰
                    noise_pred = (x_t - np.sqrt(diffusion.alphas_cumprod[t]) * x_0_target) / np.sqrt(1 - diffusion.alphas_cumprod[t] + 1e-8)
                    
                    if is_ddim:
                        # DDIMé‡‡æ ·
                        t_prev = timesteps_to_use[i+1] if i+1 < len(timesteps_to_use) else 0
                        alpha_t = diffusion.alphas_cumprod[t]
                        alpha_t_prev = diffusion.alphas_cumprod[t_prev] if t_prev > 0 else 1.0
                        
                        # é¢„æµ‹x_0
                        pred_x0 = (x_t - np.sqrt(1 - alpha_t) * noise_pred) / np.sqrt(alpha_t)
                        pred_x0 = np.clip(pred_x0, -2, 2)
                        
                        # æ–¹å‘æŒ‡å‘x_t
                        dir_xt = np.sqrt(1 - alpha_t_prev - eta**2 * (1 - alpha_t_prev) / (1 - alpha_t) * (1 - alpha_t / alpha_t_prev)) * noise_pred
                        
                        # éšæœºé¡¹
                        sigma = eta * np.sqrt((1 - alpha_t_prev) / (1 - alpha_t)) * np.sqrt(1 - alpha_t / alpha_t_prev)
                        noise = np.random.randn(*x_t.shape) if eta > 0 else 0
                        
                        x_t = np.sqrt(alpha_t_prev) * pred_x0 + dir_xt + sigma * noise
                    else:
                        # DDPMé‡‡æ ·
                        alpha_t = diffusion.alphas[t]
                        alpha_cumprod_t = diffusion.alphas_cumprod[t]
                        beta_t = diffusion.betas[t]
                        
                        pred_x0 = (x_t - np.sqrt(1 - alpha_cumprod_t) * noise_pred) / np.sqrt(alpha_cumprod_t)
                        pred_x0 = np.clip(pred_x0, -2, 2)
                        
                        # åéªŒå‡å€¼
                        alpha_cumprod_prev = diffusion.alphas_cumprod[t-1] if t > 0 else 1.0
                        posterior_mean = (
                            np.sqrt(alpha_cumprod_prev) * beta_t / (1 - alpha_cumprod_t) * pred_x0 +
                            np.sqrt(alpha_t) * (1 - alpha_cumprod_prev) / (1 - alpha_cumprod_t) * x_t
                        )
                        
                        posterior_variance = diffusion.posterior_variance[t]
                        noise = np.random.randn(*x_t.shape)
                        x_t = posterior_mean + np.sqrt(posterior_variance) * noise
                else:
                    # æœ€åä¸€æ­¥
                    pred_x0 = (x_t - np.sqrt(1 - diffusion.alphas_cumprod[0]) * noise_pred) / np.sqrt(diffusion.alphas_cumprod[0])
                    x_t = np.clip(pred_x0, -2, 2)
            
            # æ˜¾ç¤ºç»“æœ
            st.success("ç”Ÿæˆå®Œæˆï¼" if CHINESE_SUPPORTED else "Generation Complete!")
            
            # æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹
            num_vis = min(6, len(generated_steps))
            indices = np.linspace(0, len(generated_steps)-1, num_vis).astype(int)
            
            fig = make_subplots(
                rows=2, cols=3,
                subplot_titles=[f"t = {generated_steps[i][0]}" for i in indices],
                vertical_spacing=0.15,
                horizontal_spacing=0.1
            )
            
            for idx, i in enumerate(indices):
                t, img = generated_steps[i]
                row = idx // 3 + 1
                col = idx % 3 + 1
                
                fig.add_trace(
                    go.Heatmap(z=img, colorscale='RdBu_r', zmid=0, 
                              showscale=(idx == num_vis - 1),
                              zmin=-2, zmax=2),
                    row=row, col=col
                )
            
            fig.update_xaxes(showticklabels=False)
            fig.update_yaxes(showticklabels=False)
            fig.update_layout(height=500, title_text="ç”Ÿæˆè¿‡ç¨‹" if CHINESE_SUPPORTED else "Generation Process")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æœ€ç»ˆç»“æœ
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ç›®æ ‡å›¾åƒ**" if CHINESE_SUPPORTED else "**Target Image**")
                fig_target = go.Figure(data=go.Heatmap(z=x_0_target, colorscale='RdBu_r', zmid=0))
                fig_target.update_layout(height=300, margin=dict(l=0, r=0, t=0, b=0))
                fig_target.update_xaxes(showticklabels=False)
                fig_target.update_yaxes(showticklabels=False)
                st.plotly_chart(fig_target, use_container_width=True)
            
            with col2:
                st.markdown("**ç”Ÿæˆç»“æœ**" if CHINESE_SUPPORTED else "**Generated Image**")
                fig_gen = go.Figure(data=go.Heatmap(z=x_t, colorscale='RdBu_r', zmid=0))
                fig_gen.update_layout(height=300, margin=dict(l=0, r=0, t=0, b=0))
                fig_gen.update_xaxes(showticklabels=False)
                fig_gen.update_yaxes(showticklabels=False)
                st.plotly_chart(fig_gen, use_container_width=True)


def show_sampling_comparison(CHINESE_SUPPORTED, diffusion):
    """å¯¹æ¯”ä¸åŒé‡‡æ ·æ–¹æ³•"""
    if CHINESE_SUPPORTED:
        st.subheader("DDPM vs DDIM é‡‡æ ·å¯¹æ¯”")
        st.markdown("ç›´è§‚æ¯”è¾ƒä¸¤ç§é‡‡æ ·æ–¹æ³•çš„é€Ÿåº¦å’Œè´¨é‡å·®å¼‚")
    else:
        st.subheader("DDPM vs DDIM Comparison")
    
    # å‚æ•°
    ddim_steps = st.slider(
        "DDIMæ­¥æ•°" if CHINESE_SUPPORTED else "DDIM Steps",
        min_value=10, max_value=100, value=20, step=10
    )
    
    ddpm_steps = st.slider(
        "DDPMæ­¥æ•°" if CHINESE_SUPPORTED else "DDPM Steps",
        min_value=50, max_value=200, value=100, step=25
    )
    
    # å¯¹æ¯”è¡¨æ ¼
    if CHINESE_SUPPORTED:
        comparison_data = {
            "ç‰¹æ€§": ["é‡‡æ ·æ­¥æ•°", "æ˜¯å¦éšæœº", "é‡‡æ ·é€Ÿåº¦", "æ ·æœ¬è´¨é‡", "å¯æ§æ€§"],
            "DDPM": [f"{ddpm_steps}æ­¥", "æ˜¯", "æ…¢", "é«˜", "ä¸­ç­‰"],
            "DDIM": [f"{ddim_steps}æ­¥", "å¯é€‰", "å¿«", "é«˜", "å¼º"]
        }
    else:
        comparison_data = {
            "Feature": ["Steps", "Stochastic", "Speed", "Quality", "Control"],
            "DDPM": [f"{ddpm_steps}", "Yes", "Slow", "High", "Medium"],
            "DDIM": [f"{ddim_steps}", "Optional", "Fast", "High", "Strong"]
        }
    
    df_comp = pd.DataFrame(comparison_data)
    st.dataframe(df_comp, use_container_width=True)
    
    if CHINESE_SUPPORTED:
        st.info(f"""
        **é€Ÿåº¦æå‡**: DDIMä½¿ç”¨{ddim_steps}æ­¥ vs DDPMä½¿ç”¨{ddpm_steps}æ­¥
        - ç†è®ºåŠ é€Ÿæ¯”: {ddpm_steps/ddim_steps:.1f}x
        - å®é™…åº”ç”¨ä¸­ï¼ŒDDIMå¯ä»¥ç”¨50æ­¥è¾¾åˆ°DDPM 1000æ­¥çš„è´¨é‡
        - Stable Diffusioné»˜è®¤ä½¿ç”¨DDIMçš„å˜ä½“ï¼ˆDPM-Solverï¼‰
        """)


def create_target_images(size):
    """åˆ›å»ºä¸€äº›ç›®æ ‡å›¾åƒç”¨äºæ¼”ç¤º"""
    images = []
    
    # åœ†å½¢
    y, x = np.ogrid[:size, :size]
    center = size // 2
    radius = size // 4
    mask = (x - center)**2 + (y - center)**2 <= radius**2
    img = np.zeros((size, size))
    img[mask] = 1.0
    images.append((img - 0.5) * 2)
    
    # æ–¹å½¢
    img = np.zeros((size, size))
    img[size//4:3*size//4, size//4:3*size//4] = 1.0
    images.append((img - 0.5) * 2)
    
    # åå­—
    img = np.zeros((size, size))
    img[size//2-2:size//2+2, :] = 1.0
    img[:, size//2-2:size//2+2] = 1.0
    images.append((img - 0.5) * 2)
    
    return images


def show_2d_visualization(CHINESE_SUPPORTED, diffusion, visualization_timesteps):
    """æ˜¾ç¤º2Dæ•°æ®æ‰©æ•£å¯è§†åŒ–"""
    
    if CHINESE_SUPPORTED:
        st.header("2Dæ•°æ®åˆ†å¸ƒçš„æ‰©æ•£è¿‡ç¨‹")
        st.markdown("""
        ä½¿ç”¨2Dæ•°æ®å¯è§†åŒ–æ‰©æ•£è¿‡ç¨‹æ›´åŠ ç›´è§‚ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®åˆ†å¸ƒå¦‚ä½•ä»å¤æ‚çš„ç»“æ„
        é€æ¸å˜æˆç®€å•çš„é«˜æ–¯åˆ†å¸ƒï¼Œä»¥åŠåå‘è¿‡ç¨‹å¦‚ä½•æ¢å¤åŸå§‹åˆ†å¸ƒã€‚
        """)
    else:
        st.header("Diffusion Process on 2D Data Distributions")
    
    # é€‰æ‹©æ•°æ®åˆ†å¸ƒç±»å‹
    data_type = st.selectbox(
        "é€‰æ‹©æ•°æ®åˆ†å¸ƒ" if CHINESE_SUPPORTED else "Select Data Distribution",
        ["Swiss Roll (ç‘å£«å·)", "Two Moons (åŒæœˆ)", "Concentric Circles (åŒå¿ƒåœ†)", 
         "Gaussian Mixture (é«˜æ–¯æ··åˆ)"] if CHINESE_SUPPORTED else
        ["Swiss Roll", "Two Moons", "Concentric Circles", "Gaussian Mixture"]
    )
    
    n_samples = st.slider(
        "æ ·æœ¬æ•°é‡" if CHINESE_SUPPORTED else "Number of Samples",
        min_value=200, max_value=2000, value=500, step=100
    )
    
    # ç”Ÿæˆæ•°æ®
    if "Swiss Roll" in data_type or "ç‘å£«å·" in data_type:
        theta = np.sqrt(np.random.rand(n_samples)) * 3 * np.pi
        r = 2 * theta + np.random.randn(n_samples) * 0.1
        x = r * np.cos(theta)
        y = r * np.sin(theta)
        data = np.stack([x, y], axis=1)
    elif "Two Moons" in data_type or "åŒæœˆ" in data_type:
        from sklearn.datasets import make_moons
        data, _ = make_moons(n_samples=n_samples, noise=0.05)
        data = data * 2
    elif "Concentric" in data_type or "åŒå¿ƒåœ†" in data_type:
        # ä¸¤ä¸ªåŒå¿ƒåœ†
        n_per_circle = n_samples // 2
        theta1 = np.random.rand(n_per_circle) * 2 * np.pi
        r1 = 1 + np.random.randn(n_per_circle) * 0.1
        x1 = r1 * np.cos(theta1)
        y1 = r1 * np.sin(theta1)
        
        theta2 = np.random.rand(n_samples - n_per_circle) * 2 * np.pi
        r2 = 2.5 + np.random.randn(n_samples - n_per_circle) * 0.1
        x2 = r2 * np.cos(theta2)
        y2 = r2 * np.sin(theta2)
        
        data = np.stack([np.concatenate([x1, x2]), np.concatenate([y1, y2])], axis=1)
    else:
        # é«˜æ–¯æ··åˆ
        centers = [[-2, -2], [2, 2], [-2, 2], [2, -2]]
        n_per_center = n_samples // len(centers)
        data_list = []
        for center in centers:
            samples = np.random.randn(n_per_center, 2) * 0.3 + center
            data_list.append(samples)
        data = np.vstack(data_list)
    
    # æ ‡å‡†åŒ–
    data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)
    
    # é€‰æ‹©å¯è§†åŒ–æ—¶é—´æ­¥
    if not visualization_timesteps:
        visualization_timesteps = [0, len(diffusion.betas)//4, len(diffusion.betas)//2, 
                                   3*len(diffusion.betas)//4, len(diffusion.betas)-1]
    
    # ç”Ÿæˆä¸åŒæ—¶é—´æ­¥çš„æ‰©æ•£æ•°æ®
    diffused_data = {}
    for t in visualization_timesteps:
        noise = np.random.randn(*data.shape)
        x_t = diffusion.q_sample(data, np.array([t] * len(data)), noise)
        diffused_data[t] = x_t
    
    # å¯è§†åŒ–
    num_vis = len(visualization_timesteps)
    cols_per_row = 3
    rows = (num_vis + cols_per_row - 1) // cols_per_row
    
    fig = make_subplots(
        rows=rows, cols=cols_per_row,
        subplot_titles=[f"t = {t}" for t in visualization_timesteps],
        vertical_spacing=0.12,
        horizontal_spacing=0.08
    )
    
    for idx, t in enumerate(visualization_timesteps):
        row = idx // cols_per_row + 1
        col = idx % cols_per_row + 1
        
        x_t = diffused_data[t]
        
        fig.add_trace(
            go.Scatter(
                x=x_t[:, 0], y=x_t[:, 1],
                mode='markers',
                marker=dict(size=3, color=t, colorscale='Viridis', 
                           showscale=(idx == num_vis - 1)),
                showlegend=False
            ),
            row=row, col=col
        )
        
        # è®¾ç½®ç›¸åŒçš„åæ ‡èŒƒå›´
        fig.update_xaxes(range=[-4, 4], row=row, col=col)
        fig.update_yaxes(range=[-4, 4], row=row, col=col)
    
    fig.update_layout(height=300 * rows, title_text="2Dæ•°æ®çš„æ‰©æ•£è¿‡ç¨‹" if CHINESE_SUPPORTED else "Diffusion Process on 2D Data")
    st.plotly_chart(fig, use_container_width=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    if CHINESE_SUPPORTED:
        st.subheader("ğŸ“Š åˆ†å¸ƒç»Ÿè®¡")
        
        stats = []
        for t in visualization_timesteps:
            x_t = diffused_data[t]
            stats.append({
                "æ—¶é—´æ­¥ t": t,
                "å‡å€¼ (x)": f"{x_t[:, 0].mean():.4f}",
                "å‡å€¼ (y)": f"{x_t[:, 1].mean():.4f}",
                "æ ‡å‡†å·® (x)": f"{x_t[:, 0].std():.4f}",
                "æ ‡å‡†å·® (y)": f"{x_t[:, 1].std():.4f}",
                "ç›¸å…³ç³»æ•°": f"{np.corrcoef(x_t[:, 0], x_t[:, 1])[0, 1]:.4f}"
            })
        
        df = pd.DataFrame(stats)
        st.dataframe(df, use_container_width=True)
        
        st.info("""
        **å…³é”®è§‚å¯Ÿ**ï¼š
        - åŸå§‹æ•°æ®å¯èƒ½æœ‰å¤æ‚çš„ç»“æ„å’Œç›¸å…³æ€§
        - éšç€æ‰©æ•£è¿›è¡Œï¼Œæ•°æ®é€æ¸å¤±å»ç»“æ„ï¼Œå˜æˆå„å‘åŒæ€§çš„é«˜æ–¯åˆ†å¸ƒ
        - æœ€ç»ˆçŠ¶æ€ï¼šå‡å€¼â‰ˆ0ï¼Œæ ‡å‡†å·®â‰ˆ1ï¼Œå„ç»´åº¦ç‹¬ç«‹ï¼ˆç›¸å…³ç³»æ•°â‰ˆ0ï¼‰
        - è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‰©æ•£æ¨¡å‹èƒ½ä»ç®€å•çš„é«˜æ–¯å™ªå£°ç”Ÿæˆå¤æ‚æ•°æ®ï¼
        """)
    
    # åŠ¨ç”»æ¼”ç¤º
    with st.expander("ğŸ¬ åŠ¨ç”»æ¼”ç¤º" if CHINESE_SUPPORTED else "ğŸ¬ Animation Demo"):
        if st.button("ç”Ÿæˆæ‰©æ•£åŠ¨ç”»" if CHINESE_SUPPORTED else "Generate Diffusion Animation"):
            # åˆ›å»ºæ›´å¤šæ—¶é—´æ­¥ç”¨äºåŠ¨ç”»
            animation_steps = 20
            animation_timesteps = np.linspace(0, len(diffusion.betas)-1, animation_steps).astype(int)
            
            frames = []
            for t in animation_timesteps:
                noise = np.random.randn(*data.shape)
                x_t = diffusion.q_sample(data, np.array([t] * len(data)), noise)
                
                frames.append(
                    go.Frame(
                        data=[go.Scatter(x=x_t[:, 0], y=x_t[:, 1], mode='markers',
                                       marker=dict(size=3, color='blue'))],
                        name=str(t)
                    )
                )
            
            # åˆå§‹å¸§
            fig_anim = go.Figure(
                data=[go.Scatter(x=data[:, 0], y=data[:, 1], mode='markers',
                               marker=dict(size=3, color='blue'))],
                layout=go.Layout(
                    title="æ‰©æ•£è¿‡ç¨‹åŠ¨ç”»" if CHINESE_SUPPORTED else "Diffusion Animation",
                    xaxis=dict(range=[-4, 4], autorange=False),
                    yaxis=dict(range=[-4, 4], autorange=False),
                    updatemenus=[dict(
                        type="buttons",
                        buttons=[dict(label="æ’­æ”¾", method="animate",
                                    args=[None, {"frame": {"duration": 100}}])]
                    )]
                ),
                frames=frames
            )
            
            st.plotly_chart(fig_anim, use_container_width=True)
    
    # Scoreå‡½æ•°å¯è§†åŒ–
    with st.expander("ğŸ“ Scoreå‡½æ•°ï¼ˆæ¢¯åº¦åœºï¼‰" if CHINESE_SUPPORTED else "ğŸ“ Score Function (Gradient Field)"):
        if CHINESE_SUPPORTED:
            st.markdown("""
            Scoreå‡½æ•° $\\nabla_x \\log p(x)$ æŒ‡å‘æ•°æ®å¯†åº¦å¢åŠ çš„æ–¹å‘ã€‚
            æ‰©æ•£æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯åœ¨å­¦ä¹ è¿™ä¸ªscoreå‡½æ•°ã€‚
            """)
        
        # é€‰æ‹©ä¸€ä¸ªæ—¶é—´æ­¥
        score_t = st.slider(
            "æ—¶é—´æ­¥" if CHINESE_SUPPORTED else "Timestep",
            min_value=0,
            max_value=len(diffusion.betas) - 1,
            value=len(diffusion.betas) // 4,
            key="score_t"
        )
        
        # ç”Ÿæˆè¯¥æ—¶é—´æ­¥çš„æ•°æ®
        noise = np.random.randn(*data.shape)
        x_t = diffusion.q_sample(data, np.array([score_t] * len(data)), noise)
        
        # åˆ›å»ºç½‘æ ¼
        grid_size = 20
        x_grid = np.linspace(-3, 3, grid_size)
        y_grid = np.linspace(-3, 3, grid_size)
        X, Y = np.meshgrid(x_grid, y_grid)
        
        # ç®€åŒ–çš„scoreä¼°è®¡ï¼ˆä½¿ç”¨KDEï¼‰
        from scipy.stats import gaussian_kde
        kde = gaussian_kde(x_t.T)
        
        # è®¡ç®—æ¢¯åº¦ï¼ˆæ•°å€¼æ–¹æ³•ï¼‰
        delta = 0.1
        U = np.zeros_like(X)
        V = np.zeros_like(Y)
        
        for i in range(grid_size):
            for j in range(grid_size):
                x, y = X[i, j], Y[i, j]
                
                # æ•°å€¼æ¢¯åº¦
                grad_x = (kde([x + delta, y]) - kde([x - delta, y])) / (2 * delta)
                grad_y = (kde([x, y + delta]) - kde([x, y - delta])) / (2 * delta)
                
                U[i, j] = grad_x[0]
                V[i, j] = grad_y[0]
        
        # ç»˜åˆ¶
        fig_score = go.Figure()
        
        # æ•°æ®ç‚¹
        fig_score.add_trace(go.Scatter(
            x=x_t[:, 0], y=x_t[:, 1],
            mode='markers',
            marker=dict(size=2, color='lightblue', opacity=0.5),
            name='Data'
        ))
        
        # æ¢¯åº¦åœºï¼ˆæŠ½æ ·æ˜¾ç¤ºï¼‰
        step = 2
        fig_score.add_trace(go.Scatter(
            x=X[::step, ::step].flatten(),
            y=Y[::step, ::step].flatten(),
            mode='markers',
            marker=dict(size=8, color='red', symbol='arrow', angle=np.arctan2(V[::step, ::step], U[::step, ::step]).flatten() * 180 / np.pi),
            name='Score',
            showlegend=False
        ))
        
        fig_score.update_layout(
            title=f"Scoreå‡½æ•° at t={score_t}" if CHINESE_SUPPORTED else f"Score Function at t={score_t}",
            xaxis=dict(range=[-3, 3]),
            yaxis=dict(range=[-3, 3]),
            height=500
        )
        
        st.plotly_chart(fig_score, use_container_width=True)
        
        if CHINESE_SUPPORTED:
            st.info("""
            **Score-Basedæ¨¡å‹è§‚ç‚¹**ï¼š
            - æ‰©æ•£æ¨¡å‹å¯ä»¥çœ‹ä½œæ˜¯åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹å­¦ä¹ scoreå‡½æ•°
            - ScoreæŒ‡å‘å¯†åº¦é«˜çš„åŒºåŸŸï¼Œéµå¾ªè¿™ä¸ªåœºå¯ä»¥ä»å™ªå£°é‡‡æ ·åˆ°æ•°æ®
            - è¿™ä¸LangevinåŠ¨åŠ›å­¦é‡‡æ ·ç›¸å…³
            """)
