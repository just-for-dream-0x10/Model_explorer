"""
GNNå›¾ç¥ç»ç½‘ç»œæ•°å­¦åŸç†æ¨¡å—

v2.2.0 æ–°å¢ï¼š
- æ•°å€¼ç¨³å®šæ€§è‡ªåŠ¨æ£€æµ‹
- è¿‡å¹³æ»‘(over-smoothing)æ£€æµ‹
- èŠ‚ç‚¹ç‰¹å¾èŒƒæ•°æ£€æµ‹
- é‚»æ¥çŸ©é˜µè°±åˆ†æ
"""

import streamlit as st
import numpy as np
import torch
import torch.nn.functional as F
import pandas as pd
import networkx as nx
import plotly.graph_objects as go
import plotly.express as px
from simple_latex import display_latex
from utils.numerical_stability_checker import StabilityChecker

from utils.visualization import ChartBuilder
from utils.exceptions import ComputationError


def gnn_tab(CHINESE_SUPPORTED):
    """GNNæ ‡ç­¾é¡µå†…å®¹"""

    # å®šä¹‰é»˜è®¤å‚æ•°
    # ä½¿ç”¨åŠ¨æ€ç¤ºä¾‹ç”Ÿæˆå™¨
    from utils.example_generator import get_dynamic_example

    try:
        example = get_dynamic_example("gnn")
        num_nodes = example["num_nodes"]
        feature_dim = example["feature_dim"]
    except Exception as e:
        # å¦‚æœåŠ¨æ€ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        num_nodes = 8
        feature_dim = 3

    # ä½¿ç”¨åŠ¨æ€å‚æ•°å»ºè®®å™¨
    from utils.parameter_suggester import get_suggested_params

    try:
        suggested_params = get_suggested_params(
            "gnn",
            num_nodes=num_nodes,
            feature_dim=feature_dim,
            task_complexity="medium",
        )
        num_layers = suggested_params["num_layers"]
        hidden_dims = suggested_params["hidden_dims"]
        dropout = suggested_params["dropout"]
        learning_rate = suggested_params["learning_rate"]
    except Exception as e:
        # å¦‚æœåŠ¨æ€å»ºè®®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        num_layers = 2
        hidden_dims = [feature_dim * 4, feature_dim * 8]
        dropout = 0.5
        learning_rate = 0.001

    st.header("ğŸ•¸ï¸ GNNå›¾ç¥ç»ç½‘ç»œæ•°å­¦åŸç†")

    # åˆå§‹åŒ–å›¾è¡¨å·¥å…·
    chart_builder = ChartBuilder()

    display_latex("H^{(l+1)} = \\sigma(\\tilde{A} H^{(l)} W^{(l)})")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("#### ç¬¦å·è¯´æ˜")
        st.markdown("- Ãƒ: å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µ")
        st.markdown("- $H_l$: ç¬¬lå±‚çš„èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ")
        st.markdown("- $W_l$: ç¬¬lå±‚çš„æƒé‡çŸ©é˜µ")
        st.markdown("- $\\sigma$: æ¿€æ´»å‡½æ•°")

        # åˆ›å»ºç¤ºä¾‹å›¾
        G = nx.erdos_renyi_graph(num_nodes, 0.4, seed=42)
        pos = nx.spring_layout(G, seed=42)

        # éšæœºåˆ†é…èŠ‚ç‚¹æ ‡ç­¾ç”¨äºå¯è§†åŒ–
        node_labels = np.random.randint(0, 4, num_nodes)

        # å¯è§†åŒ–å›¾ç»“æ„
        edge_x = []
        edge_y = []
        for edge in G.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])

        edge_trace = go.Scatter(
            x=edge_x,
            y=edge_y,
            line=dict(width=2, color="#888"),
            hoverinfo="none",
            mode="lines",
        )

        node_x = []
        node_y = []
        node_text = []
        node_color = []
        colors = ["lightblue", "lightgreen", "lightcoral", "lightyellow"]

        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            node_text.append(str(node))
            node_color.append(colors[node_labels[node] % len(colors)])

        node_trace = go.Scatter(
            x=node_x,
            y=node_y,
            mode="markers+text",
            hoverinfo="text",
            text=node_text,
            textposition="middle center",
            marker=dict(
                showscale=True,
                colorscale="YlGnBu",
                size=20,
                color=node_color,
                line_width=2,
            ),
        )

        fig = go.Figure(
            data=[edge_trace, node_trace],
            layout=go.Layout(
                title=dict(
                    text=(
                        "å›¾ç»“æ„ä¸çœŸå®æ ‡ç­¾"
                        if CHINESE_SUPPORTED
                        else "Graph Structure and True Labels"
                    ),
                    font=dict(size=16),
                ),
                showlegend=False,
                hovermode="closest",
                margin=dict(b=20, l=5, r=5, t=40),
                annotations=[
                    dict(
                        text="",
                        showarrow=False,
                        xref="paper",
                        yref="paper",
                        x=0.005,
                        y=-0.002,
                        xanchor="left",
                        yanchor="bottom",
                        font=dict(color="#888", size=12),
                    )
                ],
                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                height=500,
            ),
        )
        st.plotly_chart(fig, width="stretch")

        # é‚»æ¥çŸ©é˜µ
        A = nx.adjacency_matrix(G).todense()
        st.markdown("### é‚»æ¥çŸ©é˜µ A")
        st.dataframe(
            pd.DataFrame(
                A,
                index=[f"Node {i}" for i in range(num_nodes)],
                columns=[f"Node {i}" for i in range(num_nodes)],
            )
        )

    with col2:
        st.markdown("### å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µè®¡ç®—")

        # æ·»åŠ è‡ªç¯
        A_tilde = A + np.eye(num_nodes)
        st.markdown("#### æ­¥éª¤1: æ·»åŠ è‡ªç¯ Ãƒ = A + I")
        st.dataframe(
            pd.DataFrame(
                A_tilde,
                index=[f"Node {i}" for i in range(num_nodes)],
                columns=[f"Node {i}" for i in range(num_nodes)],
            )
        )

        # è®¡ç®—åº¦çŸ©é˜µ
        D_tilde = np.diag(np.sum(A_tilde, axis=1))
        st.markdown("#### æ­¥éª¤2: åº¦çŸ©é˜µ DÌƒ")
        st.dataframe(
            pd.DataFrame(
                D_tilde,
                index=[f"Node {i}" for i in range(num_nodes)],
                columns=[f"Node {i}" for i in range(num_nodes)],
            )
        )

        # å½’ä¸€åŒ–
        try:
            D_tilde_inv_sqrt = np.linalg.inv(np.sqrt(D_tilde))
            A_hat = D_tilde_inv_sqrt @ A_tilde @ D_tilde_inv_sqrt
        except np.linalg.LinAlgError as e:
            # å¤„ç†å¥‡å¼‚çŸ©é˜µæƒ…å†µ
            try:
                D_tilde_sqrt = np.sqrt(D_tilde)
                D_tilde_inv_sqrt = np.zeros_like(D_tilde_sqrt)
                non_zero_mask = D_tilde_sqrt > 1e-10
                D_tilde_inv_sqrt[non_zero_mask] = 1.0 / D_tilde_sqrt[non_zero_mask]
                A_hat = D_tilde_inv_sqrt @ A_tilde @ D_tilde_inv_sqrt
            except Exception as calc_error:
                raise ComputationError(
                    operation="å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µå½’ä¸€åŒ–",
                    error_details=f"å¥‡å¼‚çŸ©é˜µå¤„ç†å¤±è´¥: {str(calc_error)}",
                ) from e

        st.markdown(
            "#### æ­¥éª¤3: å¯¹ç§°å½’ä¸€åŒ– $ \\tilde{A} = \\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} $"
        )
        st.dataframe(
            pd.DataFrame(
                A_hat.round(3),
                index=[f"Node {i}" for i in range(num_nodes)],
                columns=[f"Node {i}" for i in range(num_nodes)],
            )
        )

    # æ¶ˆæ¯ä¼ é€’å¯è§†åŒ–
    st.markdown("---")
    st.markdown("### ğŸ”— æ¶ˆæ¯ä¼ é€’æœºåˆ¶")

    # ä½¿ç”¨åŠ¨æ€ç¤ºä¾‹ç”Ÿæˆå™¨
    try:
        example = get_dynamic_example("gnn")
        H = example["node_features"]
        feature_dim = example["feature_dim"]
    except Exception as e:
        # å¦‚æœåŠ¨æ€ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        feature_dim = 3
        H = np.random.randn(num_nodes, feature_dim).round(2)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("#### ğŸ“Š èŠ‚ç‚¹ç‰¹å¾æ•°æ®")
        st.markdown("**æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ç‰¹å¾å€¼ï¼Œå°±åƒæ¯ä¸ªäººéƒ½æœ‰ä¸åŒçš„ç‰¹ç‚¹**")

        # å¯è§†åŒ–ç‰¹å¾çŸ©é˜µ
        fig = px.imshow(
            H,
            labels=dict(x="ç‰¹å¾ç»´åº¦", y="èŠ‚ç‚¹", color="ç‰¹å¾å€¼"),
            color_continuous_scale="RdYlBu_r",
            title="èŠ‚ç‚¹ç‰¹å¾çƒ­åŠ›å›¾",
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, width="stretch")

        # æ˜¾ç¤ºå…·ä½“æ•°å€¼ï¼ˆå¯é€‰ï¼‰
        show_details = st.checkbox("ğŸ” æ˜¾ç¤ºå…·ä½“æ•°å€¼")
        if show_details:
            st.dataframe(
                pd.DataFrame(
                    H.round(2),
                    index=[f"èŠ‚ç‚¹{i}" for i in range(num_nodes)],
                    columns=[f"ç‰¹å¾{j}" for j in range(feature_dim)],
                )
            )

        # æƒé‡çŸ©é˜µ
        st.markdown("#### âš™ï¸ è¿æ¥æƒé‡")
        st.markdown("**æƒé‡å†³å®šäº†èŠ‚ç‚¹é—´ä¿¡æ¯ä¼ é€’çš„å¼ºåº¦**")

        W = np.random.randn(feature_dim, feature_dim).round(2)
        fig = px.imshow(
            W,
            labels=dict(x="è¾“å‡ºç‰¹å¾", y="è¾“å…¥ç‰¹å¾", color="æƒé‡å€¼"),
            color_continuous_scale="RdBu",
            title="æƒé‡çŸ©é˜µçƒ­åŠ›å›¾",
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, width="stretch")

    with col2:
        st.markdown("#### ğŸ”„ ä¿¡æ¯ä¼ é€’è¿‡ç¨‹")

        # è®¡ç®—æ¶ˆæ¯ä¼ é€’
        messages = A_hat @ H
        st.markdown("**ç¬¬1æ­¥ï¼šé‚»å±…ä¿¡æ¯èšåˆ**")
        st.markdown("*æ¯ä¸ªèŠ‚ç‚¹æ”¶é›†é‚»å±…çš„ä¿¡æ¯ï¼Œå°±åƒå’Œæœ‹å‹èŠå¤©ä¸€æ ·*")

        # å¯è§†åŒ–æ¶ˆæ¯èšåˆ
        fig = px.imshow(
            messages.round(3),
            labels=dict(x="ç‰¹å¾", y="èŠ‚ç‚¹", color="èšåˆå€¼"),
            color_continuous_scale="Viridis",
            title="é‚»å±…ä¿¡æ¯èšåˆç»“æœ",
        )
        fig.update_layout(height=250)
        st.plotly_chart(fig, width="stretch")

        # çº¿æ€§å˜æ¢
        transformed = messages @ W
        st.markdown("**ç¬¬2æ­¥ï¼šä¿¡æ¯å˜æ¢**")
        st.markdown("*é€šè¿‡æƒé‡çŸ©é˜µé‡æ–°ç»„åˆä¿¡æ¯ï¼Œå°±åƒé‡æ–°æ•´ç†æ€è·¯*")

        fig = px.imshow(
            transformed.round(3),
            labels=dict(x="è¾“å‡ºç‰¹å¾", y="èŠ‚ç‚¹", color="å˜æ¢å€¼"),
            color_continuous_scale="Plasma",
            title="ä¿¡æ¯å˜æ¢ç»“æœ",
        )
        fig.update_layout(height=250)
        st.plotly_chart(fig, width="stretch")

        # æ¿€æ´»å‡½æ•°
        activated = F.relu(torch.tensor(transformed)).numpy()
        st.markdown("**ç¬¬3æ­¥ï¼šæ¿€æ´»å¤„ç†**")
        st.markdown("*ReLUå°±åƒä¸€ä¸ªè¿‡æ»¤å™¨ï¼šä¿ç•™æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå»æ‰è´Ÿå€¼*")

        # å¯¹æ¯”æ¿€æ´»å‰å
        fig = go.Figure()
        fig.add_trace(
            go.Bar(
                x=list(range(len(activated.flatten()))),
                y=transformed.flatten(),
                name="æ¿€æ´»å‰",
                marker_color="lightblue",
                opacity=0.7,
            )
        )
        fig.add_trace(
            go.Bar(
                x=list(range(len(activated.flatten()))),
                y=activated.flatten(),
                name="æ¿€æ´»å",
                marker_color="orange",
                opacity=0.7,
            )
        )
        fig.update_layout(
            title="ReLUæ¿€æ´»æ•ˆæœå¯¹æ¯”",
            xaxis_title="ç‰¹å¾ç´¢å¼•",
            yaxis_title="æ•°å€¼",
            height=300,
            barmode="overlay",
        )
        st.plotly_chart(fig, width="stretch")

        # æ¿€æ´»å‡½æ•°å¯è§†åŒ–
        st.markdown("**ğŸ¯ æ¿€æ´»å‡½æ•°å·¥ä½œåŸç†**")
        x_vals = np.linspace(-5, 5, 100)
        relu_vals = np.maximum(0, x_vals)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=x_vals, y=relu_vals, mode="lines", name="ReLU"))
        fig.update_layout(
            title="ReLUå‡½æ•°ï¼šf(x) = max(0, x)",
            xaxis_title="è¾“å…¥å€¼",
            yaxis_title="è¾“å‡ºå€¼",
            height=250,
        )
        st.plotly_chart(fig, width="stretch")

        # æ˜¾ç¤ºæ•°å€¼ï¼ˆå¯é€‰ï¼‰
        if show_details:
            st.markdown("**æœ€ç»ˆè¾“å‡ºæ•°å€¼**")
            st.dataframe(
                pd.DataFrame(
                    activated.round(3),
                    index=[f"èŠ‚ç‚¹{i}" for i in range(num_nodes)],
                    columns=[f"è¾“å‡º{j}" for j in range(feature_dim)],
                )
            )
        
        # ==================== æ•°å€¼ç¨³å®šæ€§æ£€æµ‹ ====================
        st.markdown("---")
        st.markdown("### ğŸ”¬ GNNæ•°å€¼ç¨³å®šæ€§è¯Šæ–­")
        
        st.info("ğŸ’¡ GNNç‰¹æœ‰é—®é¢˜ï¼šè¿‡å¹³æ»‘(over-smoothing)ã€æ¢¯åº¦æ¶ˆå¤±ã€èŠ‚ç‚¹ç‰¹å¾é€€åŒ–")
        
        stability_issues = []
        
        # 1. æ£€æŸ¥èŠ‚ç‚¹ç‰¹å¾èŒƒæ•°
        feature_norm = np.linalg.norm(features)
        feature_check = StabilityChecker.check_activation(
            features.flatten(), "è¾“å…¥èŠ‚ç‚¹ç‰¹å¾"
        )
        stability_issues.append(feature_check)
        
        # 2. æ£€æŸ¥èšåˆåçš„ç‰¹å¾
        aggregated_check = StabilityChecker.check_activation(
            aggregated.flatten(), "èšåˆåç‰¹å¾"
        )
        stability_issues.append(aggregated_check)
        
        # 3. æ£€æŸ¥è¾“å‡ºç‰¹å¾
        output_check = StabilityChecker.check_activation(
            activated.flatten(), "GNNè¾“å‡ºç‰¹å¾"
        )
        stability_issues.append(output_check)
        
        # 4. è¿‡å¹³æ»‘æ£€æµ‹ï¼ˆå…³é”®ï¼ï¼‰
        # è®¡ç®—èŠ‚ç‚¹ç‰¹å¾ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
        feature_norms = np.linalg.norm(activated, axis=1, keepdims=True)
        normalized_features = activated / (feature_norms + 1e-8)
        similarity_matrix = np.dot(normalized_features, normalized_features.T)
        
        # æ’é™¤å¯¹è§’çº¿
        off_diagonal_mask = ~np.eye(num_nodes, dtype=bool)
        avg_similarity = np.mean(similarity_matrix[off_diagonal_mask])
        max_similarity = np.max(similarity_matrix[off_diagonal_mask])
        
        if avg_similarity > 0.95:
            stability_issues.append({
                'status': 'error',
                'type': 'ä¸¥é‡è¿‡å¹³æ»‘',
                'value': f'{avg_similarity:.4f}',
                'threshold': '> 0.95',
                'icon': 'ğŸ”´',
                'severity': 'critical',
                'details': {
                    'å¹³å‡ç›¸ä¼¼åº¦': f'{avg_similarity:.4f}',
                    'æœ€å¤§ç›¸ä¼¼åº¦': f'{max_similarity:.4f}',
                    'èŠ‚ç‚¹æ•°': num_nodes,
                    'ç‰¹å¾ç»´åº¦': feature_dim
                },
                'solution': [
                    'å‡å°‘GNNå±‚æ•°',
                    'ä½¿ç”¨æ®‹å·®è¿æ¥ï¼ˆå¦‚ResGCNï¼‰',
                    'ä½¿ç”¨PairNorm/GraphNorm',
                    'ä½¿ç”¨Jumping Knowledge Networks',
                    'æ·»åŠ è‡ªç¯ï¼ˆself-loopsï¼‰æƒé‡'
                ],
                'explanation': 'æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾é«˜åº¦ç›¸ä¼¼ï¼Œå¤±å»äº†èŠ‚ç‚¹é—´çš„åŒºåˆ†åº¦ï¼Œè¿™æ˜¯æ·±å±‚GNNçš„å…¸å‹é—®é¢˜'
            })
        elif avg_similarity > 0.85:
            stability_issues.append({
                'status': 'warning',
                'type': 'è½»åº¦è¿‡å¹³æ»‘',
                'value': f'{avg_similarity:.4f}',
                'threshold': '> 0.85',
                'icon': 'ğŸŸ¡',
                'severity': 'medium',
                'details': {
                    'å¹³å‡ç›¸ä¼¼åº¦': f'{avg_similarity:.4f}',
                    'æœ€å¤§ç›¸ä¼¼åº¦': f'{max_similarity:.4f}',
                    'èŠ‚ç‚¹æ•°': num_nodes
                },
                'solution': [
                    'ç›‘æ§æ›´æ·±å±‚çš„ç›¸ä¼¼åº¦å˜åŒ–',
                    'è€ƒè™‘æ·»åŠ æ®‹å·®è¿æ¥',
                    'ä½¿ç”¨èŠ‚ç‚¹è‡ªé€‚åº”èšåˆ'
                ],
                'explanation': 'èŠ‚ç‚¹ç‰¹å¾ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œç»§ç»­åŠ æ·±å¯èƒ½å¯¼è‡´è¿‡å¹³æ»‘'
            })
        else:
            stability_issues.append({
                'status': 'success',
                'type': 'èŠ‚ç‚¹ç‰¹å¾åŒºåˆ†åº¦',
                'value': f'å¹³å‡ç›¸ä¼¼åº¦={avg_similarity:.4f}',
                'icon': 'ğŸŸ¢',
                'severity': 'none',
                'details': {
                    'å¹³å‡ç›¸ä¼¼åº¦': f'{avg_similarity:.4f}',
                    'æœ€å¤§ç›¸ä¼¼åº¦': f'{max_similarity:.4f}',
                    'èŠ‚ç‚¹æ•°': num_nodes
                }
            })
        
        # 5. é‚»æ¥çŸ©é˜µè°±åˆ†æ
        eigenvalues = np.linalg.eigvals(normalized_adj)
        max_eigenvalue = np.max(np.abs(eigenvalues))
        
        if max_eigenvalue > 1.1:
            stability_issues.append({
                'status': 'warning',
                'type': 'é‚»æ¥çŸ©é˜µç‰¹å¾å€¼è¿‡å¤§',
                'value': f'{max_eigenvalue:.4f}',
                'threshold': '> 1.1',
                'icon': 'ğŸŸ¡',
                'severity': 'medium',
                'details': {
                    'æœ€å¤§ç‰¹å¾å€¼': f'{max_eigenvalue:.4f}',
                    'å½’ä¸€åŒ–æ–¹æ³•': 'å¯¹ç§°å½’ä¸€åŒ–',
                    'ç†æƒ³èŒƒå›´': '[0, 1]'
                },
                'solution': [
                    'æ£€æŸ¥å½’ä¸€åŒ–æ˜¯å¦æ­£ç¡®',
                    'ä½¿ç”¨è°±å½’ä¸€åŒ–',
                    'æ·»åŠ è‡ªç¯æƒé‡',
                    'ä½¿ç”¨GCNçš„å½’ä¸€åŒ–æŠ€å·§'
                ],
                'explanation': 'ç‰¹å¾å€¼>1å¯èƒ½å¯¼è‡´ç‰¹å¾çˆ†ç‚¸ï¼Œå½±å“è®­ç»ƒç¨³å®šæ€§'
            })
        else:
            stability_issues.append({
                'status': 'success',
                'type': 'é‚»æ¥çŸ©é˜µç‰¹å¾å€¼',
                'value': f'{max_eigenvalue:.4f}',
                'icon': 'ğŸŸ¢',
                'severity': 'none',
                'details': {
                    'æœ€å¤§ç‰¹å¾å€¼': f'{max_eigenvalue:.4f}',
                    'ç‰¹å¾å€¼èŒƒå›´': f'[{np.min(np.abs(eigenvalues)):.4f}, {max_eigenvalue:.4f}]'
                }
            })
        
        # 6. åº¦åˆ†å¸ƒæ£€æŸ¥
        degree_sum = np.sum(adj_matrix, axis=1)
        max_degree = np.max(degree_sum)
        min_degree = np.min(degree_sum)
        degree_variance = np.var(degree_sum)
        
        if max_degree / (min_degree + 1) > 10:
            stability_issues.append({
                'status': 'warning',
                'type': 'åº¦åˆ†å¸ƒä¸å¹³è¡¡',
                'value': f'æœ€å¤§/æœ€å°={max_degree/(min_degree+1):.1f}',
                'threshold': '> 10',
                'icon': 'ğŸŸ¡',
                'severity': 'medium',
                'details': {
                    'æœ€å¤§åº¦': f'{max_degree:.0f}',
                    'æœ€å°åº¦': f'{min_degree:.0f}',
                    'å¹³å‡åº¦': f'{np.mean(degree_sum):.2f}',
                    'æ–¹å·®': f'{degree_variance:.2f}'
                },
                'solution': [
                    'ä½¿ç”¨åº¦å½’ä¸€åŒ–ï¼ˆGCNæ ‡å‡†ï¼‰',
                    'ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆGATï¼‰',
                    'å¯¹é«˜åº¦èŠ‚ç‚¹è¿›è¡Œé‡‡æ ·',
                    'ä½¿ç”¨GraphSAINTç­‰é‡‡æ ·æ–¹æ³•'
                ],
                'explanation': 'åº¦åˆ†å¸ƒä¸å¹³è¡¡ä¼šå¯¼è‡´é«˜åº¦èŠ‚ç‚¹ç‰¹å¾ä¸»å¯¼ï¼Œä½åº¦èŠ‚ç‚¹ä¿¡æ¯ä¸è¶³'
            })
        
        # æ˜¾ç¤ºè¯Šæ–­ç»“æœ
        StabilityChecker.display_issues(stability_issues, 
                                       title="ğŸ”¬ GNNæ•°å€¼ç¨³å®šæ€§è¯Šæ–­æŠ¥å‘Š")
        
        st.markdown("---")
        st.info(f"""
        ğŸ’¡ **GNNå¥åº·æŒ‡æ ‡æ€»ç»“**ï¼š
        
        **èŠ‚ç‚¹ç‰¹å¾**ï¼š
        - è¾“å…¥èŒƒæ•°: {feature_norm:.4f}
        - è¾“å‡ºèŒƒå›´: [{np.min(activated):.2f}, {np.max(activated):.2f}]
        
        **è¿‡å¹³æ»‘æŒ‡æ ‡**ï¼š
        - å¹³å‡èŠ‚ç‚¹ç›¸ä¼¼åº¦: {avg_similarity:.4f} (å»ºè®®<0.85)
        - æœ€å¤§èŠ‚ç‚¹ç›¸ä¼¼åº¦: {max_similarity:.4f}
        
        **å›¾ç»“æ„**ï¼š
        - é‚»æ¥çŸ©é˜µæœ€å¤§ç‰¹å¾å€¼: {max_eigenvalue:.4f} (å»ºè®®â‰¤1.0)
        - åº¦åˆ†å¸ƒ: æœ€å°{min_degree:.0f}, æœ€å¤§{max_degree:.0f}, å¹³å‡{np.mean(degree_sum):.2f}
        
        **å…¸å‹GNNé—®é¢˜**ï¼š
        1. **è¿‡å¹³æ»‘(Over-smoothing)**: æ·±å±‚GNNå¯¼è‡´æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾è¶‹åŒ
           - ç—‡çŠ¶ï¼šèŠ‚ç‚¹ç›¸ä¼¼åº¦>0.9
           - è§£å†³ï¼šæ®‹å·®è¿æ¥ã€PairNormã€å‡å°‘å±‚æ•°
        
        2. **æ¢¯åº¦æ¶ˆå¤±**: ç±»ä¼¼äºæ·±å±‚ç¥ç»ç½‘ç»œ
           - ç—‡çŠ¶ï¼šæ¢¯åº¦èŒƒæ•°<1e-7
           - è§£å†³ï¼šæ®‹å·®è¿æ¥ã€LayerNormã€æ§åˆ¶å±‚æ•°
        
        3. **åº¦ä¸å¹³è¡¡**: HubèŠ‚ç‚¹ä¸»å¯¼ä¿¡æ¯æµ
           - ç—‡çŠ¶ï¼šåº¦åˆ†å¸ƒæ–¹å·®å¤§
           - è§£å†³ï¼šåº¦å½’ä¸€åŒ–ã€æ³¨æ„åŠ›æœºåˆ¶ã€é‡‡æ ·
        
        4. **ç‰¹å¾é€€åŒ–**: æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾æ”¶æ•›åˆ°ç›¸åŒå€¼
           - ç—‡çŠ¶ï¼šç‰¹å¾æ–¹å·®è¶‹è¿‘äº0
           - è§£å†³ï¼šJumping Knowledgeã€æ··åˆä¸åŒå±‚çš„ç‰¹å¾
        
        **æ¨èå®è·µ**ï¼š
        - GCN: é€šå¸¸2-3å±‚æœ€ä¼˜
        - GAT: å¯ä»¥åˆ°4-5å±‚ï¼ˆæ³¨æ„åŠ›ç¼“è§£è¿‡å¹³æ»‘ï¼‰
        - ResGCN: å¯ä»¥åˆ°10+å±‚ï¼ˆæ®‹å·®è¿æ¥ï¼‰
        """)


if __name__ == "__main__":
    # ç‹¬ç«‹è¿è¡Œæ—¶çš„æµ‹è¯•
    gnn_tab(True)
