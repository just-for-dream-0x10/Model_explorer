"""
å¤±è´¥æ¡ˆä¾‹åšç‰©é¦† - Failure Cases Museum
å±•ç¤ºå¸¸è§çš„ç¥ç»ç½‘ç»œè®¾è®¡é”™è¯¯ï¼Œå¸®åŠ©ç†è§£ä¸ºä»€ä¹ˆæŸäº›è®¾è®¡ä¼šå¤±è´¥

æ ¸å¿ƒç†å¿µï¼šä¸æ˜¯å‘Šè¯‰ä½ "è¿™æ ·ä¸å¥½"ï¼Œè€Œæ˜¯è®©ä½ çœ‹åˆ°"åˆ°åº•å“ªé‡Œå‡ºé—®é¢˜äº†"
"""

import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from utils.failure_cases import get_failure_case


def calculate_params_and_memory(model, input_size):
    """
    è®¡ç®—æ¨¡å‹çš„å‚æ•°é‡å’Œå†…å­˜å ç”¨

    Args:
        model: PyTorchæ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸ (tuple)

    Returns:
        dict: åŒ…å«å‚æ•°é‡ã€å†…å­˜ç­‰ä¿¡æ¯
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    # ä¼°ç®—å‰å‘ä¼ æ’­å†…å­˜ï¼ˆMBï¼‰
    # å‡è®¾float32ï¼Œæ¯ä¸ªå‚æ•°4å­—èŠ‚
    param_memory = total_params * 4 / (1024**2)

    # ä¼°ç®—æ¿€æ´»å€¼å†…å­˜ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
    try:
        x = torch.randn(input_size)
        with torch.no_grad():
            y = model(x)
        activation_memory = np.prod(y.shape) * 4 / (1024**2)
    except:
        activation_memory = 0

    return {
        "total_params": total_params,
        "trainable_params": trainable_params,
        "param_memory_mb": param_memory,
        "activation_memory_mb": activation_memory,
        "total_memory_mb": param_memory + activation_memory,
    }


def simulate_gradient_flow(model, input_size, num_samples=10):
    """
    æ¨¡æ‹Ÿæ¢¯åº¦æµï¼Œæ£€æµ‹æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸

    Args:
        model: PyTorchæ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸
        num_samples: é‡‡æ ·æ¬¡æ•°

    Returns:
        dict: æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
    """
    model.train()
    gradient_norms = []
    layer_names = []

    # æ”¶é›†å¯è®­ç»ƒå‚æ•°
    named_params = [
        (name, p) for name, p in model.named_parameters() if p.requires_grad
    ]

    for _ in range(num_samples):
        model.zero_grad()

        # å‰å‘ä¼ æ’­
        x = torch.randn(input_size)
        try:
            y = model(x)

            # æ„é€ æŸå¤±ï¼ˆç®€å•çš„L2æŸå¤±ï¼‰
            target = torch.randn_like(y)
            loss = ((y - target) ** 2).mean()

            # åå‘ä¼ æ’­
            loss.backward()

            # æ”¶é›†æ¢¯åº¦èŒƒæ•°
            if len(gradient_norms) == 0:
                for name, p in named_params:
                    if p.grad is not None:
                        layer_names.append(name)
                        gradient_norms.append([])

            for i, (name, p) in enumerate(named_params):
                if p.grad is not None:
                    grad_norm = p.grad.norm().item()
                    if i < len(gradient_norms):
                        gradient_norms[i].append(grad_norm)
        except Exception as e:
            st.warning(f"æ¢¯åº¦æ¨¡æ‹Ÿå¤±è´¥: {e}")
            break

    # è®¡ç®—ç»Ÿè®¡é‡
    gradient_stats = []
    for i, norms in enumerate(gradient_norms):
        if norms:
            gradient_stats.append(
                {
                    "layer": layer_names[i] if i < len(layer_names) else f"layer_{i}",
                    "mean": np.mean(norms),
                    "std": np.std(norms),
                    "min": np.min(norms),
                    "max": np.max(norms),
                }
            )

    return gradient_stats


def simulate_training_with_lr(model, input_size, lr, num_steps=50):
    """
    æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œè§‚å¯Ÿä¸åŒå­¦ä¹ ç‡çš„å½±å“

    Args:
        model: PyTorchæ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸
        lr: å­¦ä¹ ç‡
        num_steps: è®­ç»ƒæ­¥æ•°

    Returns:
        list: æ¯æ­¥çš„losså€¼
    """
    model.train()
    optimizer = torch.optim.SGD(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    losses = []

    for step in range(num_steps):
        optimizer.zero_grad()

        # ç”Ÿæˆéšæœºæ•°æ®
        x = torch.randn(input_size)
        target = torch.randn(model(x).shape)

        # å‰å‘ä¼ æ’­
        try:
            y = model(x)
            loss = criterion(y, target)

            # æ£€æŸ¥æ˜¯å¦ä¸ºNaN
            if torch.isnan(loss):
                losses.append(float("nan"))
                st.warning(f"âš ï¸ Lossåœ¨ç¬¬{step+1}æ­¥å˜æˆNaNï¼")
                break

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            losses.append(loss.item())
        except Exception as e:
            st.error(f"è®­ç»ƒå¤±è´¥: {e}")
            break

    return losses


def plot_gradient_flow(gradient_stats):
    """ç»˜åˆ¶æ¢¯åº¦æµå›¾"""
    if not gradient_stats:
        return None

    fig = go.Figure()

    layers = [stat["layer"] for stat in gradient_stats]
    means = [stat["mean"] for stat in gradient_stats]

    # ä½¿ç”¨å¯¹æ•°åæ ‡
    fig.add_trace(
        go.Scatter(
            x=list(range(len(layers))),
            y=means,
            mode="lines+markers",
            name="æ¢¯åº¦èŒƒæ•°",
            line=dict(color="red", width=2),
            marker=dict(size=8),
        )
    )

    # æ·»åŠ è­¦æˆ’çº¿
    fig.add_hline(
        y=1e-5, line_dash="dash", line_color="orange", annotation_text="æ¢¯åº¦æ¶ˆå¤±è­¦æˆ’çº¿"
    )
    fig.add_hline(
        y=1e2, line_dash="dash", line_color="purple", annotation_text="æ¢¯åº¦çˆ†ç‚¸è­¦æˆ’çº¿"
    )

    fig.update_layout(
        title="æ¢¯åº¦æµåˆ†æï¼ˆå¯¹æ•°åæ ‡ï¼‰",
        xaxis_title="å±‚ç´¢å¼•",
        yaxis_title="æ¢¯åº¦èŒƒæ•°ï¼ˆå¯¹æ•°ï¼‰",
        yaxis_type="log",
        height=400,
        showlegend=True,
    )

    return fig


def plot_loss_curve(losses, title="Lossæ›²çº¿"):
    """ç»˜åˆ¶Lossæ›²çº¿"""
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=list(range(len(losses))),
            y=losses,
            mode="lines+markers",
            name="Loss",
            line=dict(color="blue", width=2),
            marker=dict(size=6),
        )
    )

    fig.update_layout(
        title=title, xaxis_title="è®­ç»ƒæ­¥æ•°", yaxis_title="Loss", height=400
    )

    return fig


def failure_museum_tab(chinese_supported=True):
    """å¤±è´¥æ¡ˆä¾‹åšç‰©é¦†ä¸»å‡½æ•°"""

    st.header("ğŸ›ï¸ å¤±è´¥æ¡ˆä¾‹åšç‰©é¦†")
    st.markdown(
        """
    > **æ•™å­¦ç›®æ ‡**ï¼šé€šè¿‡å®é™…æ¡ˆä¾‹ï¼Œè®©ä½ çœ‹åˆ°ç½‘ç»œè®¾è®¡é”™è¯¯ä¼šå¯¼è‡´ä»€ä¹ˆå…·ä½“çš„æ•°å€¼é—®é¢˜
    
    **æ ¸å¿ƒç†å¿µ**ï¼šä¸æ˜¯å‘Šè¯‰ä½ "è¿™æ ·ä¸å¥½"ï¼Œè€Œæ˜¯è®©ä½ çœ‹åˆ°"æ¢¯åº¦çœŸçš„å˜æˆ0äº†"ã€"å‚æ•°çœŸçš„æœ‰32äº¿ä¸ª"
    """
    )

    st.markdown("---")

    # æ¡ˆä¾‹é€‰æ‹©
    st.subheader("ğŸ“‹ é€‰æ‹©å¤±è´¥æ¡ˆä¾‹")

    case_options = {
        "100å±‚æ™®é€šMLPï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰": "deep_mlp",
        "å·ç§¯å±‚ç›´æ¥æ¥è¶…å¤§å…¨è¿æ¥ï¼ˆå‚æ•°çˆ†ç‚¸ï¼‰": "conv_fc",
        "20å±‚å·ç§¯ç½‘ç»œæ— å½’ä¸€åŒ–ï¼ˆè®­ç»ƒä¸ç¨³å®šï¼‰": "no_norm",
        "ç®€å•MLP + è¶…å¤§å­¦ä¹ ç‡ï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰": "huge_lr",
    }

    selected_case_name = st.selectbox(
        "é€‰æ‹©æ¡ˆä¾‹", list(case_options.keys()), help="é€‰æ‹©ä¸€ä¸ªç»å…¸çš„è®¾è®¡é”™è¯¯æ¡ˆä¾‹"
    )

    case_id = case_options[selected_case_name]

    # åŠ è½½æ¡ˆä¾‹
    try:
        model, case_info = get_failure_case(case_id)
    except Exception as e:
        st.error(f"åŠ è½½æ¡ˆä¾‹å¤±è´¥: {e}")
        return

    # æ˜¾ç¤ºæ¡ˆä¾‹ä¿¡æ¯
    st.markdown("---")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown(f"### ğŸ“Œ {case_info['name']}")
        st.markdown(f"**é—®é¢˜ç±»å‹**: {case_info['problem']}")
        st.markdown(f"**ç—‡çŠ¶**: {case_info['symptom']}")

    with col2:
        st.markdown("### ğŸ” åŸå› åˆ†æ")
        st.markdown(case_info["reason"])
        st.markdown("### âœ… è§£å†³æ–¹æ¡ˆ")
        st.success(case_info["solution"])

    # è®¡ç®—å‚æ•°é‡å’Œå†…å­˜
    st.markdown("---")
    st.subheader("ğŸ“Š å‚æ•°é‡ä¸å†…å­˜åˆ†æ")

    with st.spinner("è®¡ç®—ä¸­..."):
        stats = calculate_params_and_memory(model, case_info["input_size"])

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ€»å‚æ•°é‡", f"{stats['total_params']:,}")
    with col2:
        st.metric("å‚æ•°å†…å­˜", f"{stats['param_memory_mb']:.2f} MB")
    with col3:
        st.metric("æ¿€æ´»å€¼å†…å­˜", f"{stats['activation_memory_mb']:.2f} MB")
    with col4:
        total_mem = stats["total_memory_mb"]
        mem_color = "normal" if total_mem < 1000 else "inverse"
        st.metric("æ€»å†…å­˜", f"{total_mem:.2f} MB", delta_color=mem_color)

    # æ ¹æ®æ¡ˆä¾‹ç±»å‹æ˜¾ç¤ºä¸åŒçš„è¯Šæ–­
    st.markdown("---")

    if case_id == "deep_mlp":
        st.subheader("ğŸ”¬ æ¢¯åº¦æ¶ˆå¤±è¯Šæ–­")
        st.markdown("æ¨¡æ‹Ÿ10æ¬¡å‰å‘+åå‘ä¼ æ’­ï¼Œè§‚å¯Ÿå„å±‚çš„æ¢¯åº¦èŒƒæ•°")

        if st.button("ğŸš€ å¼€å§‹æ¢¯åº¦åˆ†æ", key="grad_analysis"):
            with st.spinner("åˆ†æä¸­..."):
                gradient_stats = simulate_gradient_flow(model, case_info["input_size"])

            if gradient_stats:
                # æ˜¾ç¤ºæ¢¯åº¦è¡¨æ ¼
                st.markdown("#### å„å±‚æ¢¯åº¦ç»Ÿè®¡")

                # åªæ˜¾ç¤ºå‰10å±‚å’Œå10å±‚
                if len(gradient_stats) > 20:
                    display_stats = gradient_stats[:10] + gradient_stats[-10:]
                    st.info("æ˜¾ç¤ºå‰10å±‚å’Œå10å±‚çš„æ¢¯åº¦ç»Ÿè®¡")
                else:
                    display_stats = gradient_stats

                for i, stat in enumerate(display_stats):
                    mean_grad = stat["mean"]
                    if mean_grad < 1e-5:
                        st.error(
                            f"âŒ {stat['layer']}: æ¢¯åº¦={mean_grad:.2e} (ä¸¥é‡æ¶ˆå¤±ï¼)"
                        )
                    elif mean_grad < 1e-3:
                        st.warning(
                            f"âš ï¸ {stat['layer']}: æ¢¯åº¦={mean_grad:.2e} (è½»å¾®æ¶ˆå¤±)"
                        )
                    else:
                        st.success(f"âœ… {stat['layer']}: æ¢¯åº¦={mean_grad:.2e} (æ­£å¸¸)")

                # ç»˜åˆ¶æ¢¯åº¦æµå›¾
                fig = plot_gradient_flow(gradient_stats)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)

    elif case_id == "conv_fc":
        st.subheader("ğŸ’¥ å‚æ•°çˆ†ç‚¸è­¦å‘Š")

        # è®¡ç®—å…¨è¿æ¥å±‚çš„å‚æ•°é‡
        fc_params = 64 * 224 * 224 * 1000
        st.error(f"âš ï¸ å…¨è¿æ¥å±‚å‚æ•°é‡: **{fc_params:,}** (32äº¿å‚æ•°ï¼)")

        st.markdown("#### ä¸ºä»€ä¹ˆè¿™ä¹ˆå¤šï¼Ÿ")
        st.code(
            """
è¾“å…¥ç‰¹å¾å›¾: [Batch, 64, 224, 224]
Flattenå:  [Batch, 64Ã—224Ã—224] = [Batch, 3,211,264]
å…¨è¿æ¥å±‚:   Linear(3,211,264 -> 1000)
å‚æ•°é‡ = 3,211,264 Ã— 1000 + 1000 = 3,211,265,000
        """
        )

        st.markdown("#### âœ… æ­£ç¡®åšæ³•ï¼šå…¨å±€å¹³å‡æ± åŒ–")
        st.code(
            """
è¾“å…¥ç‰¹å¾å›¾: [Batch, 64, 224, 224]
å…¨å±€å¹³å‡æ± åŒ–: [Batch, 64, 1, 1] -> [Batch, 64]
å…¨è¿æ¥å±‚:   Linear(64 -> 1000)
å‚æ•°é‡ = 64 Ã— 1000 + 1000 = 65,000 (å‡å°‘äº†5ä¸‡å€ï¼)
        """
        )

    elif case_id == "no_norm":
        st.subheader("ğŸ“‰ è®­ç»ƒä¸ç¨³å®šæ¨¡æ‹Ÿ")
        st.markdown("æ¯”è¾ƒæœ‰æ— BatchNormçš„è®­ç»ƒæ›²çº¿å·®å¼‚")

        st.info(
            "ğŸ’¡ æç¤ºï¼šç”±äºæ—¶é—´é™åˆ¶ï¼Œè¿™é‡Œå±•ç¤ºç†è®ºåˆ†æã€‚å®é™…è®­ç»ƒå¯ä»¥çœ‹åˆ°Losså‰§çƒˆéœ‡è¡ã€‚"
        )

        # æ˜¾ç¤ºæ¿€æ´»å€¼åˆ†å¸ƒåˆ†æ
        st.markdown("#### æ¿€æ´»å€¼åˆ†å¸ƒé—®é¢˜")
        st.markdown(
            """
        **æ— å½’ä¸€åŒ–çš„é—®é¢˜**ï¼š
        - ç¬¬1å±‚è¾“å‡ºèŒƒå›´: [-10, 10]
        - ç¬¬10å±‚è¾“å‡ºèŒƒå›´: [-1000, 1000]ï¼ˆèŒƒå›´æ‰©å¤§ï¼‰
        - ç¬¬20å±‚è¾“å‡ºèŒƒå›´: å¯èƒ½æº¢å‡ºåˆ°inf
        
        **BatchNormçš„ä½œç”¨**ï¼š
        - å¼ºåˆ¶æ¯å±‚è¾“å‡ºå‡å€¼=0ï¼Œæ–¹å·®=1
        - ä¿æŒæ¿€æ´»å€¼åœ¨åˆç†èŒƒå›´å†…
        - æ¢¯åº¦æ›´ç¨³å®š
        """
        )

    elif case_id == "huge_lr":
        st.subheader("ğŸ”¥ å­¦ä¹ ç‡å¯¹æ¯”å®éªŒ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### âŒ å­¦ä¹ ç‡è¿‡å¤§ (lr=10.0)")
            if st.button("æ¨¡æ‹Ÿè®­ç»ƒï¼ˆå¤§å­¦ä¹ ç‡ï¼‰", key="train_huge_lr"):
                with st.spinner("è®­ç»ƒä¸­..."):
                    bad_losses = simulate_training_with_lr(
                        model,
                        case_info["input_size"],
                        case_info["bad_lr"],
                        num_steps=30,
                    )

                fig = plot_loss_curve(bad_losses, "Lossæ›²çº¿ï¼ˆlr=10.0ï¼‰")
                st.plotly_chart(fig, use_container_width=True)

                if any(np.isnan(bad_losses)):
                    st.error("ğŸ’¥ Losså˜æˆNaNï¼æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´æ•°å€¼æº¢å‡º")

        with col2:
            st.markdown("#### âœ… åˆç†å­¦ä¹ ç‡ (lr=0.01)")
            if st.button("æ¨¡æ‹Ÿè®­ç»ƒï¼ˆæ­£å¸¸å­¦ä¹ ç‡ï¼‰", key="train_good_lr"):
                with st.spinner("è®­ç»ƒä¸­..."):
                    good_losses = simulate_training_with_lr(
                        model,
                        case_info["input_size"],
                        case_info["good_lr"],
                        num_steps=30,
                    )

                fig = plot_loss_curve(good_losses, "Lossæ›²çº¿ï¼ˆlr=0.01ï¼‰")
                st.plotly_chart(fig, use_container_width=True)

                st.success("âœ… Lossæ­£å¸¸ä¸‹é™ï¼Œè®­ç»ƒç¨³å®š")

    # æ€»ç»“
    st.markdown("---")
    st.subheader("ğŸ“š å­¦ä¹ è¦ç‚¹")

    st.markdown(
        f"""
    **é€šè¿‡è¿™ä¸ªæ¡ˆä¾‹ï¼Œä½ åº”è¯¥çœ‹åˆ°**ï¼š
    1. **å…·ä½“çš„æ•°å€¼é—®é¢˜**ï¼šä¸æ˜¯"å¯èƒ½ä¼šå¤±è´¥"ï¼Œè€Œæ˜¯"æ¢¯åº¦çœŸçš„æ˜¯1e-10"
    2. **é—®é¢˜çš„æ ¹æº**ï¼š{case_info['reason']}
    3. **å®é™…çš„è§£å†³æ–¹æ¡ˆ**ï¼š{case_info['solution']}
    
    **è®°ä½**ï¼šç¥ç»ç½‘ç»œçš„è®¾è®¡ä¸æ˜¯ç„å­¦ï¼Œæ¯ä¸ªé€‰æ‹©éƒ½æœ‰æ•°å­¦å’Œå·¥ç¨‹ä¸Šçš„ç†ç”±ï¼
    """
    )


if __name__ == "__main__":
    # æµ‹è¯•è¿è¡Œ
    failure_museum_tab()
