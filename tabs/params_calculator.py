"""
å‚æ•°é‡ä¸è®¡ç®—é‡åˆ†æå·¥å…·
ä¸“æ³¨äºå…·ä½“ç½‘ç»œå±‚çš„è®¡ç®—ç»†èŠ‚åˆ†æ
"""

import streamlit as st
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from typing import Dict, List, Tuple


class LayerAnalyzer:
    """ç½‘ç»œå±‚åˆ†æå™¨ï¼šè®¡ç®—å‚æ•°é‡ã€FLOPsã€å†…å­˜å ç”¨"""
    
    @staticmethod
    def conv2d_analysis(in_channels: int, out_channels: int, kernel_size: int, 
                       stride: int, padding: int, input_shape: Tuple[int, int, int],
                       use_bias: bool = True) -> Dict:
        """
        åˆ†æ Conv2d å±‚çš„è®¡ç®—ç»†èŠ‚
        
        Args:
            in_channels: è¾“å…¥é€šé“æ•°
            out_channels: è¾“å‡ºé€šé“æ•°
            kernel_size: å·ç§¯æ ¸å¤§å°
            stride: æ­¥é•¿
            padding: å¡«å……
            input_shape: (C, H, W)
            use_bias: æ˜¯å¦ä½¿ç”¨åç½®
            
        Returns:
            åŒ…å«å‚æ•°é‡ã€FLOPsã€å†…å­˜ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        C_in, H_in, W_in = input_shape
        
        # è¾“å‡ºå°ºå¯¸è®¡ç®—
        H_out = (H_in + 2 * padding - kernel_size) // stride + 1
        W_out = (W_in + 2 * padding - kernel_size) // stride + 1
        
        # å‚æ•°é‡è®¡ç®—
        # æƒé‡å‚æ•°: out_channels Ã— in_channels Ã— kernel_size Ã— kernel_size
        weight_params = out_channels * in_channels * kernel_size * kernel_size
        # åç½®å‚æ•°: out_channels (å¦‚æœä½¿ç”¨)
        bias_params = out_channels if use_bias else 0
        total_params = weight_params + bias_params
        
        # FLOPs è®¡ç®—
        # æ¯ä¸ªè¾“å‡ºä½ç½®éœ€è¦: kernel_sizeÂ² Ã— in_channels æ¬¡ä¹˜æ³•
        # è¾“å‡ºä½ç½®æ€»æ•°: out_channels Ã— H_out Ã— W_out
        macs_per_position = kernel_size * kernel_size * in_channels  # ä¹˜åŠ æ“ä½œ
        total_macs = macs_per_position * out_channels * H_out * W_out
        # 1 MAC = 2 FLOPs (1ä¸ªä¹˜æ³• + 1ä¸ªåŠ æ³•)
        total_flops = 2 * total_macs
        
        # å¦‚æœæœ‰åç½®ï¼Œæ¯ä¸ªè¾“å‡ºä½ç½®è¿˜éœ€è¦1æ¬¡åŠ æ³•
        if use_bias:
            total_flops += out_channels * H_out * W_out
        
        # å†…å­˜å ç”¨ (å‡è®¾ FP32, æ¯ä¸ªå‚æ•° 4 bytes)
        param_memory_mb = (total_params * 4) / (1024 ** 2)
        
        # å‰å‘ä¼ æ’­æ¿€æ´»å€¼å†…å­˜
        input_memory = C_in * H_in * W_in * 4 / (1024 ** 2)  # MB
        output_memory = out_channels * H_out * W_out * 4 / (1024 ** 2)  # MB
        forward_memory_mb = input_memory + output_memory
        
        # åå‘ä¼ æ’­éœ€è¦å­˜å‚¨è¾“å…¥å’Œè¾“å‡ºçš„æ¢¯åº¦ï¼Œå†…å­˜ç¿»å€
        backward_memory_mb = forward_memory_mb * 2
        
        return {
            'layer_type': 'Conv2d',
            'input_shape': (C_in, H_in, W_in),
            'output_shape': (out_channels, H_out, W_out),
            'kernel_size': kernel_size,
            'stride': stride,
            'padding': padding,
            'parameters': {
                'weight': weight_params,
                'bias': bias_params,
                'total': total_params
            },
            'flops': {
                'macs': total_macs,
                'total': total_flops,
                'macs_readable': f"{total_macs / 1e6:.2f}M" if total_macs > 1e6 else f"{total_macs / 1e3:.2f}K",
                'flops_readable': f"{total_flops / 1e9:.2f}G" if total_flops > 1e9 else f"{total_flops / 1e6:.2f}M"
            },
            'memory_mb': {
                'parameters': param_memory_mb,
                'forward': forward_memory_mb,
                'backward': backward_memory_mb,
                'total': param_memory_mb + backward_memory_mb
            }
        }
    
    @staticmethod
    def linear_analysis(in_features: int, out_features: int, use_bias: bool = True) -> Dict:
        """
        åˆ†æ Linear (å…¨è¿æ¥) å±‚çš„è®¡ç®—ç»†èŠ‚
        
        Args:
            in_features: è¾“å…¥ç‰¹å¾æ•°
            out_features: è¾“å‡ºç‰¹å¾æ•°
            use_bias: æ˜¯å¦ä½¿ç”¨åç½®
            
        Returns:
            åŒ…å«å‚æ•°é‡ã€FLOPsã€å†…å­˜ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        # å‚æ•°é‡è®¡ç®—
        weight_params = in_features * out_features
        bias_params = out_features if use_bias else 0
        total_params = weight_params + bias_params
        
        # FLOPs è®¡ç®—
        # y = Wx + b
        # çŸ©é˜µä¹˜æ³•: in_features Ã— out_features æ¬¡ä¹˜åŠ æ“ä½œ
        total_macs = in_features * out_features
        total_flops = 2 * total_macs
        if use_bias:
            total_flops += out_features
        
        # å†…å­˜å ç”¨ (FP32)
        param_memory_mb = (total_params * 4) / (1024 ** 2)
        
        return {
            'layer_type': 'Linear',
            'input_features': in_features,
            'output_features': out_features,
            'parameters': {
                'weight': weight_params,
                'bias': bias_params,
                'total': total_params
            },
            'flops': {
                'macs': total_macs,
                'total': total_flops,
                'macs_readable': f"{total_macs / 1e6:.2f}M" if total_macs > 1e6 else f"{total_macs / 1e3:.2f}K",
                'flops_readable': f"{total_flops / 1e9:.2f}G" if total_flops > 1e9 else f"{total_flops / 1e6:.2f}M"
            },
            'memory_mb': {
                'parameters': param_memory_mb
            }
        }
    
    @staticmethod
    def batchnorm2d_analysis(num_features: int, input_shape: Tuple[int, int, int]) -> Dict:
        """
        åˆ†æ BatchNorm2d å±‚çš„è®¡ç®—ç»†èŠ‚
        
        Args:
            num_features: é€šé“æ•°
            input_shape: (C, H, W)
            
        Returns:
            åŒ…å«å‚æ•°é‡ã€FLOPsã€å†…å­˜ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        C, H, W = input_shape
        
        # å‚æ•°é‡: gamma (scale) å’Œ beta (shift)
        total_params = 2 * num_features
        
        # FLOPs è®¡ç®—
        # æ¯ä¸ªå…ƒç´ : (x - mean) / sqrt(var + eps) * gamma + beta
        # = å‡æ³• + é™¤æ³• + ä¹˜æ³• + åŠ æ³• = 4 ops per element
        total_elements = C * H * W
        total_flops = 4 * total_elements
        
        param_memory_mb = (total_params * 4) / (1024 ** 2)
        
        return {
            'layer_type': 'BatchNorm2d',
            'num_features': num_features,
            'input_shape': input_shape,
            'parameters': {
                'gamma': num_features,
                'beta': num_features,
                'total': total_params
            },
            'flops': {
                'total': total_flops,
                'flops_readable': f"{total_flops / 1e6:.2f}M" if total_flops > 1e6 else f"{total_flops / 1e3:.2f}K"
            },
            'memory_mb': {
                'parameters': param_memory_mb
            }
        }


def params_calculator_tab():
    """å‚æ•°é‡ä¸FLOPsè®¡ç®—å™¨æ ‡ç­¾é¡µ"""
    
    st.header("ğŸ”¢ å‚æ•°é‡ä¸FLOPsè®¡ç®—å™¨")
    
    st.markdown("""
    ### æ ¸å¿ƒåŠŸèƒ½ï¼šé€å±‚åˆ†æç½‘ç»œè®¡ç®—ç»†èŠ‚
    
    è¾“å…¥ç½‘ç»œå±‚çš„é…ç½®ï¼Œè‡ªåŠ¨è®¡ç®—ï¼š
    - ğŸ“Š å‚æ•°é‡ï¼ˆParamsï¼‰
    - ğŸ“ˆ æµ®ç‚¹è¿ç®—é‡ï¼ˆFLOPs / MACsï¼‰
    - ğŸ’¾ å†…å­˜å ç”¨ï¼ˆå‰å‘/åå‘ä¼ æ’­ï¼‰
    - ğŸ” è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸
    
    **ä¸ torchinfo çš„åŒºåˆ«**ï¼šæˆ‘ä»¬ä¸ä»…ç»™å‡ºæ•°å­—ï¼Œè¿˜å±•ç¤º**æ¯ä¸ªæ•°å­—èƒŒåçš„è®¡ç®—å…¬å¼**ï¼
    """)
    
    # é€‰æ‹©å±‚ç±»å‹
    layer_type = st.selectbox(
        "é€‰æ‹©ç½‘ç»œå±‚ç±»å‹",
        ["Conv2d (å·ç§¯å±‚)", "Linear (å…¨è¿æ¥å±‚)", "BatchNorm2d (æ‰¹å½’ä¸€åŒ–)"]
    )
    
    analyzer = LayerAnalyzer()
    
    if "Conv2d" in layer_type:
        st.markdown("### ğŸ–¼ï¸ Conv2d å·ç§¯å±‚åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**è¾“å…¥é…ç½®**")
            C_in = st.number_input("è¾“å…¥é€šé“æ•° (in_channels)", min_value=1, value=3, step=1)
            H_in = st.number_input("è¾“å…¥é«˜åº¦ (H)", min_value=1, value=224, step=1)
            W_in = st.number_input("è¾“å…¥å®½åº¦ (W)", min_value=1, value=224, step=1)
        
        with col2:
            st.markdown("**å±‚å‚æ•°é…ç½®**")
            C_out = st.number_input("è¾“å‡ºé€šé“æ•° (out_channels)", min_value=1, value=64, step=1)
            kernel_size = st.number_input("å·ç§¯æ ¸å¤§å° (kernel_size)", min_value=1, value=7, step=1)
            stride = st.number_input("æ­¥é•¿ (stride)", min_value=1, value=2, step=1)
            padding = st.number_input("å¡«å…… (padding)", min_value=0, value=3, step=1)
            use_bias = st.checkbox("ä½¿ç”¨åç½® (bias)", value=True)
        
        # è®¡ç®—åˆ†æ
        result = analyzer.conv2d_analysis(
            in_channels=C_in,
            out_channels=C_out,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            input_shape=(C_in, H_in, W_in),
            use_bias=use_bias
        )
        
        # æ˜¾ç¤ºç»“æœ
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        
        # è¾“å‡ºå½¢çŠ¶
        st.markdown("#### 1ï¸âƒ£ è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸")
        C_out_calc, H_out, W_out = result['output_shape']
        
        st.latex(r"H_{out} = \left\lfloor \frac{H_{in} + 2 \times padding - kernel\_size}{stride} \right\rfloor + 1")
        st.latex(r"W_{out} = \left\lfloor \frac{W_{in} + 2 \times padding - kernel\_size}{stride} \right\rfloor + 1")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è¾“å…¥å½¢çŠ¶", f"[{C_in}, {H_in}, {W_in}]")
        with col2:
            st.metric("è¾“å‡ºå½¢çŠ¶", f"[{C_out_calc}, {H_out}, {W_out}]")
        with col3:
            reduction = ((H_in * W_in) - (H_out * W_out)) / (H_in * W_in) * 100
            st.metric("ç©ºé—´é™é‡‡æ ·", f"{reduction:.1f}%")
        
        # å‚æ•°é‡
        st.markdown("#### 2ï¸âƒ£ å‚æ•°é‡è®¡ç®—")
        st.latex(r"Params_{weight} = C_{out} \times C_{in} \times K_h \times K_w")
        if use_bias:
            st.latex(r"Params_{bias} = C_{out}")
            st.latex(r"Params_{total} = Params_{weight} + Params_{bias}")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æƒé‡å‚æ•°", f"{result['parameters']['weight']:,}")
        with col2:
            st.metric("åç½®å‚æ•°", f"{result['parameters']['bias']:,}")
        with col3:
            st.metric("æ€»å‚æ•°é‡", f"{result['parameters']['total']:,}")
        
        # è¯¦ç»†è®¡ç®—è¿‡ç¨‹
        with st.expander("ğŸ“– æŸ¥çœ‹è¯¦ç»†è®¡ç®—è¿‡ç¨‹"):
            st.code(f"""
è®¡ç®—è¿‡ç¨‹ï¼š
æƒé‡å‚æ•° = {C_out} Ã— {C_in} Ã— {kernel_size} Ã— {kernel_size}
        = {result['parameters']['weight']:,}

åç½®å‚æ•° = {C_out if use_bias else 0}

æ€»å‚æ•°é‡ = {result['parameters']['weight']:,} + {result['parameters']['bias']}
        = {result['parameters']['total']:,}
            """)
        
        # FLOPs
        st.markdown("#### 3ï¸âƒ£ æµ®ç‚¹è¿ç®—é‡ (FLOPs)")
        st.latex(r"MACs = K_h \times K_w \times C_{in} \times C_{out} \times H_{out} \times W_{out}")
        st.latex(r"FLOPs = 2 \times MACs" + (r" + C_{out} \times H_{out} \times W_{out}" if use_bias else ""))
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("MACs", result['flops']['macs_readable'])
        with col2:
            st.metric("FLOPs", result['flops']['flops_readable'])
        
        with st.expander("ğŸ“– æŸ¥çœ‹è¯¦ç»†è®¡ç®—è¿‡ç¨‹"):
            st.code(f"""
è®¡ç®—è¿‡ç¨‹ï¼š
æ¯ä¸ªè¾“å‡ºä½ç½®çš„ä¹˜åŠ æ“ä½œæ•° (MACs per position):
    = {kernel_size} Ã— {kernel_size} Ã— {C_in}
    = {kernel_size * kernel_size * C_in}

è¾“å‡ºä½ç½®æ€»æ•°:
    = {C_out} Ã— {H_out} Ã— {W_out}
    = {C_out * H_out * W_out:,}

æ€» MACs:
    = {kernel_size * kernel_size * C_in} Ã— {C_out * H_out * W_out:,}
    = {result['flops']['macs']:,}

æ€» FLOPs (1 MAC = 2 FLOPs):
    = 2 Ã— {result['flops']['macs']:,}{' + ' + str(C_out * H_out * W_out) if use_bias else ''}
    = {result['flops']['total']:,}
            """)
        
        # å†…å­˜å ç”¨
        st.markdown("#### 4ï¸âƒ£ å†…å­˜å ç”¨ (FP32)")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å‚æ•°å†…å­˜", f"{result['memory_mb']['parameters']:.4f} MB")
        with col2:
            st.metric("å‰å‘ä¼ æ’­", f"{result['memory_mb']['forward']:.4f} MB")
        with col3:
            st.metric("åå‘ä¼ æ’­", f"{result['memory_mb']['backward']:.4f} MB")
        
        # å¯è§†åŒ–å¯¹æ¯”
        st.markdown("#### 5ï¸âƒ£ ç›´è§‚å¯¹æ¯”")
        
        # åˆ›å»ºé¥¼å›¾
        fig = go.Figure(data=[go.Pie(
            labels=['æƒé‡å‚æ•°', 'åç½®å‚æ•°'] if use_bias else ['æƒé‡å‚æ•°'],
            values=[result['parameters']['weight'], result['parameters']['bias']] if use_bias else [result['parameters']['weight']],
            hole=.3
        )])
        fig.update_layout(title_text="å‚æ•°é‡åˆ†å¸ƒ", height=400)
        st.plotly_chart(fig, width='stretch')
        
    elif "Linear" in layer_type:
        st.markdown("### ğŸ”— Linear å…¨è¿æ¥å±‚åˆ†æ")
        
        col1, col2 = st.columns(2)
        with col1:
            in_features = st.number_input("è¾“å…¥ç‰¹å¾æ•° (in_features)", min_value=1, value=512, step=1)
        with col2:
            out_features = st.number_input("è¾“å‡ºç‰¹å¾æ•° (out_features)", min_value=1, value=1000, step=1)
        
        use_bias = st.checkbox("ä½¿ç”¨åç½® (bias)", value=True, key="linear_bias")
        
        result = analyzer.linear_analysis(in_features, out_features, use_bias)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        
        # å‚æ•°é‡
        st.markdown("#### å‚æ•°é‡è®¡ç®—")
        st.latex(r"Params_{weight} = in\_features \times out\_features")
        if use_bias:
            st.latex(r"Params_{total} = Params_{weight} + out\_features")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æƒé‡å‚æ•°", f"{result['parameters']['weight']:,}")
        with col2:
            st.metric("åç½®å‚æ•°", f"{result['parameters']['bias']:,}")
        with col3:
            st.metric("æ€»å‚æ•°é‡", f"{result['parameters']['total']:,}")
        
        # FLOPs
        st.markdown("#### æµ®ç‚¹è¿ç®—é‡")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("MACs", result['flops']['macs_readable'])
        with col2:
            st.metric("FLOPs", result['flops']['flops_readable'])
        
        # è­¦å‘Šï¼šå…¨è¿æ¥å±‚å‚æ•°é‡é—®é¢˜
        if result['parameters']['total'] > 1e6:
            st.warning(f"""
            âš ï¸ **å‚æ•°é‡è­¦å‘Š**
            
            è¯¥å…¨è¿æ¥å±‚æœ‰ **{result['parameters']['total']:,}** ä¸ªå‚æ•°ï¼ˆ>{result['parameters']['total']/1e6:.1f}Mï¼‰ï¼
            
            **å¸¸è§é—®é¢˜**ï¼š
            - å…¨è¿æ¥å±‚é€šå¸¸æ˜¯ç½‘ç»œä¸­å‚æ•°é‡æœ€å¤šçš„éƒ¨åˆ†
            - è€ƒè™‘ä½¿ç”¨ Global Average Pooling æ›¿ä»£
            - æˆ–è€…å‡å°‘è¾“å…¥ç‰¹å¾æ•°
            """)
    
    elif "BatchNorm" in layer_type:
        st.markdown("### ğŸ“ BatchNorm2d æ‰¹å½’ä¸€åŒ–å±‚åˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            num_features = st.number_input("é€šé“æ•° (num_features)", min_value=1, value=64, step=1)
        with col2:
            H = st.number_input("ç‰¹å¾å›¾é«˜åº¦ (H)", min_value=1, value=56, step=1)
        with col3:
            W = st.number_input("ç‰¹å¾å›¾å®½åº¦ (W)", min_value=1, value=56, step=1)
        
        result = analyzer.batchnorm2d_analysis(num_features, (num_features, H, W))
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        
        st.markdown("#### å‚æ•°é‡")
        st.latex(r"Params_{total} = 2 \times num\_features \quad (\gamma \text{ å’Œ } \beta)")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Gamma (scale)", f"{result['parameters']['gamma']}")
        with col2:
            st.metric("Beta (shift)", f"{result['parameters']['beta']}")
        
        st.info("""
        ğŸ’¡ **BatchNorm å‚æ•°é‡å¾ˆå°**
        
        BatchNorm åªæœ‰ 2 Ã— é€šé“æ•° ä¸ªå¯å­¦ä¹ å‚æ•°ï¼Œä¸»è¦å¼€é”€åœ¨äºè®¡ç®—å‡å€¼å’Œæ–¹å·®ã€‚
        """)
