"""
æ¶æ„è®¡ç®—è§£å‰–å·¥ä½œå°
Architecture Computational Dissection Workbench

å¯è§†åŒ–æ­å»ºç¥ç»ç½‘ç»œï¼Œæ·±å…¥è§£å‰–æ¯ä¸€æ­¥çš„æ•°å€¼è®¡ç®—
æ ¸å¿ƒç†å¿µï¼šè®©ä½ çœ‹åˆ°æ¯ä¸€å±‚åˆ°åº•ç®—äº†ä»€ä¹ˆæ•°å€¼ã€ä¸ºä»€ä¹ˆè¿™æ ·è®¡ç®—ã€æ•°å€¼å¦‚ä½•ä¼ æ’­

è®¡ç®—è§£å‰–åŠŸèƒ½ï¼š
- é€å±‚æ•°å€¼è®¡ç®—è¿‡ç¨‹å±•ç¤º
- å‚æ•°è®¡ç®—çš„æ•°å­¦å…¬å¼æ¨å¯¼
- æ¿€æ´»å€¼ä¼ æ’­çš„æ•°å€¼è¿½è¸ª
- æ¢¯åº¦åå‘ä¼ æ’­çš„æ•°å€¼åˆ†æ
- æ•°å€¼ç¨³å®šæ€§é—®é¢˜çš„å®æ—¶æ£€æµ‹

v2.2.0 æ–°å¢ï¼š
- ç»Ÿä¸€ç¨³å®šæ€§æ£€æµ‹
- å‚æ•°çˆ†ç‚¸é¢„è­¦
- å†…å­˜æº¢å‡ºæ£€æµ‹
- ç“¶é¢ˆå±‚è¯†åˆ«
"""

import streamlit as st
import torch
import torch.nn as nn
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from PIL import Image
import io
import json
from typing import List, Dict, Optional, Tuple

from utils.memory_analyzer import (
    analyze_conv2d_memory,
    analyze_linear_memory,
    get_tensor_memory,
)
from utils.stability_analyzer import check_activation_stability
from templates.template_loader import TemplateLoader
from utils.template_calculator import TemplateCalculator
from utils.numerical_stability_checker import StabilityChecker


class LayerConfig:
    """å±‚é…ç½®ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, layer_type: str, name: str, params: dict):
        self.layer_type = layer_type
        self.name = name
        self.params = params
        self.output_shape = None
        self.param_count = 0
        self.memory = 0.0
        self.flops = 0

        # æ–°å¢ï¼šé—®é¢˜æ£€æµ‹
        self.has_issues = False
        self.issues = []
        self.warnings = []
        self.recommendations = []

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºå¯¼å‡ºï¼‰"""
        return {"layer_type": self.layer_type, "name": self.name, "params": self.params}

    @staticmethod
    def from_dict(data: dict) -> "LayerConfig":
        """ä»å­—å…¸åˆ›å»ºï¼ˆç”¨äºå¯¼å…¥ï¼‰"""
        return LayerConfig(data["layer_type"], data["name"], data["params"])


def create_layer_from_config(config: LayerConfig, input_shape):
    """æ ¹æ®é…ç½®åˆ›å»ºPyTorchå±‚"""
    layer_type = config.layer_type
    params = config.params

    try:
        if layer_type == "Conv2d":
            layer = nn.Conv2d(
                params["in_channels"],
                params["out_channels"],
                params["kernel_size"],
                stride=params.get("stride", 1),
                padding=params.get("padding", 0),
            )
            # è®¡ç®—è¾“å‡ºå½¢çŠ¶
            B, C, H, W = input_shape
            H_out = (
                H + 2 * params.get("padding", 0) - params["kernel_size"]
            ) // params.get("stride", 1) + 1
            W_out = (
                W + 2 * params.get("padding", 0) - params["kernel_size"]
            ) // params.get("stride", 1) + 1
            config.output_shape = (B, params["out_channels"], H_out, W_out)

        elif layer_type == "Linear":
            layer = nn.Linear(params["in_features"], params["out_features"])
            B = input_shape[0]
            config.output_shape = (B, params["out_features"])

        elif layer_type == "ReLU":
            layer = nn.ReLU()
            config.output_shape = input_shape

        elif layer_type == "MaxPool2d":
            layer = nn.MaxPool2d(
                params["kernel_size"],
                stride=params.get("stride", params["kernel_size"]),
            )
            B, C, H, W = input_shape
            H_out = (H - params["kernel_size"]) // params.get(
                "stride", params["kernel_size"]
            ) + 1
            W_out = (W - params["kernel_size"]) // params.get(
                "stride", params["kernel_size"]
            ) + 1
            config.output_shape = (B, C, H_out, W_out)

        elif layer_type == "Flatten":
            layer = nn.Flatten()
            B = input_shape[0]
            flat_size = np.prod(input_shape[1:])
            config.output_shape = (B, int(flat_size))

        elif layer_type == "BatchNorm2d":
            layer = nn.BatchNorm2d(params["num_features"])
            config.output_shape = input_shape

        elif layer_type == "Dropout":
            layer = nn.Dropout(params.get("p", 0.5))
            config.output_shape = input_shape

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å±‚ç±»å‹: {layer_type}")

        # è®¡ç®—å‚æ•°é‡
        config.param_count = sum(p.numel() for p in layer.parameters())

        return layer

    except Exception as e:
        st.error(f"åˆ›å»ºå±‚å¤±è´¥: {e}")
        return None


def detect_layer_issues(config: LayerConfig, input_shape, prev_config=None) -> None:
    """
    æ£€æµ‹å±‚çš„æ½œåœ¨é—®é¢˜

    Args:
        config: å½“å‰å±‚é…ç½®
        input_shape: è¾“å…¥å½¢çŠ¶
        prev_config: å‰ä¸€å±‚é…ç½®ï¼ˆå¯é€‰ï¼‰
    """
    config.issues = []
    config.warnings = []
    config.recommendations = []
    config.has_issues = False

    layer_type = config.layer_type
    params = config.params

    # æ£€æµ‹Conv2dé—®é¢˜
    if layer_type == "Conv2d":
        # æ£€æŸ¥è¾“å…¥ç»´åº¦
        if len(input_shape) != 4:
            config.issues.append(f"âŒ Conv2déœ€è¦4Dè¾“å…¥ï¼Œå½“å‰: {len(input_shape)}D")
            config.recommendations.append("ç¡®ä¿è¾“å…¥æ˜¯ (Batch, Channels, Height, Width)")
            config.has_issues = True
        else:
            in_channels = input_shape[1]
            expected_in = params["in_channels"]
            if in_channels != expected_in:
                config.issues.append(
                    f"âŒ é€šé“æ•°ä¸åŒ¹é…: è¾“å…¥{in_channels}, æœŸæœ›{expected_in}"
                )
                config.recommendations.append(f"å°†in_channelsæ”¹ä¸º{in_channels}")
                config.has_issues = True

            # æ£€æŸ¥kernel_sizeæ˜¯å¦è¿‡å¤§
            H, W = input_shape[2], input_shape[3]
            k = params["kernel_size"]
            p = params.get("padding", 0)
            if k > H + 2 * p or k > W + 2 * p:
                config.warnings.append(f"âš ï¸ å·ç§¯æ ¸({k})å¯èƒ½è¿‡å¤§")
                config.recommendations.append("å‡å°kernel_sizeæˆ–å¢åŠ padding")

        # æ£€æŸ¥å‚æ•°æ•°é‡
        param_count = (
            params["in_channels"]
            * params["out_channels"]
            * (params["kernel_size"] ** 2)
        )
        if param_count > 1_000_000:
            config.warnings.append(f"âš ï¸ å‚æ•°é‡è¾ƒå¤§: {param_count:,}")
            config.recommendations.append("è€ƒè™‘ä½¿ç”¨åˆ†ç»„å·ç§¯æˆ–å‡å°‘é€šé“æ•°")

    # æ£€æµ‹Linearé—®é¢˜
    elif layer_type == "Linear":
        if len(input_shape) == 4:
            config.issues.append("âŒ Linearå±‚éœ€è¦2Dè¾“å…¥ï¼Œä½†è¾“å…¥æ˜¯4D")
            config.recommendations.append("åœ¨Linearå‰æ·»åŠ Flattenå±‚")
            config.has_issues = True
        elif len(input_shape) == 2:
            in_features = input_shape[1]
            expected_in = params["in_features"]
            if in_features != expected_in:
                config.issues.append(
                    f"âŒ ç‰¹å¾æ•°ä¸åŒ¹é…: è¾“å…¥{in_features}, æœŸæœ›{expected_in}"
                )
                config.recommendations.append(f"å°†in_featuresæ”¹ä¸º{in_features}")
                config.has_issues = True

        # æ£€æŸ¥å‚æ•°æ•°é‡
        param_count = params["in_features"] * params["out_features"]
        if param_count > 10_000_000:
            config.warnings.append(f"âš ï¸ å‚æ•°é‡éå¸¸å¤§: {param_count:,}")
            config.recommendations.append("è€ƒè™‘ä½¿ç”¨Global Average Poolingå‡å°‘ç‰¹å¾ç»´åº¦")

    # æ£€æµ‹BatchNormé—®é¢˜
    elif layer_type == "BatchNorm2d":
        if len(input_shape) != 4:
            config.issues.append(f"âŒ BatchNorm2déœ€è¦4Dè¾“å…¥")
            config.has_issues = True
        else:
            num_channels = input_shape[1]
            expected = params["num_features"]
            if num_channels != expected:
                config.issues.append(
                    f"âŒ é€šé“æ•°ä¸åŒ¹é…: è¾“å…¥{num_channels}, æœŸæœ›{expected}"
                )
                config.recommendations.append(f"å°†num_featuresæ”¹ä¸º{num_channels}")
                config.has_issues = True

    # æ£€æµ‹Flattenåæ¥Conv2dçš„é—®é¢˜
    if layer_type == "Conv2d" and prev_config and prev_config.layer_type == "Flatten":
        config.issues.append("âŒ ä¸èƒ½åœ¨Flattenåæ¥Conv2d")
        config.recommendations.append("å·ç§¯å±‚åº”è¯¥åœ¨Flattenä¹‹å‰")
        config.has_issues = True

    # æ£€æµ‹è¿ç»­çš„Poolingå±‚
    if (
        layer_type == "MaxPool2d"
        and prev_config
        and prev_config.layer_type == "MaxPool2d"
    ):
        config.warnings.append("âš ï¸ è¿ç»­çš„Poolingå±‚å¯èƒ½å¯¼è‡´ä¿¡æ¯æŸå¤±è¿‡å¤§")
        config.recommendations.append("è€ƒè™‘åœ¨Poolingå±‚ä¹‹é—´æ·»åŠ å·ç§¯å±‚")


def visualize_network_flow(layers_config):
    """å¯è§†åŒ–ç½‘ç»œæµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼Œå¸¦é—®é¢˜æ ‡æ³¨ï¼‰"""
    if not layers_config:
        return None

    fig = go.Figure()

    # åˆ›å»ºæµç¨‹å›¾èŠ‚ç‚¹
    y_pos = 0
    annotations = []

    for i, config in enumerate(layers_config):
        # èŠ‚ç‚¹é¢œè‰²ï¼ˆæ ¹æ®é—®é¢˜çŠ¶æ€ï¼‰
        if config.has_issues:
            color = "#ffcccb"  # çº¢è‰²ï¼ˆæœ‰é”™è¯¯ï¼‰
            border_color = "red"
            border_width = 3
        elif config.warnings:
            color = "#fff8dc"  # é»„è‰²ï¼ˆæœ‰è­¦å‘Šï¼‰
            border_color = "orange"
            border_width = 3
        elif config.layer_type in ["Conv2d", "Linear"]:
            color = "lightblue"
            border_color = "black"
            border_width = 2
        elif config.layer_type in ["ReLU", "Sigmoid", "Tanh"]:
            color = "lightgreen"
            border_color = "black"
            border_width = 2
        elif config.layer_type in ["MaxPool2d", "AvgPool2d"]:
            color = "lightyellow"
            border_color = "black"
            border_width = 2
        else:
            color = "lightgray"
            border_color = "black"
            border_width = 2

        # ç»˜åˆ¶èŠ‚ç‚¹
        fig.add_trace(
            go.Scatter(
                x=[0.5],
                y=[y_pos],
                mode="markers+text",
                marker=dict(
                    size=80,
                    color=color,
                    line=dict(color=border_color, width=border_width),
                ),
                text=f"{config.name}",
                textposition="middle center",
                showlegend=False,
                hovertext=f"{config.layer_type}<br>è¾“å‡º: {config.output_shape}",
                hoverinfo="text",
            )
        )

        # æ·»åŠ è¯¦ç»†ä¿¡æ¯
        info_text = f"<b>{config.layer_type}</b><br>"
        if config.output_shape:
            info_text += f"è¾“å‡º: {config.output_shape}<br>"
        if config.param_count > 0:
            info_text += f"å‚æ•°: {config.param_count:,}<br>"
        if config.memory > 0:
            info_text += f"å†…å­˜: {config.memory:.2f}MB"

        annotations.append(
            dict(
                x=1.2,
                y=y_pos,
                text=info_text,
                showarrow=False,
                xanchor="left",
                font=dict(size=10),
                bgcolor="rgba(255,255,255,0.8)",
                borderpad=4,
            )
        )

        # ç»˜åˆ¶è¿æ¥çº¿
        if i < len(layers_config) - 1:
            fig.add_trace(
                go.Scatter(
                    x=[0.5, 0.5],
                    y=[y_pos, y_pos - 1],
                    mode="lines",
                    line=dict(color="gray", width=2),
                    showlegend=False,
                    hoverinfo="skip",
                )
            )

        y_pos -= 1

    fig.update_layout(
        title="ç½‘ç»œæ¶æ„æµç¨‹å›¾",
        xaxis=dict(visible=False, range=[0, 2.5]),
        yaxis=dict(visible=False, range=[y_pos, 1]),
        height=max(400, len(layers_config) * 100),
        annotations=annotations,
        showlegend=False,
        margin=dict(l=20, r=300, t=50, b=20),
    )

    return fig


def simulate_forward_pass(model, input_data):
    """æ¨¡æ‹Ÿå‰å‘ä¼ æ’­ï¼Œæ”¶é›†æ¯å±‚è¾“å‡º"""
    activations = []

    def hook_fn(name):
        def hook(module, input, output):
            if isinstance(output, torch.Tensor):
                activations.append(
                    {
                        "name": name,
                        "output": output.detach().cpu(),
                        "shape": tuple(output.shape),
                        "mean": output.mean().item(),
                        "std": output.std().item(),
                        "min": output.min().item(),
                        "max": output.max().item(),
                    }
                )

        return hook

    # æ³¨å†Œhooks
    hooks = []
    for name, module in model.named_modules():
        if isinstance(
            module, (nn.Conv2d, nn.Linear, nn.ReLU, nn.MaxPool2d, nn.Flatten)
        ):
            hooks.append(module.register_forward_hook(hook_fn(name)))

    # å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        output = model(input_data)

    # ç§»é™¤hooks
    for hook in hooks:
        hook.remove()

    return output, activations


def visualize_activation_heatmap(activation_data):
    """å¯è§†åŒ–æ¿€æ´»å€¼çƒ­åŠ›å›¾"""
    output = activation_data["output"]

    # å¦‚æœæ˜¯4Då¼ é‡ï¼ˆå›¾åƒï¼‰ï¼Œå–ç¬¬ä¸€ä¸ªæ ·æœ¬å’Œç¬¬ä¸€ä¸ªé€šé“
    if len(output.shape) == 4:
        heatmap_data = output[0, 0].numpy()
    # å¦‚æœæ˜¯2Då¼ é‡ï¼Œç›´æ¥ä½¿ç”¨
    elif len(output.shape) == 2:
        heatmap_data = output[0].reshape(-1, 1).numpy()
    else:
        return None

    fig = go.Figure(data=go.Heatmap(z=heatmap_data, colorscale="Viridis"))

    fig.update_layout(title=f"{activation_data['name']} - æ¿€æ´»å€¼çƒ­åŠ›å›¾", height=400)

    return fig


def export_network_config(layers: List[LayerConfig], input_shape: Tuple) -> str:
    """å¯¼å‡ºç½‘ç»œé…ç½®ä¸ºJSON"""
    config_dict = {
        "input_shape": input_shape,
        "layers": [layer.to_dict() for layer in layers],
    }
    return json.dumps(config_dict, indent=2)


def import_network_config(json_str: str) -> Tuple[List[LayerConfig], Tuple]:
    """ä»JSONå¯¼å…¥ç½‘ç»œé…ç½®"""
    config_dict = json.loads(json_str)
    layers = [LayerConfig.from_dict(layer_data) for layer_data in config_dict["layers"]]
    input_shape = tuple(config_dict["input_shape"])
    return layers, input_shape


def architecture_designer_tab(chinese_supported=True):
    """æ¶æ„è®¾è®¡å·¥ä½œå°ä¸»å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    st.header("ğŸ¨ æ¶æ„è®¡ç®—è§£å‰–å·¥ä½œå°")
    st.markdown(
        """
    > **æ ¸å¿ƒåŠŸèƒ½**ï¼šæ·±å…¥è§£å‰–ç¥ç»ç½‘ç»œæ¯ä¸€æ­¥çš„æ•°å€¼è®¡ç®—è¿‡ç¨‹
    
    **è®¡ç®—è§£å‰–ç»´åº¦**ï¼š
    - ğŸ”¢ **æ•°å€¼è®¡ç®—å…¬å¼**ï¼šæ¯å±‚çš„å…·ä½“æ•°å­¦è®¡ç®—è¿‡ç¨‹
    - ğŸ“Š **æ•°å€¼ä¼ æ’­è¿½è¸ª**ï¼šæ¿€æ´»å€¼å¦‚ä½•é€å±‚å˜åŒ–
    - ğŸ§® **å‚æ•°è®¡ç®—æ¨å¯¼**ï¼šä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªå‚æ•°é‡ï¼Ÿ
    - ğŸŒŠ **æ¢¯åº¦æ•°å€¼åˆ†æ**ï¼šæ¢¯åº¦å¦‚ä½•åå‘ä¼ æ’­
    - âš ï¸ **æ•°å€¼ç¨³å®šæ€§**ï¼šä»€ä¹ˆæ—¶å€™ä¼šå‡ºç°æ•°å€¼é—®é¢˜ï¼Ÿ
    """
    )

    st.markdown("---")

    # åˆå§‹åŒ–session state
    if "layers" not in st.session_state:
        st.session_state.layers = []
    if "input_shape" not in st.session_state:
        st.session_state.input_shape = (1, 3, 224, 224)

    # å·¦å³åˆ†æ 
    col_left, col_right = st.columns([1, 2])

    with col_left:
        st.subheader("ğŸ”§ å±‚é…ç½®")

        # è¾“å…¥å½¢çŠ¶è®¾ç½®
        with st.expander("âš™ï¸ è¾“å…¥é…ç½®", expanded=True):
            # è‡ªåŠ¨æ£€æµ‹è¾“å…¥ç±»å‹
            current_shape = st.session_state.input_shape
            if len(current_shape) == 4:
                default_input_type = "å›¾åƒ"
            else:
                default_input_type = "å‘é‡"

            input_type_index = 0 if default_input_type == "å›¾åƒ" else 1
            input_type = st.selectbox(
                "è¾“å…¥ç±»å‹",
                ["å›¾åƒ", "å‘é‡"],
                index=input_type_index,
                key="input_type_selector",
            )

            if input_type == "å›¾åƒ":
                col1, col2 = st.columns(2)
                with col1:
                    # ä»å½“å‰å½¢çŠ¶è¯»å–é»˜è®¤å€¼
                    default_channels = (
                        current_shape[1] if len(current_shape) == 4 else 3
                    )
                    channels = st.number_input(
                        "é€šé“æ•°", 1, 4, default_channels, key="input_channels"
                    )
                with col2:
                    default_size = current_shape[2] if len(current_shape) == 4 else 224
                    size_options = [28, 32, 64, 224]
                    default_index = (
                        size_options.index(default_size)
                        if default_size in size_options
                        else 3
                    )
                    img_size = st.selectbox(
                        "å›¾åƒå°ºå¯¸", size_options, index=default_index, key="input_size"
                    )
                st.session_state.input_shape = (1, channels, img_size, img_size)
            else:
                # ä»å½“å‰å½¢çŠ¶è¯»å–é»˜è®¤å€¼
                default_vector_size = (
                    current_shape[1] if len(current_shape) == 2 else 784
                )
                vector_size = st.number_input(
                    "å‘é‡ç»´åº¦", 1, 100000, default_vector_size, key="vector_size"
                )
                st.session_state.input_shape = (1, vector_size)

            st.info(f"å½“å‰è¾“å…¥å½¢çŠ¶: `{st.session_state.input_shape}`")

        # æ·»åŠ å±‚
        with st.expander("â• æ·»åŠ å±‚", expanded=True):
            layer_type = st.selectbox(
                "é€‰æ‹©å±‚ç±»å‹",
                [
                    "Conv2d",
                    "Linear",
                    "ReLU",
                    "MaxPool2d",
                    "Flatten",
                    "BatchNorm2d",
                    "Dropout",
                ],
            )

            layer_name = st.text_input(
                "å±‚åç§°", f"{layer_type}_{len(st.session_state.layers)+1}"
            )

            params = {}

            if layer_type == "Conv2d":
                col1, col2 = st.columns(2)
                with col1:
                    # æ™ºèƒ½é»˜è®¤å€¼ï¼šè‡ªåŠ¨åŒ¹é…å‰ä¸€å±‚çš„è¾“å‡º
                    if len(st.session_state.layers) == 0:
                        # ç¬¬ä¸€å±‚ï¼šåŒ¹é…è¾“å…¥é€šé“æ•°
                        default_in_channels = st.session_state.input_shape[1]
                    else:
                        # åç»­å±‚ï¼šåŒ¹é…å‰ä¸€å±‚è¾“å‡º
                        prev_layer = st.session_state.layers[-1]
                        if prev_layer.layer_type == "Conv2d":
                            default_in_channels = prev_layer.params.get(
                                "out_channels", 64
                            )
                        elif prev_layer.layer_type == "BatchNorm2d":
                            default_in_channels = prev_layer.params.get(
                                "num_features", 64
                            )
                        elif (
                            prev_layer.output_shape
                            and len(prev_layer.output_shape) == 4
                        ):
                            default_in_channels = prev_layer.output_shape[1]
                        else:
                            default_in_channels = 64
                    params["in_channels"] = st.number_input(
                        "è¾“å…¥é€šé“", 1, 512, default_in_channels
                    )
                    params["out_channels"] = st.number_input("è¾“å‡ºé€šé“", 1, 512, 64)
                with col2:
                    params["kernel_size"] = st.number_input("å·ç§¯æ ¸å¤§å°", 1, 11, 3)
                    params["stride"] = st.number_input("æ­¥é•¿", 1, 4, 1)
                    params["padding"] = st.number_input("å¡«å……", 0, 10, 1)

            elif layer_type == "Linear":
                # æ™ºèƒ½é»˜è®¤å€¼ï¼šè‡ªåŠ¨è®¡ç®— Flatten åçš„ç‰¹å¾æ•°
                if len(st.session_state.layers) > 0:
                    prev_layer = st.session_state.layers[-1]
                    if prev_layer.layer_type == "Flatten" and prev_layer.output_shape:
                        # Flatten åçš„è¾“å‡ºæ˜¯ (batch, features)
                        default_in_features = prev_layer.output_shape[1]
                    elif prev_layer.layer_type == "Linear":
                        default_in_features = prev_layer.params.get("out_features", 128)
                    elif prev_layer.output_shape and len(prev_layer.output_shape) == 2:
                        default_in_features = prev_layer.output_shape[1]
                    else:
                        default_in_features = 784
                else:
                    default_in_features = 784

                # æ˜¾ç¤ºæç¤ºä¿¡æ¯
                if (
                    len(st.session_state.layers) > 0
                    and st.session_state.layers[-1].layer_type == "Flatten"
                ):
                    st.info(f"ğŸ’¡ Flattenåç‰¹å¾æ•°: {default_in_features:,}")

                params["in_features"] = st.number_input(
                    "è¾“å…¥ç‰¹å¾", 1, 10000000, default_in_features
                )
                params["out_features"] = st.number_input("è¾“å‡ºç‰¹å¾", 1, 10000, 128)

            elif layer_type == "MaxPool2d":
                params["kernel_size"] = st.number_input("æ± åŒ–æ ¸å¤§å°", 2, 8, 2)
                params["stride"] = st.number_input("æ­¥é•¿", 1, 8, 2)

            elif layer_type == "BatchNorm2d":
                # æ™ºèƒ½é»˜è®¤å€¼ï¼šåŒ¹é…å‰ä¸€å±‚çš„é€šé“æ•°
                if len(st.session_state.layers) > 0:
                    prev_layer = st.session_state.layers[-1]
                    if prev_layer.layer_type == "Conv2d":
                        default_num_features = prev_layer.params.get("out_channels", 64)
                    elif prev_layer.output_shape and len(prev_layer.output_shape) == 4:
                        default_num_features = prev_layer.output_shape[1]
                    else:
                        default_num_features = 64
                else:
                    default_num_features = 64
                params["num_features"] = st.number_input(
                    "ç‰¹å¾æ•°", 1, 512, default_num_features
                )

            elif layer_type == "Dropout":
                params["p"] = st.slider("ä¸¢å¼ƒç‡", 0.0, 0.9, 0.5)

            if st.button("â• æ·»åŠ åˆ°ç½‘ç»œ"):
                config = LayerConfig(layer_type, layer_name, params)
                st.session_state.layers.append(config)
                st.success(f"âœ… å·²æ·»åŠ  {layer_name}")
                st.rerun()

        # å±‚ç®¡ç†ï¼ˆå¢å¼ºç‰ˆï¼šå¸¦ä¸Šä¸‹ç§»åŠ¨ï¼‰
        if st.session_state.layers:
            with st.expander("ğŸ“‹ å±‚ç®¡ç†", expanded=True):
                for i, layer in enumerate(st.session_state.layers):
                    col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                    with col1:
                        # æ˜¾ç¤ºå±‚åå’ŒçŠ¶æ€å›¾æ ‡
                        status_icon = (
                            "âŒ"
                            if layer.has_issues
                            else ("âš ï¸" if layer.warnings else "âœ…")
                        )
                        st.write(
                            f"{i+1}. {status_icon} {layer.name} ({layer.layer_type})"
                        )
                    with col2:
                        if i > 0 and st.button("â¬†ï¸", key=f"up_{i}", help="ä¸Šç§»"):
                            (
                                st.session_state.layers[i],
                                st.session_state.layers[i - 1],
                            ) = (
                                st.session_state.layers[i - 1],
                                st.session_state.layers[i],
                            )
                            st.rerun()
                    with col3:
                        if i < len(st.session_state.layers) - 1 and st.button(
                            "â¬‡ï¸", key=f"down_{i}", help="ä¸‹ç§»"
                        ):
                            (
                                st.session_state.layers[i],
                                st.session_state.layers[i + 1],
                            ) = (
                                st.session_state.layers[i + 1],
                                st.session_state.layers[i],
                            )
                            st.rerun()
                    with col4:
                        if st.button("ğŸ—‘ï¸", key=f"del_{i}", help="åˆ é™¤"):
                            st.session_state.layers.pop(i)
                            st.rerun()

        # å¯¼å…¥/å¯¼å‡ºé…ç½®
        with st.expander("ğŸ’¾ å¯¼å…¥/å¯¼å‡º", expanded=False):
            st.markdown("**å¯¼å‡ºé…ç½®**")
            if st.session_state.layers:
                config_json = export_network_config(
                    st.session_state.layers, st.session_state.input_shape
                )
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½é…ç½®æ–‡ä»¶",
                    data=config_json,
                    file_name="network_config.json",
                    mime="application/json",
                )
                st.code(config_json, language="json")
            else:
                st.info("æš‚æ— ç½‘ç»œé…ç½®")

            st.markdown("---")
            st.markdown("**å¯¼å…¥é…ç½®**")
            uploaded_config = st.file_uploader("ä¸Šä¼ é…ç½®æ–‡ä»¶ (JSON)", type=["json"])
            if uploaded_config:
                try:
                    config_json = uploaded_config.read().decode("utf-8")
                    layers, input_shape = import_network_config(config_json)
                    if st.button("âœ… åº”ç”¨é…ç½®"):
                        st.session_state.layers = layers
                        st.session_state.input_shape = input_shape
                        st.success("é…ç½®å·²å¯¼å…¥ï¼")
                        st.rerun()
                except Exception as e:
                    st.error(f"å¯¼å…¥å¤±è´¥: {e}")

    with col_right:
        st.subheader("ğŸ“Š ç½‘ç»œåˆ†æ")

        if not st.session_state.layers:
            st.info("ğŸ‘ˆ ä»å·¦ä¾§æ·»åŠ å±‚å¼€å§‹æ„å»ºç½‘ç»œ")
        else:
            # ğŸ”„ å¼ºåˆ¶é‡æ–°è®¡ç®—æ‰€æœ‰å±‚çš„è¾“å‡ºå½¢çŠ¶ï¼ˆç¡®ä¿æ•°æ®åŒæ­¥ï¼‰
            current_shape = st.session_state.input_shape
            valid_network = True
            has_any_issues = False
            has_any_warnings = False

            # ç¬¬ä¸€éï¼šé‡æ–°è®¡ç®—æ‰€æœ‰è¾“å‡ºå½¢çŠ¶
            for idx, config in enumerate(st.session_state.layers):
                try:
                    layer = create_layer_from_config(config, current_shape)
                    if layer is None:
                        valid_network = False
                        break
                    current_shape = config.output_shape
                except:
                    valid_network = False
                    break

            # ç¬¬äºŒéï¼šæ£€æµ‹é—®é¢˜
            current_shape = st.session_state.input_shape
            for idx, config in enumerate(st.session_state.layers):
                prev_config = st.session_state.layers[idx - 1] if idx > 0 else None

                try:
                    # æ£€æµ‹é—®é¢˜
                    detect_layer_issues(config, current_shape, prev_config)

                    if config.has_issues:
                        has_any_issues = True
                    if config.warnings:
                        has_any_warnings = True

                    # æ›´æ–°å½“å‰å½¢çŠ¶
                    if config.output_shape:
                        current_shape = config.output_shape
                        # è®¡ç®—å†…å­˜
                        config.memory = get_tensor_memory(config.output_shape)
                    else:
                        valid_network = False
                        break

                except Exception as e:
                    st.error(f"å±‚ {config.name} é…ç½®é”™è¯¯: {e}")
                    valid_network = False
                    break

            # æ˜¾ç¤ºé—®é¢˜æ‘˜è¦
            if has_any_issues or has_any_warnings:
                st.markdown("#### âš ï¸ é—®é¢˜æ£€æµ‹")

                issue_count = sum(1 for c in st.session_state.layers if c.has_issues)
                warning_count = sum(
                    1
                    for c in st.session_state.layers
                    if c.warnings and not c.has_issues
                )

                col1, col2, col3 = st.columns(3)
                with col1:
                    if issue_count > 0:
                        st.error(f"âŒ å‘ç° {issue_count} ä¸ªé”™è¯¯")
                with col2:
                    if warning_count > 0:
                        st.warning(f"âš ï¸ å‘ç° {warning_count} ä¸ªè­¦å‘Š")
                with col3:
                    if issue_count > 0 and st.button(
                        "ğŸ”§ ä¸€é”®ä¿®å¤", type="primary", help="è‡ªåŠ¨ä¿®æ­£æ‰€æœ‰å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜"
                    ):
                        # è‡ªåŠ¨ä¿®å¤æ‰€æœ‰å±‚ - æ”¹è¿›ç‰ˆï¼ˆæ”¯æŒè‡ªåŠ¨æ’å…¥Flattenï¼‰
                        temp_shape = st.session_state.input_shape
                        fixed_count = 0
                        new_layers = []

                        for idx, config in enumerate(st.session_state.layers):
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å…¥Flattenå±‚
                            if config.layer_type == "Linear" and len(temp_shape) == 4:
                                # éœ€è¦åœ¨Linearå‰æ’å…¥Flatten
                                flatten_config = LayerConfig(
                                    "Flatten", f"flatten_auto_{idx}", {}
                                )
                                flatten_layer = create_layer_from_config(
                                    flatten_config, temp_shape
                                )
                                new_layers.append(flatten_config)
                                temp_shape = flatten_config.output_shape
                                fixed_count += 1

                            # æ ¹æ®å½“å‰å½¢çŠ¶ä¿®å¤å‚æ•°
                            if config.layer_type == "Conv2d" and len(temp_shape) == 4:
                                if config.params["in_channels"] != temp_shape[1]:
                                    config.params["in_channels"] = temp_shape[1]
                                    fixed_count += 1

                            elif (
                                config.layer_type == "BatchNorm2d"
                                and len(temp_shape) == 4
                            ):
                                if config.params["num_features"] != temp_shape[1]:
                                    config.params["num_features"] = temp_shape[1]
                                    fixed_count += 1

                            elif config.layer_type == "Linear" and len(temp_shape) == 2:
                                if config.params["in_features"] != temp_shape[1]:
                                    config.params["in_features"] = temp_shape[1]
                                    fixed_count += 1

                            # æ·»åŠ å½“å‰å±‚
                            new_layers.append(config)

                            # é‡æ–°è®¡ç®—è¾“å‡ºå½¢çŠ¶ï¼ˆä½¿ç”¨ä¿®å¤åçš„å‚æ•°ï¼‰
                            try:
                                layer = create_layer_from_config(config, temp_shape)
                                if config.output_shape:
                                    temp_shape = config.output_shape
                            except Exception as e:
                                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­
                                pass

                        # æ›´æ–°å±‚åˆ—è¡¨
                        st.session_state.layers = new_layers

                        if fixed_count > 0:
                            st.success(f"âœ… è‡ªåŠ¨ä¿®å¤å®Œæˆï¼å·²ä¿®æ­£ {fixed_count} ä¸ªé—®é¢˜")
                        else:
                            st.info("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦ä¿®å¤çš„å‚æ•°")
                        st.rerun()

                # æ˜¾ç¤ºè¯¦ç»†é—®é¢˜
                for i, config in enumerate(st.session_state.layers):
                    if config.issues or config.warnings:
                        with st.expander(
                            f"{'âŒ' if config.has_issues else 'âš ï¸'} {config.name} - é—®é¢˜è¯¦æƒ…",
                            expanded=config.has_issues,
                        ):
                            if config.issues:
                                st.markdown("**é”™è¯¯ï¼š**")
                                for issue in config.issues:
                                    st.markdown(f"- {issue}")

                            if config.warnings:
                                st.markdown("**è­¦å‘Šï¼š**")
                                for warning in config.warnings:
                                    st.markdown(f"- {warning}")

                            if config.recommendations:
                                st.markdown("**å»ºè®®ï¼š**")
                                for rec in config.recommendations:
                                    st.markdown(f"- ğŸ’¡ {rec}")

                st.markdown("---")

            if valid_network:
                # æ˜¾ç¤ºç½‘ç»œæµç¨‹å›¾
                fig = visualize_network_flow(st.session_state.layers)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)

                # æ˜¾ç¤ºæ€»ç»“
                st.markdown("#### ğŸ“‹ ç½‘ç»œæ€»ç»“")

                total_params = sum(
                    config.param_count for config in st.session_state.layers
                )
                total_memory = sum(config.memory for config in st.session_state.layers)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»å±‚æ•°", len(st.session_state.layers))
                with col2:
                    st.metric("æ€»å‚æ•°é‡", f"{total_params:,}")
                with col3:
                    st.metric("æ¿€æ´»å†…å­˜", f"{total_memory:.2f} MB")
                with col4:
                    st.metric("è¾“å‡ºå½¢çŠ¶", str(current_shape))

                # ==================== ç½‘ç»œç¨³å®šæ€§è¯Šæ–­ ====================
                st.markdown("---")
                st.markdown("#### ğŸ”¬ ç½‘ç»œç¨³å®šæ€§è¯Šæ–­")

                stability_issues = []

                # 1. æ£€æŸ¥æ€»å‚æ•°é‡
                if total_params > 1e9:
                    stability_issues.append(
                        {
                            "status": "error",
                            "type": "å‚æ•°é‡è¿‡å¤§",
                            "value": f"{total_params/1e9:.2f}B",
                            "threshold": "> 1B",
                            "icon": "ğŸ”´",
                            "severity": "critical",
                            "details": {
                                "æ€»å‚æ•°": f"{total_params:,}",
                                "å±‚æ•°": len(st.session_state.layers),
                            },
                            "solution": [
                                "ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯å‡å°‘å‚æ•°",
                                "å‡å°‘å…¨è¿æ¥å±‚ç¥ç»å…ƒæ•°é‡",
                                "ä½¿ç”¨MobileNet/EfficientNetæ¶æ„",
                                "æ·»åŠ æ›´å¤šPoolingå±‚",
                            ],
                            "explanation": "å‚æ•°é‡è¿‡å¤§ä¼šå¯¼è‡´æ˜¾å­˜ä¸è¶³ã€è®­ç»ƒæ…¢ã€å®¹æ˜“è¿‡æ‹Ÿåˆ",
                        }
                    )
                elif total_params > 1e8:
                    stability_issues.append(
                        {
                            "status": "warning",
                            "type": "å‚æ•°é‡è¾ƒå¤§",
                            "value": f"{total_params/1e6:.1f}M",
                            "threshold": "> 100M",
                            "icon": "ğŸŸ¡",
                            "severity": "medium",
                            "details": {
                                "æ€»å‚æ•°": f"{total_params:,}",
                                "ä¼°ç®—æ˜¾å­˜": f"{total_params * 4 / 1024 / 1024:.1f} MB",
                            },
                            "solution": [
                                "ç›‘æ§æ˜¾å­˜ä½¿ç”¨",
                                "è€ƒè™‘ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ",
                                "é€‚å½“å‡å°‘batch size",
                            ],
                            "explanation": "å‚æ•°é‡è¾ƒå¤§ï¼Œæ³¨æ„æ˜¾å­˜ç®¡ç†",
                        }
                    )
                else:
                    stability_issues.append(
                        {
                            "status": "success",
                            "type": "å‚æ•°é‡",
                            "value": (
                                f"{total_params/1e6:.2f}M"
                                if total_params > 1e6
                                else f"{total_params:,}"
                            ),
                            "icon": "ğŸŸ¢",
                            "severity": "none",
                        }
                    )

                # 2. æ£€æŸ¥æ¿€æ´»å†…å­˜
                if total_memory > 1000:
                    stability_issues.append(
                        {
                            "status": "error",
                            "type": "æ¿€æ´»å†…å­˜è¿‡å¤§",
                            "value": f"{total_memory:.1f} MB",
                            "threshold": "> 1000 MB",
                            "icon": "ğŸ”´",
                            "severity": "high",
                            "details": {
                                "æ¿€æ´»å†…å­˜": f"{total_memory:.1f} MB",
                                "ä¼°ç®—æ€»æ˜¾å­˜": f"{total_memory * 3:.1f} MB (å«æ¢¯åº¦)",
                            },
                            "solution": [
                                "å‡å°batch size",
                                "å¢åŠ Poolingå±‚",
                                "ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹(gradient checkpointing)",
                                "å‡å°‘è¾“å…¥å›¾åƒå°ºå¯¸",
                            ],
                            "explanation": "æ¿€æ´»å†…å­˜è¿‡å¤§ä¼šå¯¼è‡´OOMï¼ˆæ˜¾å­˜æº¢å‡ºï¼‰",
                        }
                    )
                elif total_memory > 500:
                    stability_issues.append(
                        {
                            "status": "warning",
                            "type": "æ¿€æ´»å†…å­˜è¾ƒå¤§",
                            "value": f"{total_memory:.1f} MB",
                            "threshold": "> 500 MB",
                            "icon": "ğŸŸ¡",
                            "severity": "medium",
                            "solution": ["ç›‘æ§æ˜¾å­˜ä½¿ç”¨", "è€ƒè™‘å‡å°batch size"],
                            "explanation": "æ¿€æ´»å†…å­˜è¾ƒå¤§ï¼Œæ³¨æ„batch sizeè®¾ç½®",
                        }
                    )

                # 3. è¯†åˆ«ç“¶é¢ˆå±‚
                if st.session_state.layers:
                    max_params_layer = max(
                        st.session_state.layers, key=lambda x: x.param_count
                    )
                    max_memory_layer = max(
                        st.session_state.layers, key=lambda x: x.memory
                    )

                    params_ratio = max_params_layer.param_count / (total_params + 1)
                    memory_ratio = max_memory_layer.memory / (total_memory + 1)

                    if params_ratio > 0.5:
                        stability_issues.append(
                            {
                                "status": "warning",
                                "type": "å‚æ•°ç“¶é¢ˆå±‚",
                                "value": f"{max_params_layer.name} ({params_ratio*100:.1f}%)",
                                "threshold": "> 50%",
                                "icon": "ğŸŸ¡",
                                "severity": "medium",
                                "details": {
                                    "ç“¶é¢ˆå±‚": max_params_layer.name,
                                    "å‚æ•°é‡": f"{max_params_layer.param_count:,}",
                                    "å æ¯”": f"{params_ratio*100:.1f}%",
                                },
                                "solution": [
                                    "å‡å°‘è¯¥å±‚çš„ç¥ç»å…ƒæ•°é‡",
                                    "ä½¿ç”¨å‚æ•°åˆ†è§£æŠ€æœ¯",
                                    "è€ƒè™‘ä½¿ç”¨ç“¶é¢ˆç»“æ„",
                                ],
                                "explanation": f"{max_params_layer.name}å±‚å ç”¨äº†è¶…è¿‡ä¸€åŠçš„å‚æ•°",
                            }
                        )

                    if memory_ratio > 0.5:
                        stability_issues.append(
                            {
                                "status": "warning",
                                "type": "å†…å­˜ç“¶é¢ˆå±‚",
                                "value": f"{max_memory_layer.name} ({memory_ratio*100:.1f}%)",
                                "threshold": "> 50%",
                                "icon": "ğŸŸ¡",
                                "severity": "medium",
                                "details": {
                                    "ç“¶é¢ˆå±‚": max_memory_layer.name,
                                    "å†…å­˜": f"{max_memory_layer.memory:.2f} MB",
                                    "å æ¯”": f"{memory_ratio*100:.1f}%",
                                },
                                "solution": [
                                    "åœ¨è¯¥å±‚ä¹‹å‰æ·»åŠ Pooling",
                                    "å‡å°‘è¯¥å±‚çš„é€šé“æ•°",
                                    "ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯",
                                ],
                                "explanation": f"{max_memory_layer.name}å±‚å ç”¨äº†è¶…è¿‡ä¸€åŠçš„æ¿€æ´»å†…å­˜",
                            }
                        )

                # 4. æ£€æŸ¥ç½‘ç»œæ·±åº¦
                conv_count = sum(
                    1 for c in st.session_state.layers if "Conv" in c.layer_type
                )
                fc_count = sum(
                    1 for c in st.session_state.layers if c.layer_type == "Linear"
                )

                if conv_count > 50:
                    stability_issues.append(
                        {
                            "status": "warning",
                            "type": "ç½‘ç»œè¿‡æ·±",
                            "value": f"{conv_count}å±‚å·ç§¯",
                            "threshold": "> 50å±‚",
                            "icon": "ğŸŸ¡",
                            "severity": "medium",
                            "solution": [
                                "ä½¿ç”¨æ®‹å·®è¿æ¥ï¼ˆResNetï¼‰",
                                "ä½¿ç”¨BatchNormç¨³å®šè®­ç»ƒ",
                                "è€ƒè™‘ä½¿ç”¨DenseNetæˆ–å…¶ä»–skip connection",
                            ],
                            "explanation": "æ·±å±‚ç½‘ç»œå®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±ï¼Œéœ€è¦ç‰¹æ®Šè®¾è®¡",
                        }
                    )

                # æ˜¾ç¤ºè¯Šæ–­ç»“æœ
                if stability_issues:
                    StabilityChecker.display_issues(
                        stability_issues, title="ğŸ”¬ ç½‘ç»œæ¶æ„ç¨³å®šæ€§è¯Šæ–­"
                    )
                else:
                    st.success("âœ… ç½‘ç»œæ¶æ„æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°é—®é¢˜")

                # æ˜¾ç¤ºå„å±‚è¯¦ç»†ä¿¡æ¯è¡¨æ ¼
                if st.checkbox("ğŸ“Š æ˜¾ç¤ºè¯¦ç»†å±‚ä¿¡æ¯è¡¨", value=False):
                    import pandas as pd

                    table_data = []
                    for i, config in enumerate(st.session_state.layers):
                        status = (
                            "âŒ é”™è¯¯"
                            if config.has_issues
                            else ("âš ï¸ è­¦å‘Š" if config.warnings else "âœ… æ­£å¸¸")
                        )
                        table_data.append(
                            {
                                "åºå·": i + 1,
                                "å±‚å": config.name,
                                "ç±»å‹": config.layer_type,
                                "è¾“å‡ºå½¢çŠ¶": (
                                    str(config.output_shape)
                                    if config.output_shape
                                    else "N/A"
                                ),
                                "å‚æ•°é‡": f"{config.param_count:,}",
                                "å†…å­˜(MB)": f"{config.memory:.2f}",
                                "çŠ¶æ€": status,
                            }
                        )

                    df = pd.DataFrame(table_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)

                # ç”Ÿæˆä»£ç 
                st.markdown("---")
                st.markdown("#### ğŸ’» ç”ŸæˆPyTorchä»£ç ")

                code = "import torch.nn as nn\n\nclass CustomModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n"

                for config in st.session_state.layers:
                    if config.layer_type == "Conv2d":
                        code += f"        self.{config.name} = nn.Conv2d({config.params['in_channels']}, {config.params['out_channels']}, {config.params['kernel_size']}, stride={config.params.get('stride', 1)}, padding={config.params.get('padding', 0)})\n"
                    elif config.layer_type == "Linear":
                        code += f"        self.{config.name} = nn.Linear({config.params['in_features']}, {config.params['out_features']})\n"
                    elif config.layer_type == "ReLU":
                        code += f"        self.{config.name} = nn.ReLU()\n"
                    elif config.layer_type == "MaxPool2d":
                        code += f"        self.{config.name} = nn.MaxPool2d({config.params['kernel_size']}, stride={config.params.get('stride', config.params['kernel_size'])})\n"
                    elif config.layer_type == "Flatten":
                        code += f"        self.{config.name} = nn.Flatten()\n"
                    elif config.layer_type == "BatchNorm2d":
                        code += f"        self.{config.name} = nn.BatchNorm2d({config.params['num_features']})\n"
                    elif config.layer_type == "Dropout":
                        code += f"        self.{config.name} = nn.Dropout({config.params.get('p', 0.5)})\n"

                code += "\n    def forward(self, x):\n"
                for config in st.session_state.layers:
                    code += f"        x = self.{config.name}(x)\n"
                code += "        return x"

                st.code(code, language="python")

                # å‰å‘ä¼ æ’­æ¨¡æ‹Ÿ
                st.markdown("---")
                st.markdown("#### ğŸš€ å‰å‘ä¼ æ’­æ¨¡æ‹Ÿ")

                st.info("ä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨éšæœºæ•°æ®æµ‹è¯•ç½‘ç»œ")

                col1, col2 = st.columns(2)

                with col1:
                    use_random = st.checkbox("ä½¿ç”¨éšæœºæ•°æ®", value=True)

                with col2:
                    if not use_random:
                        uploaded_file = st.file_uploader(
                            "ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg"]
                        )

                # è¿è¡Œå‰æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                has_errors_before_run = any(
                    c.has_issues for c in st.session_state.layers
                )

                if has_errors_before_run:
                    st.error("âš ï¸ ç½‘ç»œä¸­å­˜åœ¨é”™è¯¯ï¼Œæ— æ³•è¿è¡Œå‰å‘ä¼ æ’­ï¼è¯·å…ˆä¿®å¤é”™è¯¯ã€‚")
                    if st.button(
                        "ğŸ”§ è‡ªåŠ¨ä¿®å¤å¹¶è¿è¡Œ", type="primary", key="auto_fix_run"
                    ):
                        # è‡ªåŠ¨ä¿®å¤ - æ”¹è¿›ç‰ˆï¼ˆæ”¯æŒè‡ªåŠ¨æ’å…¥Flattenï¼‰
                        temp_shape = st.session_state.input_shape
                        fixed_count = 0
                        new_layers = []

                        for idx, config in enumerate(st.session_state.layers):
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å…¥Flattenå±‚
                            if config.layer_type == "Linear" and len(temp_shape) == 4:
                                # éœ€è¦åœ¨Linearå‰æ’å…¥Flatten
                                flatten_config = LayerConfig(
                                    "Flatten", f"flatten_auto_{idx}", {}
                                )
                                flatten_layer = create_layer_from_config(
                                    flatten_config, temp_shape
                                )
                                new_layers.append(flatten_config)
                                temp_shape = flatten_config.output_shape
                                fixed_count += 1

                            # æ ¹æ®å½“å‰å½¢çŠ¶ä¿®å¤å‚æ•°
                            if config.layer_type == "Conv2d" and len(temp_shape) == 4:
                                if config.params["in_channels"] != temp_shape[1]:
                                    config.params["in_channels"] = temp_shape[1]
                                    fixed_count += 1

                            elif (
                                config.layer_type == "BatchNorm2d"
                                and len(temp_shape) == 4
                            ):
                                if config.params["num_features"] != temp_shape[1]:
                                    config.params["num_features"] = temp_shape[1]
                                    fixed_count += 1

                            elif config.layer_type == "Linear" and len(temp_shape) == 2:
                                if config.params["in_features"] != temp_shape[1]:
                                    config.params["in_features"] = temp_shape[1]
                                    fixed_count += 1

                            # æ·»åŠ å½“å‰å±‚
                            new_layers.append(config)

                            # é‡æ–°è®¡ç®—è¾“å‡ºå½¢çŠ¶ï¼ˆä½¿ç”¨ä¿®å¤åçš„å‚æ•°ï¼‰
                            try:
                                layer = create_layer_from_config(config, temp_shape)
                                if config.output_shape:
                                    temp_shape = config.output_shape
                            except:
                                pass

                        # æ›´æ–°å±‚åˆ—è¡¨
                        st.session_state.layers = new_layers

                        st.success(
                            f"âœ… è‡ªåŠ¨ä¿®å¤å®Œæˆï¼å·²ä¿®æ­£ {fixed_count} ä¸ªé—®é¢˜ï¼Œæ­£åœ¨è¿è¡Œ..."
                        )
                        st.rerun()

                elif st.button("â–¶ï¸ è¿è¡Œå‰å‘ä¼ æ’­", type="primary"):
                    with st.spinner("è®¡ç®—ä¸­..."):
                        try:
                            # æ„å»ºæ¨¡å‹
                            layers_list = []
                            current_shape = st.session_state.input_shape

                            for config in st.session_state.layers:
                                layer = create_layer_from_config(config, current_shape)
                                if layer:
                                    layers_list.append(layer)
                                    current_shape = config.output_shape

                            model = nn.Sequential(*layers_list)

                            # å‡†å¤‡è¾“å…¥
                            if use_random:
                                input_data = torch.randn(st.session_state.input_shape)
                            else:
                                # TODO: å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
                                input_data = torch.randn(st.session_state.input_shape)

                            # å‰å‘ä¼ æ’­
                            output, activations = simulate_forward_pass(
                                model, input_data
                            )

                            st.success("âœ… å‰å‘ä¼ æ’­å®Œæˆï¼")

                            # æ˜¾ç¤ºè¾“å‡º
                            st.markdown("#### ğŸ“Š è¾“å‡ºç»“æœ")
                            st.write(f"æœ€ç»ˆè¾“å‡ºå½¢çŠ¶: `{tuple(output.shape)}`")

                            if output.numel() <= 100:
                                st.write("è¾“å‡ºå€¼:")
                                st.write(output.squeeze().numpy())
                            else:
                                st.write(
                                    f"è¾“å‡ºç»Ÿè®¡: mean={output.mean():.4f}, std={output.std():.4f}, min={output.min():.4f}, max={output.max():.4f}"
                                )

                            # æ˜¾ç¤ºæ¯å±‚æ¿€æ´»å€¼
                            if activations:
                                st.markdown("---")
                                st.markdown("#### ğŸ” é€å±‚æ¿€æ´»å€¼åˆ†æ")

                                for act in activations:
                                    with st.expander(
                                        f"ğŸ“ {act['name']} - å½¢çŠ¶: {act['shape']}",
                                        expanded=False,
                                    ):
                                        col1, col2 = st.columns(2)

                                        with col1:
                                            st.markdown("**ç»Ÿè®¡ä¿¡æ¯**")
                                            st.write(f"å‡å€¼: {act['mean']:.4f}")
                                            st.write(f"æ ‡å‡†å·®: {act['std']:.4f}")
                                            st.write(f"æœ€å°å€¼: {act['min']:.4f}")
                                            st.write(f"æœ€å¤§å€¼: {act['max']:.4f}")

                                        with col2:
                                            st.markdown("**å½¢çŠ¶ä¿¡æ¯**")
                                            st.write(f"è¾“å‡ºå½¢çŠ¶: {act['shape']}")
                                            st.write(
                                                f"å…ƒç´ æ•°é‡: {np.prod(act['shape']):,}"
                                            )

                                        # å¯è§†åŒ–
                                        fig = visualize_activation_heatmap(act)
                                        if fig:
                                            st.plotly_chart(
                                                fig, use_container_width=True
                                            )

                        except Exception as e:
                            st.error(f"å‰å‘ä¼ æ’­å¤±è´¥: {e}")
                            import traceback

                            st.code(traceback.format_exc())

    # åº•éƒ¨æç¤º
    st.markdown("---")

    # æ˜¾ç¤ºå¿«æ·æ¨¡æ¿ï¼ˆä½¿ç”¨æ–°çš„æ¨¡æ¿ç³»ç»Ÿï¼‰
    with st.expander("ğŸš€ ç¥ç»ç½‘ç»œæ¨¡æ¿åº“", expanded=False):
        st.markdown("### ğŸ“š é¢„è®¾ç½‘ç»œæ¶æ„æ¨¡æ¿")
        st.markdown("ä»12+ç§ç»å…¸æ¶æ„ä¸­é€‰æ‹©ï¼Œä¸€é”®åŠ è½½å®Œæ•´ç½‘ç»œé…ç½®")

        # åˆå§‹åŒ–æ¨¡æ¿åŠ è½½å™¨
        try:
            loader = TemplateLoader()
            templates = loader.get_all_templates()

            if not templates:
                st.warning("âš ï¸ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ templates/configs/ ç›®å½•å­˜åœ¨")
            else:
                # æŒ‰åˆ†ç±»æ˜¾ç¤ºæ¨¡æ¿
                categories = loader.get_categories()

                # æ·»åŠ ç­›é€‰é€‰é¡¹
                col_filter1, col_filter2, col_filter3 = st.columns(3)
                with col_filter1:
                    selected_category = st.selectbox(
                        "ğŸ“‚ æŒ‰åˆ†ç±»ç­›é€‰",
                        ["å…¨éƒ¨"] + categories,
                        key="template_category_filter",
                    )
                with col_filter2:
                    selected_difficulty = st.selectbox(
                        "ğŸ“Š æŒ‰éš¾åº¦ç­›é€‰",
                        ["å…¨éƒ¨", "beginner", "intermediate", "advanced"],
                        format_func=lambda x: {
                            "å…¨éƒ¨": "å…¨éƒ¨",
                            "beginner": "å…¥é—¨",
                            "intermediate": "ä¸­çº§",
                            "advanced": "é«˜çº§",
                        }.get(x, x),
                        key="template_difficulty_filter",
                    )
                with col_filter3:
                    search_query = st.text_input(
                        "ğŸ” æœç´¢æ¨¡æ¿",
                        placeholder="è¾“å…¥å…³é”®è¯...",
                        key="template_search",
                    )

                # åº”ç”¨ç­›é€‰
                filtered_templates = templates
                if selected_category != "å…¨éƒ¨":
                    filtered_templates = [
                        t for t in filtered_templates if t.category == selected_category
                    ]
                if selected_difficulty != "å…¨éƒ¨":
                    filtered_templates = [
                        t
                        for t in filtered_templates
                        if t.difficulty == selected_difficulty
                    ]
                if search_query:
                    filtered_templates = loader.search_templates(search_query)

                if not filtered_templates:
                    st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ¨¡æ¿")
                else:
                    st.markdown(f"**æ‰¾åˆ° {len(filtered_templates)} ä¸ªæ¨¡æ¿**")

                    # æŒ‰åˆ†ç±»ç»„ç»‡æ˜¾ç¤º
                    for category in categories:
                        cat_templates = [
                            t for t in filtered_templates if t.category == category
                        ]
                        if not cat_templates:
                            continue

                        st.markdown(f"#### ğŸ“ {category}")

                        # æ¯è¡Œæ˜¾ç¤º3ä¸ªæ¨¡æ¿
                        for i in range(0, len(cat_templates), 3):
                            cols = st.columns(3)
                            for j, col in enumerate(cols):
                                if i + j < len(cat_templates):
                                    template = cat_templates[i + j]
                                    with col:
                                        # éš¾åº¦æ ‡ç­¾
                                        difficulty_colors = {
                                            "beginner": "ğŸŸ¢",
                                            "intermediate": "ğŸŸ¡",
                                            "advanced": "ğŸ”´",
                                        }
                                        difficulty_emoji = difficulty_colors.get(
                                            template.difficulty, "âšª"
                                        )

                                        # åˆ›å»ºæŒ‰é’®
                                        button_label = f"{template.icon} {template.name}\n{difficulty_emoji}"
                                        if st.button(
                                            button_label,
                                            key=f"template_{template.id}",
                                            use_container_width=True,
                                            help=f"{template.description}\nå±‚æ•°: {len(template.layers)}\nè¾“å…¥: {template.input_shape}",
                                        ):
                                            # åŠ è½½æ¨¡æ¿
                                            st.session_state.input_shape = tuple(
                                                template.input_shape
                                            )
                                            st.session_state.layers = (
                                                template.to_layer_configs()
                                            )
                                            st.success(f"âœ… å·²åŠ è½½ {template.name}")
                                            st.info(f"ğŸ“‹ {template.description}")
                                            st.rerun()

                                        # æ˜¾ç¤ºç®€è¦ä¿¡æ¯
                                        st.caption(
                                            f"{len(template.layers)} å±‚ | {template.input_shape}"
                                        )

                        st.markdown("---")

        except Exception as e:
            st.error(f"åŠ è½½æ¨¡æ¿å¤±è´¥: {e}")
            st.info("ğŸ’¡ ä½¿ç”¨é»˜è®¤æ¨¡æ¿ä½œä¸ºå¤‡é€‰...")

            # å¤‡é€‰æ–¹æ¡ˆï¼šæ˜¾ç¤ºæ—§çš„ç¡¬ç¼–ç æ¨¡æ¿
            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("ğŸ“± ç®€å•CNN (MNIST)", use_container_width=True):
                    st.session_state.input_shape = (1, 1, 28, 28)
                    st.session_state.layers = [
                        LayerConfig(
                            "Conv2d",
                            "conv1",
                            {
                                "in_channels": 1,
                                "out_channels": 32,
                                "kernel_size": 3,
                                "stride": 1,
                                "padding": 1,
                            },
                        ),
                        LayerConfig("ReLU", "relu1", {}),
                        LayerConfig(
                            "MaxPool2d", "pool1", {"kernel_size": 2, "stride": 2}
                        ),
                        LayerConfig(
                            "Conv2d",
                            "conv2",
                            {
                                "in_channels": 32,
                                "out_channels": 64,
                                "kernel_size": 3,
                                "stride": 1,
                                "padding": 1,
                            },
                        ),
                        LayerConfig("ReLU", "relu2", {}),
                        LayerConfig(
                            "MaxPool2d", "pool2", {"kernel_size": 2, "stride": 2}
                        ),
                        LayerConfig("Flatten", "flatten", {}),
                        LayerConfig(
                            "Linear", "fc1", {"in_features": 3136, "out_features": 128}
                        ),
                        LayerConfig("ReLU", "relu3", {}),
                        LayerConfig(
                            "Linear", "fc2", {"in_features": 128, "out_features": 10}
                        ),
                    ]
                    st.success("âœ… å·²åŠ è½½ MNIST CNN æ¨¡æ¿")
                    st.rerun()

            with col2:
                if st.button("ğŸ–¼ï¸ ä¸­ç­‰CNN (CIFAR)", use_container_width=True):
                    st.session_state.input_shape = (1, 3, 32, 32)
                    st.session_state.layers = [
                        LayerConfig(
                            "Conv2d",
                            "conv1",
                            {
                                "in_channels": 3,
                                "out_channels": 64,
                                "kernel_size": 3,
                                "stride": 1,
                                "padding": 1,
                            },
                        ),
                        LayerConfig("BatchNorm2d", "bn1", {"num_features": 64}),
                        LayerConfig("ReLU", "relu1", {}),
                        LayerConfig(
                            "Conv2d",
                            "conv2",
                            {
                                "in_channels": 64,
                                "out_channels": 128,
                                "kernel_size": 3,
                                "stride": 1,
                                "padding": 1,
                            },
                        ),
                        LayerConfig("BatchNorm2d", "bn2", {"num_features": 128}),
                        LayerConfig("ReLU", "relu2", {}),
                        LayerConfig(
                            "MaxPool2d", "pool1", {"kernel_size": 2, "stride": 2}
                        ),
                        LayerConfig("Flatten", "flatten", {}),
                        LayerConfig(
                            "Linear", "fc1", {"in_features": 32768, "out_features": 256}
                        ),
                        LayerConfig("ReLU", "relu3", {}),
                        LayerConfig("Dropout", "dropout", {"p": 0.5}),
                        LayerConfig(
                            "Linear", "fc2", {"in_features": 256, "out_features": 10}
                        ),
                    ]
                    st.success("âœ… å·²åŠ è½½ CIFAR CNN æ¨¡æ¿")
                    st.rerun()

            with col3:
                if st.button("ğŸ§  ç®€å•MLP", use_container_width=True):
                    st.session_state.input_shape = (1, 784)
                    st.session_state.layers = [
                        LayerConfig(
                            "Linear", "fc1", {"in_features": 784, "out_features": 512}
                        ),
                        LayerConfig("ReLU", "relu1", {}),
                        LayerConfig("Dropout", "dropout1", {"p": 0.2}),
                        LayerConfig(
                            "Linear", "fc2", {"in_features": 512, "out_features": 256}
                        ),
                        LayerConfig("ReLU", "relu2", {}),
                        LayerConfig("Dropout", "dropout2", {"p": 0.2}),
                        LayerConfig(
                            "Linear", "fc3", {"in_features": 256, "out_features": 10}
                        ),
                    ]
                    st.success("âœ… å·²åŠ è½½ MLP æ¨¡æ¿")
                    st.rerun()

    st.markdown(
        """
    ### ğŸ’¡ ä½¿ç”¨æç¤º
    
    1. **ä»è¾“å…¥å¼€å§‹** - å…ˆé…ç½®è¾“å…¥å½¢çŠ¶ï¼ˆå›¾åƒæˆ–å‘é‡ï¼‰
    2. **é€å±‚æ·»åŠ ** - ä»å·¦ä¾§æ·»åŠ å±‚ï¼Œæ³¨æ„å½¢çŠ¶åŒ¹é…
    3. **å®æ—¶åé¦ˆ** - æ¯æ·»åŠ ä¸€å±‚ï¼Œç«‹å³çœ‹åˆ°è¾“å‡ºå½¢çŠ¶å’Œå‚æ•°é‡
    4. **è‡ªåŠ¨æ£€æµ‹** - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å½¢çŠ¶ä¸åŒ¹é…ã€å‚æ•°è¿‡å¤§ç­‰é—®é¢˜
    5. **å±‚é‡æ’åº** - ä½¿ç”¨â¬†ï¸â¬‡ï¸æŒ‰é’®è°ƒæ•´å±‚çš„é¡ºåº
    6. **æ¨¡æ‹Ÿè¿è¡Œ** - ç‚¹å‡»"è¿è¡Œå‰å‘ä¼ æ’­"æŸ¥çœ‹é€å±‚è®¡ç®—ç»“æœ
    7. **ä¿å­˜é…ç½®** - å¯¼å‡ºé…ç½®æ–‡ä»¶ä»¥ä¾¿åç»­ä½¿ç”¨
    
    ### âš ï¸ å¸¸è§é—®é¢˜
    
    - **å½¢çŠ¶ä¸åŒ¹é…**ï¼šæ£€æŸ¥å‰ä¸€å±‚çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆå½“å‰å±‚çš„è¾“å…¥è¦æ±‚ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æç¤ºï¼‰
    - **å‚æ•°è¿‡å¤š**ï¼šåœ¨Flattenåæ¥Linearæ—¶æ³¨æ„ç‰¹å¾ç»´åº¦ï¼Œè€ƒè™‘ä½¿ç”¨Poolingå‡å°‘å°ºå¯¸
    - **é€šé“æ•°é”™è¯¯**ï¼šConv2då’ŒBatchNorm2dçš„é€šé“æ•°è¦åŒ¹é…
    - **çº¢è‰²èŠ‚ç‚¹**ï¼šè¡¨ç¤ºè¯¥å±‚æœ‰é”™è¯¯ï¼Œéœ€è¦ä¿®æ­£å‚æ•°
    - **é»„è‰²èŠ‚ç‚¹**ï¼šè¡¨ç¤ºè¯¥å±‚æœ‰è­¦å‘Šï¼Œå»ºè®®ä¼˜åŒ–ä½†ä¸å½±å“è¿è¡Œ
    """
    )


if __name__ == "__main__":
    # æµ‹è¯•è¿è¡Œ
    architecture_designer_tab()
