"""å‚æ•°è®¡ç®—å™¨ä¸»æ ‡ç­¾é¡µ

æä¾›å•å±‚åˆ†æå’Œç½‘ç»œåˆ†æçš„ç•Œé¢åŠŸèƒ½ã€‚

Author: Just For Dream Lab
Version: 1.0.0
"""

import streamlit as st

from .layer_analyzer import LayerAnalyzer
from .network_analysis import full_network_analysis


def params_calculator_tab():
    """å‚æ•°é‡ä¸FLOPsè®¡ç®—å™¨æ ‡ç­¾é¡µ"""

    st.header("ğŸ”¢ å‚æ•°é‡ä¸FLOPsè®¡ç®—å™¨")

    st.markdown(
        """
    ### æ ¸å¿ƒåŠŸèƒ½ï¼šé€å±‚åˆ†æç½‘ç»œè®¡ç®—ç»†èŠ‚
    
    è¾“å…¥ç½‘ç»œå±‚çš„é…ç½®ï¼Œè‡ªåŠ¨è®¡ç®—ï¼š
    - ğŸ“Š å‚æ•°é‡ï¼ˆParamsï¼‰
    - ğŸ“ˆ æµ®ç‚¹è¿ç®—é‡ï¼ˆFLOPs / MACsï¼‰
    - ğŸ’¾ å†…å­˜å ç”¨ï¼ˆå‰å‘/åå‘ä¼ æ’­ï¼‰
    - ğŸ” è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸
    
    **ä¸ torchinfo çš„åŒºåˆ«**ï¼šæˆ‘ä»¬ä¸ä»…ç»™å‡ºæ•°å­—ï¼Œè¿˜å±•ç¤º**æ¯ä¸ªæ•°å­—èƒŒåçš„è®¡ç®—å…¬å¼**ï¼
    """
    )

    # é€‰æ‹©åˆ†ææ¨¡å¼
    analysis_mode = st.radio(
        "é€‰æ‹©åˆ†ææ¨¡å¼",
        ["å•å±‚åˆ†æ", "å®Œæ•´ç½‘ç»œåˆ†æ"],
        horizontal=True,
        key="analysis_mode"
    )

    if analysis_mode == "å•å±‚åˆ†æ":
        _single_layer_analysis()
    else:
        full_network_analysis()


def _single_layer_analysis():
    """å•å±‚åˆ†ææ¨¡å¼"""
    # é€‰æ‹©å±‚ç±»å‹
    layer_type = st.selectbox(
        "é€‰æ‹©ç½‘ç»œå±‚ç±»å‹",
        [
            "Conv2d (æ ‡å‡†å·ç§¯å±‚)",
            "DepthwiseConv2d (æ·±åº¦å¯åˆ†ç¦»å·ç§¯)",
            "Linear (å…¨è¿æ¥å±‚)",
            "MultiHeadAttention (å¤šå¤´æ³¨æ„åŠ›)",
            "LSTM (é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ)",
            "Embedding (åµŒå…¥å±‚)",
            "BatchNorm2d (æ‰¹å½’ä¸€åŒ–)",
            "LayerNorm (å±‚å½’ä¸€åŒ–)",
        ],
    )

    analyzer = LayerAnalyzer()

    if "Conv2d" in layer_type:
        _conv2d_analysis(analyzer)
    elif "DepthwiseConv2d" in layer_type:
        _depthwise_conv_analysis(analyzer)
    elif "Linear" in layer_type:
        _linear_analysis(analyzer)
    elif "MultiHeadAttention" in layer_type:
        _attention_analysis(analyzer)
    elif "LSTM" in layer_type:
        _lstm_analysis(analyzer)
    elif "Embedding" in layer_type:
        _embedding_analysis(analyzer)
    elif "BatchNorm2d" in layer_type:
        _batchnorm_analysis(analyzer)
    elif "LayerNorm" in layer_type:
        _layernorm_analysis(analyzer)


def _conv2d_analysis(analyzer):
    """Conv2då±‚åˆ†æ"""
    st.markdown("### ğŸ–¼ï¸ Conv2d å·ç§¯å±‚åˆ†æ")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**è¾“å…¥é…ç½®**")
        C_in = st.number_input(
            "è¾“å…¥é€šé“æ•° (in_channels)", min_value=1, value=3, step=1
        )
        H_in = st.number_input("è¾“å…¥é«˜åº¦ (H)", min_value=1, value=224, step=1)
        W_in = st.number_input("è¾“å…¥å®½åº¦ (W)", min_value=1, value=224, step=1)

    with col2:
        st.markdown("**å±‚å‚æ•°é…ç½®**")
        C_out = st.number_input(
            "è¾“å‡ºé€šé“æ•° (out_channels)", min_value=1, value=64, step=1
        )
        kernel_size = st.number_input(
            "å·ç§¯æ ¸å¤§å° (kernel_size)", min_value=1, value=7, step=1
        )
        stride = st.number_input("æ­¥é•¿ (stride)", min_value=1, value=2, step=1)
        padding = st.number_input("å¡«å…… (padding)", min_value=0, value=3, step=1)
        use_bias = st.checkbox("ä½¿ç”¨åç½® (bias)", value=True)

    # è®¡ç®—åˆ†æ
    result = analyzer.conv2d_analysis(
        in_channels=C_in,
        out_channels=C_out,
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        input_shape=(C_in, H_in, W_in),
        use_bias=use_bias,
    )

    # æ˜¾ç¤ºç»“æœ
    _display_conv2d_results(result, C_in, H_in, W_in)


def _display_conv2d_results(result, C_in, H_in, W_in):
    """æ˜¾ç¤ºConv2dåˆ†æç»“æœ"""
    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")

    # è¾“å‡ºå½¢çŠ¶
    st.markdown("#### 1ï¸âƒ£ è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸")
    C_out_calc, H_out, W_out = result["output_shape"]

    st.latex(
        r"H_{out} = \left\lfloor \frac{H_{in} + 2 \times padding - kernel\_size}{stride} \right\rfloor + 1"
    )
    st.latex(
        r"W_{out} = \left\lfloor \frac{W_{in} + 2 \times padding - kernel\_size}{stride} \right\rfloor + 1"
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¾“å…¥å½¢çŠ¶", f"[{C_in}, {H_in}, {W_in}]")
    with col2:
        st.metric("è¾“å‡ºå½¢çŠ¶", f"[{C_out_calc}, {H_out}, {W_out}]")
    with col3:
        reduction = ((H_in * W_in) - (H_out * W_out)) / (H_in * W_in) * 100
        st.metric("ç©ºé—´é™é‡‡æ ·", f"{reduction:.1f}%")

    # å‚æ•°é‡
    st.markdown("#### 2ï¸âƒ£ å‚æ•°é‡è®¡ç®—")
    st.latex(r"Params_{weight} = C_{out} \times C_{in} \times K_h \times K_w")
    
    weight_params = result["parameters"]["weight"]
    bias_params = result["parameters"]["bias"]
    total_params = result["parameters"]["total"]

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æƒé‡å‚æ•°", f"{weight_params:,}")
    with col2:
        st.metric("åç½®å‚æ•°", f"{bias_params:,}")
    with col3:
        st.metric("æ€»å‚æ•°é‡", f"{total_params:,}")

    # FLOPs
    st.markdown("#### 3ï¸âƒ£ FLOPsè®¡ç®—")
    st.latex(r"FLOPs = 2 \times MACs = 2 \times C_{out} \times H_{out} \times W_{out} \times K_h \times K_w \times C_{in}")
    
    total_flops = result["flops"]["total"]
    macs = result["flops"]["macs"]

    col1, col2 = st.columns(2)
    with col1:
        st.metric("MACs", macs)
    with col2:
        st.metric("FLOPs", total_flops)

    # å†…å­˜å ç”¨
    st.markdown("#### 4ï¸âƒ£ å†…å­˜å ç”¨")
    param_memory = result["memory_mb"]["parameters"]
    forward_memory = result["memory_mb"]["forward"]
    backward_memory = result["memory_mb"]["backward"]
    total_memory = result["memory_mb"]["total"]

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å‚æ•°å†…å­˜", f"{param_memory:.2f}MB")
    with col2:
        st.metric("å‰å‘å†…å­˜", f"{forward_memory:.2f}MB")
    with col3:
        st.metric("æ€»å†…å­˜", f"{total_memory:.2f}MB")


def _depthwise_conv_analysis(analyzer):
    """æ·±åº¦å¯åˆ†ç¦»å·ç§¯åˆ†æ"""
    st.markdown("### ğŸ“± DepthwiseConv2d æ·±åº¦å¯åˆ†ç¦»å·ç§¯åˆ†æ")
    
    # é…ç½®ç•Œé¢
    col1, col2 = st.columns(2)

    with col1:
        in_channels = st.number_input("è¾“å…¥é€šé“æ•°", 1, 1024, 32)
        kernel_size = st.number_input("å·ç§¯æ ¸å¤§å°", 1, 11, 3)
        stride = st.number_input("æ­¥é•¿", 1, 4, 1)
        padding = st.number_input("å¡«å……", 0, 5, 1)

    with col2:
        H_in = st.number_input("è¾“å…¥é«˜åº¦", 16, 512, 224)
        W_in = st.number_input("è¾“å…¥å®½åº¦", 16, 512, 224)
        use_bias = st.checkbox("ä½¿ç”¨åç½®", True)

    # è®¡ç®—åˆ†æ
    result = analyzer.depthwise_conv2d_analysis(
        in_channels, kernel_size, stride, padding, (in_channels, H_in, W_in), use_bias
    )

    # æ˜¾ç¤ºç»“æœ
    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å‚æ•°é‡", f"{result['parameters']['total']:,}")
        st.metric("å†…å­˜å ç”¨", f"{result['memory_mb']['parameters']:.2f}MB")
    with col2:
        st.metric("FLOPs", result['flops']['flops_readable'])
        st.metric("è¾“å‡ºå½¢çŠ¶", str(result['output_shape']))


def _linear_analysis(analyzer):
    """å…¨è¿æ¥å±‚åˆ†æ"""
    st.markdown("### ğŸ”— Linear å…¨è¿æ¥å±‚åˆ†æ")
    
    in_features = st.number_input("è¾“å…¥ç‰¹å¾æ•°", 1, 4096, 512)
    out_features = st.number_input("è¾“å‡ºç‰¹å¾æ•°", 1, 4096, 512)
    use_bias = st.checkbox("ä½¿ç”¨åç½®", True)

    result = analyzer.linear_analysis(in_features, out_features, use_bias)

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æƒé‡å‚æ•°", f"{result['parameters']['weight']:,}")
    with col2:
        st.metric("æ€»å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col3:
        st.metric("FLOPs", result['flops']['flops_readable'])


def _attention_analysis(analyzer):
    """å¤šå¤´æ³¨æ„åŠ›åˆ†æ"""
    st.markdown("### ğŸ‘ï¸ MultiHeadAttention å¤šå¤´æ³¨æ„åŠ›åˆ†æ")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        d_model = st.number_input("æ¨¡å‹ç»´åº¦", 64, 2048, 512)
    with col2:
        num_heads = st.number_input("æ³¨æ„åŠ›å¤´æ•°", 1, 32, 8)
    with col3:
        seq_len = st.number_input("åºåˆ—é•¿åº¦", 16, 1024, 128)

    has_qkv_bias = st.checkbox("QKVä½¿ç”¨åç½®", True)

    result = analyzer.attention_analysis(d_model, num_heads, seq_len, has_qkv_bias)

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col2:
        st.metric("FLOPs", result['flops']['flops_readable'])
    with col3:
        st.metric("æ³¨æ„åŠ›çŸ©é˜µå†…å­˜", f"{result['memory_mb']['attention_matrix']:.2f}MB")


def _lstm_analysis(analyzer):
    """LSTMåˆ†æ"""
    st.markdown("### ğŸ”„ LSTM é•¿çŸ­æœŸè®°å¿†ç½‘ç»œåˆ†æ")
    
    col1, col2 = st.columns(2)
    with col1:
        input_size = st.number_input("è¾“å…¥ç»´åº¦", 64, 2048, 512)
        hidden_size = st.number_input("éšè—ç»´åº¦", 64, 2048, 512)
    with col2:
        num_layers = st.number_input("å±‚æ•°", 1, 8, 2)
        bidirectional = st.checkbox("åŒå‘", False)

    result = analyzer.lstm_analysis(input_size, hidden_size, num_layers, bidirectional=True)

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col2:
        st.metric("æ¯å±‚å‚æ•°", f"{result['parameters']['per_layer']:,}")
    with col3:
        st.metric("æ¯æ—¶é—´æ­¥FLOPs", result['flops']['flops_readable'])


def _embedding_analysis(analyzer):
    """åµŒå…¥å±‚åˆ†æ"""
    st.markdown("### ğŸ“š Embedding åµŒå…¥å±‚åˆ†æ")
    
    col1, col2 = st.columns(2)
    with col1:
        num_embeddings = st.number_input("è¯è¡¨å¤§å°", 1000, 100000, 10000)
    with col2:
        embedding_dim = st.number_input("åµŒå…¥ç»´åº¦", 64, 1024, 512)

    result = analyzer.embedding_analysis(num_embeddings, embedding_dim)

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col2:
        st.metric("å†…å­˜å ç”¨", f"{result['memory_mb']['parameters']:.2f}MB")


def _batchnorm_analysis(analyzer):
    """æ‰¹å½’ä¸€åŒ–åˆ†æ"""
    st.markdown("### ğŸ“Š BatchNorm2d æ‰¹å½’ä¸€åŒ–åˆ†æ")
    
    col1, col2 = st.columns(2)
    with col1:
        num_features = st.number_input("ç‰¹å¾æ•°", 16, 1024, 64)
    with col2:
        H = st.number_input("é«˜åº¦", 16, 512, 224)
        W = st.number_input("å®½åº¦", 16, 512, 224)

    result = analyzer.batchnorm2d_analysis(num_features, (num_features, H, W))

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col2:
        st.metric("FLOPs", result['flops']['flops_readable'])


def _layernorm_analysis(analyzer):
    """å±‚å½’ä¸€åŒ–åˆ†æ"""
    st.markdown("### ğŸ“ LayerNorm å±‚å½’ä¸€åŒ–åˆ†æ")
    
    normalized_shape = st.number_input("å½’ä¸€åŒ–ç»´åº¦", 64, 2048, 512)
    
    # å‡è®¾è¾“å…¥å½¢çŠ¶
    input_shape = (normalized_shape, 128)  # (d_model, seq_len)

    result = analyzer.layernorm_analysis(normalized_shape, input_shape)

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("å‚æ•°é‡", f"{result['parameters']['total']:,}")
    with col2:
        st.metric("FLOPs", result['flops']['flops_readable'])