"""ç½‘ç»œåˆ†æåŠŸèƒ½

æä¾›å®Œæ•´ç½‘ç»œçš„å‚æ•°é‡ã€FLOPså’Œå†…å­˜å ç”¨åˆ†æåŠŸèƒ½ã€‚

Author: Just For Dream Lab
Version: 1.0.0
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from typing import Dict, List, Tuple

from .layer_analyzer import LayerAnalyzer
from templates.template_loader import TemplateLoader


def full_network_analysis():
    """å®Œæ•´ç½‘ç»œåˆ†ææ¨¡å¼"""
    st.markdown("---")
    st.markdown("## ğŸ—ï¸ å®Œæ•´ç½‘ç»œå‚æ•°åˆ†æ")

    st.markdown(
        """
    é€‰æ‹©é¢„å®šä¹‰ç½‘ç»œæˆ–è‡ªå®šä¹‰ç½‘ç»œæ¶æ„ï¼Œç”Ÿæˆè¯¦ç»†çš„å‚æ•°/FLOPsæŠ¥å‘Šã€‚
    """
    )

    # ç½‘ç»œé€‰æ‹©
    network_mode = st.radio(
        "é€‰æ‹©æ¨¡å¼", ["é¢„å®šä¹‰ç½‘ç»œ", "è‡ªå®šä¹‰ç½‘ç»œ"], horizontal=True, key="network_mode"
    )

    if network_mode == "é¢„å®šä¹‰ç½‘ç»œ":
        predefined_network_analysis()
    else:
        custom_network_analysis()

    # è¿”å›å•å±‚åˆ†æ
    if st.button("è¿”å›å•å±‚åˆ†æ", use_container_width=True):
        st.session_state.calc_mode = "single"
        st.rerun()


def predefined_network_analysis():
    """é¢„å®šä¹‰ç½‘ç»œåˆ†æ"""
    st.markdown("### ğŸ“¦ é¢„å®šä¹‰ç½‘ç»œæ¶æ„")

    network_name = st.selectbox(
        "é€‰æ‹©ç½‘ç»œ",
        [
            "ResNet-18 (CNN)",
            "ResNet-50 (CNN)",
            "VGG-16 (CNN)",
            "MobileNetV2 (è½»é‡çº§CNN)",
            "BERT-base (Transformer)",
            "GPT-2 small (Transformer)",
            "ViT-Base (Vision Transformer)",
        ],
        key="predefined_network",
    )

    # è¾“å…¥å°ºå¯¸
    col1, col2 = st.columns(2)
    with col1:
        batch_size = st.number_input(
            "æ‰¹æ¬¡å¤§å°", min_value=1, value=1, step=1, key="batch_size"
        )
    with col2:
        input_size = st.selectbox(
            "è¾“å…¥å°ºå¯¸", [224, 256, 384, 512], index=0, key="input_size"
        )

    # è·å–ç½‘ç»œæ¶æ„
    network_config = get_network_config(network_name, input_size)

    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    total_params = 0
    total_flops = 0
    total_memory = 0

    layers_data = []

    for layer_info in network_config:
        total_params += layer_info["params"]
        total_flops += layer_info["flops"]
        total_memory += layer_info.get("memory", 0)
        layers_data.append(layer_info)

    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    st.markdown("---")
    st.markdown("### ğŸ“Š ç½‘ç»œæ€»ä½“ç»Ÿè®¡")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "æ€»å‚æ•°é‡", f"{total_params/1e6:.2f}M", help="ç½‘ç»œä¸­æ‰€æœ‰å¯å­¦ä¹ å‚æ•°çš„æ€»æ•°"
        )

    with col2:
        st.metric(
            "æ€»FLOPs", f"{total_flops/1e9:.2f}G", help="å•æ¬¡å‰å‘ä¼ æ’­çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°"
        )

    with col3:
        st.metric("å†…å­˜å ç”¨", f"{total_memory:.1f}MB", help="å‚æ•°å­˜å‚¨æ‰€éœ€å†…å­˜")

    with col4:
        st.metric("å±‚æ•°", f"{len(layers_data)}", help="ç½‘ç»œä¸­å±‚çš„æ€»æ•°")

    # å‚æ•°é‡åˆ†å¸ƒå›¾
    st.markdown("---")
    st.markdown("### ğŸ“ˆ å‚æ•°é‡åˆ†å¸ƒ")

    layer_names = [f"Layer {i+1}" for i in range(len(layers_data))]
    param_counts = [layer["params"] for layer in layers_data]

    fig = go.Figure()
    fig.add_trace(
        go.Bar(
            x=layer_names,
            y=param_counts,
            marker_color="lightblue",
            text=[f"{p/1e6:.2f}M" for p in param_counts],
            textposition="auto",
        )
    )

    fig.update_layout(
        title="å„å±‚å‚æ•°é‡åˆ†å¸ƒ",
        xaxis_title="ç½‘ç»œå±‚",
        yaxis_title="å‚æ•°é‡",
        height=400,
    )

    st.plotly_chart(fig, use_container_width=True, key="param_distribution")

    # è¯¦ç»†å±‚ä¿¡æ¯è¡¨
    st.markdown("---")
    st.markdown("### ğŸ“‹ è¯¦ç»†å±‚ä¿¡æ¯")

    # æ£€æŸ¥æ˜¯å¦æœ‰å±‚æ•°æ®
    if not layers_data:
        st.warning("âš ï¸ è¯¥ç½‘ç»œæ¨¡æ¿æš‚æœªå®Œå…¨å®ç°ï¼Œè¯·é€‰æ‹©å…¶ä»–ç½‘ç»œæˆ–ä½¿ç”¨è‡ªå®šä¹‰ç½‘ç»œæ¨¡å¼ã€‚")
        return

    # åˆ›å»ºè¯¦ç»†æ•°æ®è¡¨
    detailed_data = []
    for i, layer in enumerate(layers_data):
        detailed_data.append(
            {
                "å±‚å·": i + 1,
                "ç±»å‹": layer["type"],
                "å‚æ•°é‡": layer["params"],
                "FLOPs": layer["flops"],
                "è¾“å‡ºå½¢çŠ¶": layer.get("output_shape", "-"),
            }
        )

    df = pd.DataFrame(detailed_data)
    
    # åªæœ‰å½“DataFrameä¸ä¸ºç©ºæ—¶æ‰è¿›è¡Œæ ¼å¼åŒ–
    if not df.empty:
        df["å‚æ•°é‡"] = df["å‚æ•°é‡"].apply(
            lambda x: f"{x/1e6:.2f}M" if x > 1e6 else f"{x/1e3:.1f}K"
        )
        df["FLOPs"] = df["FLOPs"].apply(
            lambda x: f"{x/1e9:.2f}G" if x > 1e9 else f"{x/1e6:.1f}M"
        )

    st.dataframe(df, use_container_width=True)

    # ç”ŸæˆæŠ¥å‘Š
    if st.button("ğŸ“„ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š", use_container_width=True):
        generate_network_report(network_name, layers_data, total_params, total_flops)


def custom_network_analysis():
    """è‡ªå®šä¹‰ç½‘ç»œåˆ†æ"""
    st.markdown("### ğŸ› ï¸ è‡ªå®šä¹‰ç½‘ç»œæ¶æ„")

    st.markdown(
        """
    é€å±‚æ„å»ºä½ çš„ç½‘ç»œæ¶æ„ï¼Œå®æ—¶æŸ¥çœ‹å‚æ•°é‡å’Œè®¡ç®—é‡ã€‚
    """
    )

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "custom_layers" not in st.session_state:
        st.session_state.custom_layers = []

    # å±‚é…ç½®ç•Œé¢
    col1, col2, col3 = st.columns(3)

    with col1:
        layer_type = st.selectbox(
            "å±‚ç±»å‹",
            [
                "Conv2d",
                "Linear",
                "BatchNorm2d",
                "LayerNorm",
                "MultiHeadAttention",
                "LSTM",
                "Embedding",
                "Dropout",
            ],
            key="layer_type",
        )

    with col2:
        if layer_type == "Conv2d":
            in_channels = st.number_input("è¾“å…¥é€šé“", 3, 1024, 64, key="conv_in")
            out_channels = st.number_input("è¾“å‡ºé€šé“", 16, 1024, 64, key="conv_out")
            kernel_size = st.number_input("å·ç§¯æ ¸å¤§å°", 1, 11, 3, key="kernel_size")
            stride = st.number_input("æ­¥é•¿", 1, 4, 1, key="stride")
            padding = st.number_input("å¡«å……", 0, 5, 1, key="padding")

        elif layer_type == "Linear":
            in_features = st.number_input("è¾“å…¥ç‰¹å¾", 64, 4096, 512, key="linear_in")
            out_features = st.number_input("è¾“å‡ºç‰¹å¾", 64, 4096, 512, key="linear_out")

        elif layer_type == "MultiHeadAttention":
            d_model = st.number_input("æ¨¡å‹ç»´åº¦", 64, 2048, 512, key="d_model")
            num_heads = st.number_input("æ³¨æ„åŠ›å¤´æ•°", 1, 32, 8, key="num_heads")
            seq_len = st.number_input("åºåˆ—é•¿åº¦", 16, 1024, 128, key="seq_len")

        elif layer_type == "LSTM":
            input_size = st.number_input("è¾“å…¥ç»´åº¦", 64, 2048, 512, key="lstm_in")
            hidden_size = st.number_input("éšè—ç»´åº¦", 64, 2048, 512, key="lstm_hidden")
            num_layers = st.number_input("å±‚æ•°", 1, 8, 2, key="lstm_layers")
            bidirectional = st.checkbox("åŒå‘", key="lstm_bidirectional")

        elif layer_type == "Embedding":
            num_embeddings = st.number_input(
                "è¯è¡¨å¤§å°", 1000, 100000, 10000, key="embed_vocab"
            )
            embedding_dim = st.number_input("åµŒå…¥ç»´åº¦", 64, 1024, 512, key="embed_dim")

    with col3:
        if st.button("â• æ·»åŠ å±‚", use_container_width=True):
            # æ„å»ºå±‚é…ç½®
            layer_config = {"type": layer_type}

            if layer_type == "Conv2d":
                layer_config.update(
                    {
                        "in_channels": in_channels,
                        "out_channels": out_channels,
                        "kernel_size": kernel_size,
                        "stride": stride,
                        "padding": padding,
                    }
                )
            elif layer_type == "Linear":
                layer_config.update(
                    {
                        "in_features": in_features,
                        "out_features": out_features,
                    }
                )
            elif layer_type == "MultiHeadAttention":
                layer_config.update(
                    {
                        "d_model": d_model,
                        "num_heads": num_heads,
                        "seq_len": seq_len,
                    }
                )
            elif layer_type == "LSTM":
                layer_config.update(
                    {
                        "input_size": input_size,
                        "hidden_size": hidden_size,
                        "num_layers": num_layers,
                        "bidirectional": bidirectional,
                    }
                )
            elif layer_type == "Embedding":
                layer_config.update(
                    {
                        "num_embeddings": num_embeddings,
                        "embedding_dim": embedding_dim,
                    }
                )

            st.session_state.custom_layers.append(layer_config)
            st.rerun()

    # æ˜¾ç¤ºå·²æ·»åŠ çš„å±‚
    if st.session_state.custom_layers:
        st.markdown("---")
        st.markdown("### ğŸ“‹ å½“å‰ç½‘ç»œæ¶æ„")

        # è®¡ç®—å„å±‚å‚æ•°é‡
        layers_data = []
        total_params = 0
        total_flops = 0

        for i, layer in enumerate(st.session_state.custom_layers):
            layer_info = analyze_layer(layer)
            layers_data.append(layer_info)
            total_params += layer_info["params"]
            total_flops += layer_info["flops"]

        # æ˜¾ç¤ºå±‚ä¿¡æ¯è¡¨
        df_data = []
        for i, layer in enumerate(layers_data):
            df_data.append(
                {
                    "å±‚å·": i + 1,
                    "ç±»å‹": layer["type"],
                    "å‚æ•°é‡": layer["params"],
                    "FLOPs": layer["flops"],
                }
            )

        df = pd.DataFrame(df_data)
        
        # åªæœ‰å½“DataFrameä¸ä¸ºç©ºæ—¶æ‰è¿›è¡Œæ ¼å¼åŒ–
        if not df.empty:
            df["å‚æ•°é‡"] = df["å‚æ•°é‡"].apply(
                lambda x: f"{x/1e6:.2f}M" if x > 1e6 else f"{x/1e3:.1f}K"
            )
            df["FLOPs"] = df["FLOPs"].apply(
                lambda x: f"{x/1e9:.2f}G" if x > 1e9 else f"{x/1e6:.1f}M"
            )

        st.dataframe(df, use_container_width=True)

        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        st.markdown("### ğŸ“Š ç½‘ç»œç»Ÿè®¡")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»å‚æ•°é‡", f"{total_params/1e6:.2f}M")
        with col2:
            st.metric("æ€»FLOPs", f"{total_flops/1e9:.2f}G")
        with col3:
            st.metric("å±‚æ•°", len(layers_data))

        # æ¸…ç©ºæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰å±‚", use_container_width=True):
            st.session_state.custom_layers = []
            st.rerun()


def analyze_layer(layer_config: Dict) -> Dict:
    """åˆ†æå•ä¸ªå±‚çš„å‚æ•°é‡å’ŒFLOPs"""
    layer_type = layer_config["type"]

    if layer_type == "Conv2d":
        # å‡è®¾è¾“å…¥å½¢çŠ¶
        input_shape = (layer_config["in_channels"], 224, 224)
        result = LayerAnalyzer.conv2d_analysis(
            layer_config["in_channels"],
            layer_config["out_channels"],
            layer_config["kernel_size"],
            layer_config["stride"],
            layer_config["padding"],
            input_shape,
        )

    elif layer_type == "Linear":
        result = LayerAnalyzer.linear_analysis(
            layer_config["in_features"], layer_config["out_features"]
        )

    elif layer_type == "MultiHeadAttention":
        result = LayerAnalyzer.attention_analysis(
            layer_config["d_model"], layer_config["num_heads"], layer_config["seq_len"]
        )

    elif layer_type == "LSTM":
        result = LayerAnalyzer.lstm_analysis(
            layer_config["input_size"],
            layer_config["hidden_size"],
            layer_config["num_layers"],
            bidirectional=layer_config.get("bidirectional", False),
        )

    elif layer_type == "Embedding":
        result = LayerAnalyzer.embedding_analysis(
            layer_config["num_embeddings"], layer_config["embedding_dim"]
        )

    else:
        # å…¶ä»–å±‚çš„é»˜è®¤å¤„ç†
        result = {
            "type": layer_type,
            "params": 0,
            "flops": 0,
            "memory": 0,
        }

    return {
        "type": layer_type,
        "params": result["parameters"]["total"],
        "flops": result["flops"]["total"],
        "memory": result.get("memory_mb", {}).get("parameters", 0),
        "output_shape": result.get("output_shape", "-"),
    }


def get_network_config(network_name: str, input_size: int) -> List[Dict]:
    """è·å–é¢„å®šä¹‰ç½‘ç»œé…ç½®"""
    # æ˜ å°„æ˜¾ç¤ºåç§°åˆ°æ¨¡æ¿ID
    name_to_template_id = {
        "ResNet-18 (CNN)": "residual_block",
        "ResNet-50 (CNN)": "residual_block",
        "VGG-16 (CNN)": "vgg_like",
        "MobileNetV2 (è½»é‡çº§CNN)": "mobilenet_like",
        "BERT-base (Transformer)": "bert_like",
        "GPT-2 small (Transformer)": "gpt_like",
        "ViT-Base (Vision Transformer)": "vision_transformer",
    }
    
    template_id = name_to_template_id.get(network_name)
    if not template_id:
        return []
    
    # åŠ è½½æ¨¡æ¿
    loader = TemplateLoader()
    template = loader.get_template(template_id)
    
    if not template:
        return []
    
    # åˆ†ææ¯ä¸€å±‚å¹¶è®¡ç®—å‚æ•°
    layers_data = []
    current_shape = template.input_shape[1:]  # å»æ‰batchç»´åº¦
    
    for layer_config in template.layers:
        layer_type = layer_config["layer_type"]
        params_dict = layer_config["params"]
        
        try:
            layer_info = analyze_layer_from_template(
                layer_type, params_dict, current_shape
            )
            layers_data.append(layer_info)
            
            # æ›´æ–°å½“å‰shapeç”¨äºä¸‹ä¸€å±‚
            if "output_shape" in layer_info and layer_info["output_shape"] != "-":
                current_shape = layer_info["output_shape"]
        except Exception as e:
            # å¦‚æœæŸå±‚åˆ†æå¤±è´¥ï¼Œè·³è¿‡è¯¥å±‚ä½†ç»§ç»­å¤„ç†å…¶ä»–å±‚
            print(f"Warning: Failed to analyze layer {layer_config['name']}: {e}")
            continue
    
    return layers_data


def analyze_layer_from_template(
    layer_type: str, params: Dict, input_shape
) -> Dict:
    """ä»æ¨¡æ¿é…ç½®åˆ†æå•ä¸ªå±‚"""
    
    if layer_type == "Conv2d":
        # ç¡®ä¿input_shapeæ˜¯3D (C, H, W)
        if isinstance(input_shape, (list, tuple)) and len(input_shape) >= 3:
            if len(input_shape) == 4:  # (N, C, H, W)
                input_shape = input_shape[1:]
            result = LayerAnalyzer.conv2d_analysis(
                params["in_channels"],
                params["out_channels"],
                params["kernel_size"],
                params.get("stride", 1),
                params.get("padding", 0),
                input_shape,
                use_bias=params.get("use_bias", True),
            )
        else:
            # é»˜è®¤å½¢çŠ¶
            result = LayerAnalyzer.conv2d_analysis(
                params["in_channels"],
                params["out_channels"],
                params["kernel_size"],
                params.get("stride", 1),
                params.get("padding", 0),
                (params["in_channels"], 224, 224),
                use_bias=params.get("use_bias", True),
            )
    
    elif layer_type == "Linear":
        result = LayerAnalyzer.linear_analysis(
            params["in_features"],
            params["out_features"],
            use_bias=params.get("use_bias", True),
        )
    
    elif layer_type == "BatchNorm2d":
        # BatchNorm2déœ€è¦input_shapeæ¥è®¡ç®—FLOPs
        if isinstance(input_shape, (list, tuple)) and len(input_shape) >= 3:
            if len(input_shape) == 4:  # (N, C, H, W)
                input_shape = input_shape[1:]
            result = LayerAnalyzer.batchnorm2d_analysis(
                params["num_features"], input_shape
            )
        else:
            # ä½¿ç”¨é»˜è®¤å½¢çŠ¶
            result = LayerAnalyzer.batchnorm2d_analysis(
                params["num_features"], (params["num_features"], 224, 224)
            )
    
    elif layer_type == "LayerNorm":
        normalized_shape = params.get("normalized_shape", [512])
        if isinstance(normalized_shape, int):
            normalized_shape = [normalized_shape]
        result = LayerAnalyzer.layernorm_analysis(tuple(normalized_shape))
    
    elif layer_type == "MultiHeadAttention":
        result = LayerAnalyzer.attention_analysis(
            params.get("d_model", 512),
            params.get("num_heads", 8),
            params.get("seq_len", 128),
        )
    
    elif layer_type == "LSTM":
        result = LayerAnalyzer.lstm_analysis(
            params.get("input_size", 512),
            params.get("hidden_size", 512),
            params.get("num_layers", 1),
            bidirectional=params.get("bidirectional", False),
        )
    
    elif layer_type == "Embedding":
        result = LayerAnalyzer.embedding_analysis(
            params.get("num_embeddings", 10000),
            params.get("embedding_dim", 512),
        )
    
    else:
        # å¯¹äºæ— å‚æ•°çš„å±‚ (ReLU, Dropout, MaxPool2d, Flattenç­‰)
        result = {
            "layer_type": layer_type,
            "parameters": {"total": 0},
            "flops": {"total": 0},
            "memory_mb": {"parameters": 0},
            "output_shape": "-",
        }
    
    return {
        "type": layer_type,
        "params": result["parameters"]["total"],
        "flops": result["flops"]["total"],
        "memory": result.get("memory_mb", {}).get("parameters", 0),
        "output_shape": result.get("output_shape", "-"),
    }


def generate_network_report(
    network_name: str, layers_data: List[Dict], total_params: int, total_flops: int
):
    """ç”Ÿæˆç½‘ç»œåˆ†ææŠ¥å‘Š"""
    st.markdown("---")
    st.markdown("### ğŸ“„ ç½‘ç»œåˆ†ææŠ¥å‘Š")

    report = f"""
    # {network_name} ç½‘ç»œåˆ†ææŠ¥å‘Š

    ## æ€»ä½“ç»Ÿè®¡
    - **æ€»å‚æ•°é‡**: {total_params:,} ({total_params/1e6:.2f}M)
    - **æ€»FLOPs**: {total_flops:,} ({total_flops/1e9:.2f}G)
    - **å±‚æ•°**: {len(layers_data)}

    ## è¯¦ç»†å±‚ä¿¡æ¯
    """

    for i, layer in enumerate(layers_data):
        report += f"""
        ### Layer {i+1}: {layer['type']}
        - å‚æ•°é‡: {layer['params']:,}
        - FLOPs: {layer['flops']:,}
        """

    st.markdown(report)

    # ä¸‹è½½æŒ‰é’®
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š",
        data=report,
        file_name=f"{network_name}_analysis.md",
        mime="text/markdown",
    )
