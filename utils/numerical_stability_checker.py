"""
æ•°å€¼ç¨³å®šæ€§æ£€æµ‹å™¨ - Numerical Stability Checker

ä¸ºæ‰€æœ‰æ¨¡å—æä¾›ç»Ÿä¸€çš„ç¨³å®šæ€§æ£€æµ‹æ¥å£
éµå¾ªé¡¹ç›®å®šä½ï¼šä¸ä»…å±•ç¤º"ç®—äº†ä»€ä¹ˆ"ï¼Œæ›´è¦æ£€æµ‹"ä»€ä¹ˆæ—¶å€™ä¼šå‡ºé—®é¢˜"

Author: Neural Network Math Explorer
Date: 2024-01-XX
"""

import numpy as np
import streamlit as st
import pandas as pd
from typing import Dict, List, Any, Optional


class StabilityChecker:
    """
    æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥å™¨

    æä¾›ç»Ÿä¸€çš„æ£€æµ‹æ¥å£ï¼ŒåŒ…æ‹¬ï¼š
    - æ¢¯åº¦æ£€æµ‹ï¼ˆæ¶ˆå¤±/çˆ†ç‚¸ï¼‰
    - æ¿€æ´»å€¼æ£€æµ‹ï¼ˆè¿‡å¤§/è¿‡å°ï¼‰
    - é—¨æ§é¥±å’Œæ£€æµ‹ï¼ˆLSTM/GRUï¼‰
    - æ•°å€¼éªŒè¯ï¼ˆæ¢¯åº¦æ­£ç¡®æ€§ï¼‰
    - NaN/Infæ£€æµ‹
    """

    # é˜ˆå€¼å®šä¹‰ï¼ˆåŸºäºç¨³å®šæ€§è¯Šæ–­æ¨¡å—çš„æœ€ä½³å®è·µï¼‰
    THRESHOLDS = {
        "gradient_vanishing": 1e-7,  # æ¢¯åº¦æ¶ˆå¤±é˜ˆå€¼
        "gradient_exploding": 10,  # æ¢¯åº¦çˆ†ç‚¸é˜ˆå€¼
        "activation_extreme": 100,  # æ¿€æ´»å€¼è¿‡å¤§é˜ˆå€¼
        "gate_saturation": 0.95,  # é—¨æ§é¥±å’Œé˜ˆå€¼
        "numerical_diff_good": 1e-7,  # æ¢¯åº¦éªŒè¯-ä¼˜ç§€
        "numerical_diff_ok": 1e-5,  # æ¢¯åº¦éªŒè¯-å¯æ¥å—
        "param_exploding": 1e6,  # å‚æ•°çˆ†ç‚¸é˜ˆå€¼
        "learning_rate_high": 1.0,  # å­¦ä¹ ç‡è¿‡é«˜é˜ˆå€¼
    }

    @staticmethod
    def check_gradient(gradients: np.ndarray, name: str = "æ¢¯åº¦") -> Dict[str, Any]:
        """
        æ£€æŸ¥æ¢¯åº¦æ˜¯å¦æ­£å¸¸

        Args:
            gradients: æ¢¯åº¦æ•°ç»„
            name: æ¢¯åº¦åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        grad_norm = np.linalg.norm(gradients)
        grad_mean = np.mean(np.abs(gradients))
        grad_max = np.max(np.abs(gradients))

        if grad_norm < StabilityChecker.THRESHOLDS["gradient_vanishing"]:
            return {
                "status": "error",
                "type": f"{name}æ¶ˆå¤±",
                "value": f"{grad_norm:.2e}",
                "threshold": f'< {StabilityChecker.THRESHOLDS["gradient_vanishing"]:.0e}',
                "icon": "ğŸ”´",
                "severity": "high",
                "details": {
                    "èŒƒæ•°": f"{grad_norm:.2e}",
                    "å¹³å‡ç»å¯¹å€¼": f"{grad_mean:.2e}",
                    "æœ€å¤§ç»å¯¹å€¼": f"{grad_max:.2e}",
                },
                "solution": [
                    "ä½¿ç”¨ResNetæ®‹å·®è¿æ¥",
                    "ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°",
                    "ä½¿ç”¨Heåˆå§‹åŒ–",
                    "å¢åŠ å­¦ä¹ ç‡",
                    "æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»å‡½æ•°é¥±å’Œ",
                ],
                "explanation": "æ¢¯åº¦èŒƒæ•°è¿‡å°ï¼Œåå‘ä¼ æ’­ä¿¡å·å‡ ä¹æ¶ˆå¤±ï¼Œå¯¼è‡´ç½‘ç»œæ— æ³•å­¦ä¹ ",
            }
        elif grad_norm > StabilityChecker.THRESHOLDS["gradient_exploding"]:
            return {
                "status": "error",
                "type": f"{name}çˆ†ç‚¸",
                "value": f"{grad_norm:.2e}",
                "threshold": f'> {StabilityChecker.THRESHOLDS["gradient_exploding"]}',
                "icon": "ğŸŸ ",
                "severity": "high",
                "details": {
                    "èŒƒæ•°": f"{grad_norm:.2e}",
                    "å¹³å‡ç»å¯¹å€¼": f"{grad_mean:.2e}",
                    "æœ€å¤§ç»å¯¹å€¼": f"{grad_max:.2e}",
                },
                "solution": [
                    "ä½¿ç”¨æ¢¯åº¦è£å‰ª (gradient clipping)",
                    "é™ä½å­¦ä¹ ç‡ (ä¾‹å¦‚ä»0.01é™åˆ°0.001)",
                    "æ£€æŸ¥æƒé‡åˆå§‹åŒ–æ˜¯å¦è¿‡å¤§",
                    "ä½¿ç”¨BatchNorm/LayerNorm",
                    "æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦å·²å½’ä¸€åŒ–",
                ],
                "explanation": "æ¢¯åº¦èŒƒæ•°è¿‡å¤§ï¼Œå‚æ•°æ›´æ–°æ­¥é•¿å¤ªå¤§ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šæˆ–NaN",
            }
        else:
            return {
                "status": "success",
                "type": f"{name}æ­£å¸¸",
                "value": f"{grad_norm:.2e}",
                "icon": "ğŸŸ¢",
                "severity": "none",
                "details": {
                    "èŒƒæ•°": f"{grad_norm:.2e}",
                    "å¹³å‡ç»å¯¹å€¼": f"{grad_mean:.2e}",
                    "æœ€å¤§ç»å¯¹å€¼": f"{grad_max:.2e}",
                },
            }

    @staticmethod
    def check_activation(
        activations: np.ndarray, name: str = "æ¿€æ´»å€¼"
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ¿€æ´»å€¼æ˜¯å¦æ­£å¸¸

        Args:
            activations: æ¿€æ´»å€¼æ•°ç»„
            name: æ¿€æ´»å€¼åç§°

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        max_val = np.max(np.abs(activations))
        mean_val = np.mean(activations)
        std_val = np.std(activations)

        # æ£€æŸ¥NaNæˆ–Inf
        if np.isnan(activations).any():
            return {
                "status": "error",
                "type": f"{name}åŒ…å«NaN",
                "value": f"{np.sum(np.isnan(activations))}ä¸ªNaN",
                "icon": "ğŸŸ£",
                "severity": "critical",
                "details": {
                    "NaNæ•°é‡": np.sum(np.isnan(activations)),
                    "æ€»å…ƒç´ ": activations.size,
                    "å æ¯”": f"{np.sum(np.isnan(activations))/activations.size*100:.1f}%",
                },
                "solution": [
                    "æ£€æŸ¥é™¤é›¶é”™è¯¯",
                    "æ£€æŸ¥log(0)æˆ–sqrt(è´Ÿæ•°)ç­‰éæ³•æ“ä½œ",
                    "æ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦çˆ†ç‚¸",
                    "é™ä½å­¦ä¹ ç‡",
                    "ä½¿ç”¨æ¢¯åº¦è£å‰ª",
                ],
                "explanation": "NaN (Not a Number) è¡¨ç¤ºè®¡ç®—å‡ºç°éæ³•æ“ä½œï¼Œå¿…é¡»ç«‹å³ä¿®å¤",
            }

        if np.isinf(activations).any():
            return {
                "status": "error",
                "type": f"{name}åŒ…å«Inf",
                "value": f"{np.sum(np.isinf(activations))}ä¸ªInf",
                "icon": "ğŸŸ£",
                "severity": "critical",
                "details": {
                    "Infæ•°é‡": np.sum(np.isinf(activations)),
                    "æ€»å…ƒç´ ": activations.size,
                    "å æ¯”": f"{np.sum(np.isinf(activations))/activations.size*100:.1f}%",
                },
                "solution": [
                    "æ£€æŸ¥æ•°å€¼æº¢å‡º",
                    "æ£€æŸ¥æŒ‡æ•°è¿ç®—",
                    "é™ä½å­¦ä¹ ç‡",
                    "ä½¿ç”¨æ¢¯åº¦è£å‰ª",
                    "æ£€æŸ¥æƒé‡åˆå§‹åŒ–",
                ],
                "explanation": "Inf (Infinity) è¡¨ç¤ºæ•°å€¼æº¢å‡ºï¼Œè®¡ç®—ç»“æœè¶…å‡ºæµ®ç‚¹æ•°è¡¨ç¤ºèŒƒå›´",
            }

        if max_val > StabilityChecker.THRESHOLDS["activation_extreme"]:
            return {
                "status": "warning",
                "type": f"{name}è¿‡å¤§",
                "value": f"{max_val:.2f}",
                "threshold": f'> {StabilityChecker.THRESHOLDS["activation_extreme"]}',
                "icon": "ğŸŸ¡",
                "severity": "medium",
                "details": {
                    "æœ€å¤§ç»å¯¹å€¼": f"{max_val:.2f}",
                    "å‡å€¼": f"{mean_val:.4f}",
                    "æ ‡å‡†å·®": f"{std_val:.4f}",
                },
                "solution": [
                    "ä½¿ç”¨BatchNormæˆ–LayerNorm",
                    "ä½¿ç”¨Xavieræˆ–Heåˆå§‹åŒ–",
                    "æ£€æŸ¥è¾“å…¥æ•°æ®èŒƒå›´",
                    "ä½¿ç”¨æ¿€æ´»å‡½æ•°çº¦æŸè¾“å‡ºèŒƒå›´",
                ],
                "explanation": "æ¿€æ´»å€¼è¿‡å¤§å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šï¼Œå¢åŠ æº¢å‡ºé£é™©",
            }
        else:
            return {
                "status": "success",
                "type": f"{name}æ­£å¸¸",
                "value": f"æœ€å¤§={max_val:.2f}",
                "icon": "ğŸŸ¢",
                "severity": "none",
                "details": {
                    "æœ€å¤§ç»å¯¹å€¼": f"{max_val:.2f}",
                    "å‡å€¼": f"{mean_val:.4f}",
                    "æ ‡å‡†å·®": f"{std_val:.4f}",
                },
            }

    @staticmethod
    def check_gate_saturation(
        gate_values: np.ndarray, gate_name: str = "é—¨æ§"
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥é—¨æ§æ˜¯å¦é¥±å’Œï¼ˆç”¨äºLSTM/GRUï¼‰

        Args:
            gate_values: é—¨æ§å€¼æ•°ç»„ï¼ˆåº”è¯¥åœ¨0-1ä¹‹é—´ï¼‰
            gate_name: é—¨æ§åç§°ï¼ˆå¦‚"é—å¿˜é—¨"ã€"æ›´æ–°é—¨"ï¼‰

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        # è®¡ç®—é¥±å’Œç‡ï¼ˆæ¥è¿‘0æˆ–1çš„æ¯”ä¾‹ï¼‰
        near_zero = np.sum(gate_values < 0.05)
        near_one = np.sum(gate_values > 0.95)
        total = gate_values.size
        saturation_rate = (near_zero + near_one) / total

        mean_val = np.mean(gate_values)
        std_val = np.std(gate_values)

        if saturation_rate > StabilityChecker.THRESHOLDS["gate_saturation"]:
            return {
                "status": "warning",
                "type": f"{gate_name}é¥±å’Œ",
                "value": f"{saturation_rate*100:.1f}%",
                "threshold": f'> {StabilityChecker.THRESHOLDS["gate_saturation"]*100:.0f}%',
                "icon": "ğŸŸ¡",
                "severity": "medium",
                "details": {
                    "é¥±å’Œç‡": f"{saturation_rate*100:.1f}%",
                    "æ¥è¿‘0": f"{near_zero}/{total} ({near_zero/total*100:.1f}%)",
                    "æ¥è¿‘1": f"{near_one}/{total} ({near_one/total*100:.1f}%)",
                    "å‡å€¼": f"{mean_val:.4f}",
                    "æ ‡å‡†å·®": f"{std_val:.4f}",
                },
                "solution": [
                    "é™ä½å­¦ä¹ ç‡",
                    "ä½¿ç”¨BatchNorm/LayerNorm",
                    "æ£€æŸ¥æƒé‡åˆå§‹åŒ–ï¼ˆä½¿ç”¨Orthogonalåˆå§‹åŒ–ï¼‰",
                    "ä½¿ç”¨æ¢¯åº¦è£å‰ª",
                    "è€ƒè™‘ä½¿ç”¨æ›´å°çš„ç½‘ç»œ",
                ],
                "explanation": "é—¨æ§å€¼è¿‡åº¦é›†ä¸­åœ¨0æˆ–1ï¼Œå¯¼è‡´ä¿¡æ¯æµåŠ¨å—é˜»ï¼Œç±»ä¼¼æ¢¯åº¦æ¶ˆå¤±",
            }
        else:
            return {
                "status": "success",
                "type": f"{gate_name}æ­£å¸¸",
                "value": f"é¥±å’Œç‡={saturation_rate*100:.1f}%",
                "icon": "ğŸŸ¢",
                "severity": "none",
                "details": {
                    "é¥±å’Œç‡": f"{saturation_rate*100:.1f}%",
                    "æ¥è¿‘0": f"{near_zero}/{total} ({near_zero/total*100:.1f}%)",
                    "æ¥è¿‘1": f"{near_one}/{total} ({near_one/total*100:.1f}%)",
                    "å‡å€¼": f"{mean_val:.4f}",
                    "æ ‡å‡†å·®": f"{std_val:.4f}",
                },
            }

    @staticmethod
    def verify_gradient(
        numerical_grad: np.ndarray, analytical_grad: np.ndarray, name: str = "æ¢¯åº¦"
    ) -> Dict[str, Any]:
        """
        éªŒè¯æ¢¯åº¦è®¡ç®—æ­£ç¡®æ€§ï¼ˆæ•°å€¼æ¢¯åº¦ vs è§£ææ¢¯åº¦ï¼‰

        å‚è€ƒåå‘ä¼ æ’­æ¨¡å—çš„æ ‡å‡†ï¼ˆç¬¬318-324è¡Œï¼‰

        Args:
            numerical_grad: æ•°å€¼æ¢¯åº¦ï¼ˆæœ‰é™å·®åˆ†æ³•è®¡ç®—ï¼‰
            analytical_grad: è§£ææ¢¯åº¦ï¼ˆåå‘ä¼ æ’­è®¡ç®—ï¼‰
            name: æ¢¯åº¦åç§°

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        diff = np.abs(numerical_grad - analytical_grad).mean()
        relative_error = diff / (
            np.abs(numerical_grad).mean() + np.abs(analytical_grad).mean() + 1e-8
        )

        if diff < StabilityChecker.THRESHOLDS["numerical_diff_good"]:
            return {
                "status": "success",
                "type": f"{name}éªŒè¯",
                "value": f"{diff:.2e}",
                "threshold": f'< {StabilityChecker.THRESHOLDS["numerical_diff_good"]:.0e}',
                "message": "âœ… æ¢¯åº¦è®¡ç®—æ­£ç¡®",
                "icon": "âœ…",
                "severity": "none",
                "details": {
                    "å¹³å‡å·®å¼‚": f"{diff:.2e}",
                    "ç›¸å¯¹è¯¯å·®": f"{relative_error:.2e}",
                    "æ•°å€¼æ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(numerical_grad):.2e}",
                    "è§£ææ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(analytical_grad):.2e}",
                },
            }
        elif diff < StabilityChecker.THRESHOLDS["numerical_diff_ok"]:
            return {
                "status": "warning",
                "type": f"{name}éªŒè¯",
                "value": f"{diff:.2e}",
                "threshold": f'< {StabilityChecker.THRESHOLDS["numerical_diff_ok"]:.0e}',
                "message": "âš ï¸ å¯èƒ½æœ‰å°è¯¯å·®",
                "icon": "âš ï¸",
                "severity": "low",
                "details": {
                    "å¹³å‡å·®å¼‚": f"{diff:.2e}",
                    "ç›¸å¯¹è¯¯å·®": f"{relative_error:.2e}",
                    "æ•°å€¼æ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(numerical_grad):.2e}",
                    "è§£ææ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(analytical_grad):.2e}",
                },
                "solution": [
                    "æ£€æŸ¥é“¾å¼æ³•åˆ™æ˜¯å¦æ­£ç¡®",
                    "æ£€æŸ¥æ¿€æ´»å‡½æ•°å¯¼æ•°",
                    "å¢åŠ æ•°å€¼æ¢¯åº¦çš„ç²¾åº¦ï¼ˆå‡å°epsilonï¼‰",
                ],
                "explanation": "è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä½†å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–",
            }
        else:
            return {
                "status": "error",
                "type": f"{name}éªŒè¯",
                "value": f"{diff:.2e}",
                "threshold": f'> {StabilityChecker.THRESHOLDS["numerical_diff_ok"]:.0e}',
                "message": "âŒ æ¢¯åº¦è®¡ç®—å¯èƒ½æœ‰è¯¯",
                "icon": "âŒ",
                "severity": "high",
                "details": {
                    "å¹³å‡å·®å¼‚": f"{diff:.2e}",
                    "ç›¸å¯¹è¯¯å·®": f"{relative_error:.2e}",
                    "æ•°å€¼æ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(numerical_grad):.2e}",
                    "è§£ææ¢¯åº¦èŒƒæ•°": f"{np.linalg.norm(analytical_grad):.2e}",
                },
                "solution": [
                    "ä»”ç»†æ£€æŸ¥åå‘ä¼ æ’­å®ç°",
                    "é€æ­¥éªŒè¯æ¯ä¸ªæ¢¯åº¦è®¡ç®—",
                    "æ£€æŸ¥é“¾å¼æ³•åˆ™æ˜¯å¦æ­£ç¡®åº”ç”¨",
                    "æ£€æŸ¥çŸ©é˜µç»´åº¦æ˜¯å¦åŒ¹é…",
                    "å‚è€ƒåå‘ä¼ æ’­æ¨¡å—çš„å®ç°",
                ],
                "explanation": "æ•°å€¼æ¢¯åº¦å’Œè§£ææ¢¯åº¦å·®å¼‚è¿‡å¤§ï¼Œåå‘ä¼ æ’­å®ç°å¯èƒ½æœ‰é”™è¯¯",
            }

    @staticmethod
    def check_learning_rate(
        learning_rate: float, grad_norm: float, param_norm: float
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚

        Args:
            learning_rate: å­¦ä¹ ç‡
            grad_norm: æ¢¯åº¦èŒƒæ•°
            param_norm: å‚æ•°èŒƒæ•°

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        # ä¼°è®¡å‚æ•°æ›´æ–°çš„æ­¥é•¿
        update_norm = learning_rate * grad_norm
        relative_update = update_norm / (param_norm + 1e-8)

        if learning_rate > StabilityChecker.THRESHOLDS["learning_rate_high"]:
            return {
                "status": "warning",
                "type": "å­¦ä¹ ç‡è¿‡é«˜",
                "value": f"{learning_rate}",
                "threshold": f'> {StabilityChecker.THRESHOLDS["learning_rate_high"]}',
                "icon": "ğŸŸ¡",
                "severity": "medium",
                "details": {
                    "å­¦ä¹ ç‡": f"{learning_rate}",
                    "é¢„ä¼°æ›´æ–°æ­¥é•¿": f"{update_norm:.2e}",
                    "ç›¸å¯¹æ›´æ–°æ¯”ä¾‹": f"{relative_update:.2%}",
                },
                "solution": [
                    "é™ä½å­¦ä¹ ç‡ï¼ˆå»ºè®®<0.1ï¼‰",
                    "ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡",
                    "ä½¿ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡ï¼ˆAdam, RMSpropï¼‰",
                ],
                "explanation": "å­¦ä¹ ç‡è¿‡é«˜å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šæˆ–å‘æ•£",
            }
        elif relative_update > 0.1:
            return {
                "status": "warning",
                "type": "å‚æ•°æ›´æ–°è¿‡å¤§",
                "value": f"{relative_update:.2%}",
                "threshold": "> 10%",
                "icon": "ğŸŸ¡",
                "severity": "medium",
                "details": {
                    "å­¦ä¹ ç‡": f"{learning_rate}",
                    "æ¢¯åº¦èŒƒæ•°": f"{grad_norm:.2e}",
                    "å‚æ•°èŒƒæ•°": f"{param_norm:.2e}",
                    "ç›¸å¯¹æ›´æ–°æ¯”ä¾‹": f"{relative_update:.2%}",
                },
                "solution": ["é™ä½å­¦ä¹ ç‡", "ä½¿ç”¨æ¢¯åº¦è£å‰ª", "ä½¿ç”¨æƒé‡è¡°å‡"],
                "explanation": "å•æ­¥æ›´æ–°è¶…è¿‡å‚æ•°å¤§å°çš„10%ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š",
            }
        else:
            return {
                "status": "success",
                "type": "å­¦ä¹ ç‡åˆé€‚",
                "value": f"{learning_rate}",
                "icon": "ğŸŸ¢",
                "severity": "none",
                "details": {
                    "å­¦ä¹ ç‡": f"{learning_rate}",
                    "é¢„ä¼°æ›´æ–°æ­¥é•¿": f"{update_norm:.2e}",
                    "ç›¸å¯¹æ›´æ–°æ¯”ä¾‹": f"{relative_update:.2%}",
                },
            }

    @staticmethod
    def display_issues(
        issues: List[Dict[str, Any]], title: str = "ğŸ”¬ æ•°å€¼ç¨³å®šæ€§è¯Šæ–­æŠ¥å‘Š"
    ):
        """
        åœ¨Streamlitä¸­æ˜¾ç¤ºæ£€æµ‹ç»“æœ

        å‚è€ƒç¨³å®šæ€§è¯Šæ–­æ¨¡å—çš„æ˜¾ç¤ºæ–¹å¼

        Args:
            issues: æ£€æµ‹ç»“æœåˆ—è¡¨
            title: æŠ¥å‘Šæ ‡é¢˜
        """
        if not issues:
            st.success("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œæ²¡æœ‰å‘ç°é—®é¢˜")
            return

        # åˆ†ç»„
        critical = [i for i in issues if i.get("severity") == "critical"]
        errors = [
            i
            for i in issues
            if i["status"] == "error" and i.get("severity") != "critical"
        ]
        warnings = [i for i in issues if i["status"] == "warning"]
        success = [i for i in issues if i["status"] == "success"]

        # æ˜¾ç¤ºæ ‡é¢˜
        st.markdown(f"### {title}")

        # å…³é”®é—®é¢˜ï¼ˆå¿…é¡»ç«‹å³ä¿®å¤ï¼‰
        if critical:
            st.error("ğŸš¨ **å…³é”®é—®é¢˜ï¼ˆå¿…é¡»ç«‹å³ä¿®å¤ï¼‰**")
            for issue in critical:
                with st.expander(
                    f"{issue['icon']} {issue['type']}: {issue['value']}", expanded=True
                ):
                    st.write(f"**è¯´æ˜**: {issue.get('explanation', '')}")

                    if "details" in issue:
                        st.write("**è¯¦ç»†ä¿¡æ¯**:")
                        for key, val in issue["details"].items():
                            st.write(f"- {key}: `{val}`")

                    if "solution" in issue:
                        st.write("**ğŸ”§ è§£å†³æ–¹æ¡ˆ**:")
                        for i, sol in enumerate(issue["solution"], 1):
                            st.write(f"{i}. {sol}")

        # é”™è¯¯ï¼ˆéœ€è¦ä¿®å¤ï¼‰
        if errors:
            st.error("âŒ **æ£€æµ‹åˆ°é—®é¢˜ï¼ˆéœ€è¦ä¿®å¤ï¼‰**")

            # åˆ›å»ºé—®é¢˜è¡¨æ ¼
            table_data = []
            for issue in errors:
                table_data.append(
                    {
                        "çŠ¶æ€": issue["icon"],
                        "é—®é¢˜ç±»å‹": issue["type"],
                        "å½“å‰å€¼": issue["value"],
                        "é˜ˆå€¼": issue.get("threshold", "N/A"),
                    }
                )

            df = pd.DataFrame(table_data)
            st.markdown(df.to_markdown(index=False))

            # è¯¦ç»†ä¿¡æ¯
            for issue in errors:
                with st.expander(f"è¯¦æƒ…: {issue['type']}", expanded=False):
                    st.write(f"**è¯´æ˜**: {issue.get('explanation', '')}")

                    if "details" in issue:
                        st.write("**è¯¦ç»†ä¿¡æ¯**:")
                        for key, val in issue["details"].items():
                            st.write(f"- {key}: `{val}`")

                    if "solution" in issue:
                        st.write("**ğŸ”§ è§£å†³æ–¹æ¡ˆ**:")
                        for i, sol in enumerate(issue["solution"], 1):
                            st.write(f"{i}. {sol}")

        # è­¦å‘Šï¼ˆå»ºè®®ä¼˜åŒ–ï¼‰
        if warnings:
            st.warning("âš ï¸ **è­¦å‘Šï¼ˆå»ºè®®ä¼˜åŒ–ï¼‰**")

            table_data = []
            for issue in warnings:
                table_data.append(
                    {
                        "çŠ¶æ€": issue["icon"],
                        "é—®é¢˜ç±»å‹": issue["type"],
                        "å½“å‰å€¼": issue["value"],
                        "é˜ˆå€¼": issue.get("threshold", "N/A"),
                    }
                )

            df = pd.DataFrame(table_data)
            st.markdown(df.to_markdown(index=False))

            # è¯¦ç»†ä¿¡æ¯
            for issue in warnings:
                with st.expander(f"è¯¦æƒ…: {issue['type']}", expanded=False):
                    st.write(f"**è¯´æ˜**: {issue.get('explanation', '')}")

                    if "details" in issue:
                        st.write("**è¯¦ç»†ä¿¡æ¯**:")
                        for key, val in issue["details"].items():
                            st.write(f"- {key}: `{val}`")

                    if "solution" in issue:
                        st.write("**ğŸ’¡ å»ºè®®**:")
                        for i, sol in enumerate(issue["solution"], 1):
                            st.write(f"{i}. {sol}")

        # æˆåŠŸçš„æ£€æŸ¥
        if success:
            with st.expander("âœ… é€šè¿‡çš„æ£€æŸ¥", expanded=False):
                for issue in success:
                    st.success(f"{issue['icon']} {issue['type']}: {issue['value']}")
                    if "details" in issue:
                        for key, val in issue["details"].items():
                            st.write(f"- {key}: `{val}`")


def compute_numerical_gradient(neuron, input_data, upstream_gradient, epsilon=1e-5):
    """
    è®¡ç®—æ•°å€¼æ¢¯åº¦ï¼ˆæœ‰é™å·®åˆ†æ³•ï¼‰

    ç”¨äºéªŒè¯è§£ææ¢¯åº¦çš„æ­£ç¡®æ€§

    Args:
        neuron: ç¥ç»å…ƒå¯¹è±¡
        input_data: è¾“å…¥æ•°æ®
        upstream_gradient: ä¸Šæ¸¸æ¢¯åº¦
        epsilon: æ‰°åŠ¨å¤§å°

    Returns:
        æ•°å€¼æ¢¯åº¦
    """
    numerical_grads = np.zeros_like(neuron.weights)

    for i in range(neuron.weights.size):
        # æ‰å¹³åŒ–ç´¢å¼•
        idx = (
            np.unravel_index(i, neuron.weights.shape) if neuron.weights.ndim > 1 else i
        )

        # å‰å‘æ‰°åŠ¨
        original = (
            neuron.weights.flat[i] if neuron.weights.ndim > 1 else neuron.weights[i]
        )
        neuron.weights.flat[i] = original + epsilon
        output_plus = neuron.forward(input_data)
        loss_plus = np.sum(output_plus * upstream_gradient)

        # åå‘æ‰°åŠ¨
        neuron.weights.flat[i] = original - epsilon
        output_minus = neuron.forward(input_data)
        loss_minus = np.sum(output_minus * upstream_gradient)

        # æ¢å¤åŸå€¼
        neuron.weights.flat[i] = original

        # è®¡ç®—æ•°å€¼æ¢¯åº¦
        numerical_grads.flat[i] = (loss_plus - loss_minus) / (2 * epsilon)

    return numerical_grads
